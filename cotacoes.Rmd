---
title: "Análise econométrica em tempo real: Modelos família ARCH para dados financeiros"
author: "Rodrigo H. Ozon"
date: "21/09/2020"
output:
  html_document:
    toc: true
    toc_float: true
params:
  symbol1: PBR
  symbol2: VALE
  symbol3: ^BVSP
---

<!-- https://bookdown.org/ccolonescu/RPoE4/time-varying-volatility-and-arch-models.html -->


<!-- ================================================================================= -->


```{r include=FALSE}

knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE,
	comment = NA
)
knitr::opts_chunk$set(comment = NA)    # Remove all coments # of R outputs
knitr::opts_chunk$set(warning = FALSE) # Remove all warnings # of R outputs
knitr::opts_chunk$set(message = FALSE) # Remove all messages # of R outputs

```

<!-- ================================================================================= -->


***
#### **Resumo** 

<small>Este artigo demonstra um case de aplicação dos modelos de heterocedasticidade condicional para cotações de ativos financeiros (em especial da VALE), com integração via scrapping direto do site do Yahoo!Finance. As cotações apresentam um delay de aproximadamente 1 dia de negociação, e os scripts dos chunks do R estão todos disponíveis para replicações futuras.

[A inspiração de usar a News Impact Curve surgiu do meu trabalho de monografia de graduação em Economia na UFPR em 2008, quando o Laboratório de Estatística e Geoinformação (LEG) do departamento de Estatística da Universidade criou um projeto de pesquisa, um wiki, que está disponível até hoje para sua consulta.](http://leg.ufpr.br/doku.php/projetos:ehlers:volprev)

**Palavras-Chave:** ARCH, VALE, News Impact Curve, Econometria </small>


*** 




# Introdução

```{r include = FALSE}
library(quantmod)
library(dygraphs)

ativo1 <- getSymbols(params$symbol1, auto.assign = FALSE,
                    from = "2018-01-01", end = Sys.Date())

ativo2 <- getSymbols(params$symbol2, auto.assign = FALSE,
                    from = "2018-01-01", end = Sys.Date())

ativo3 <- getSymbols(params$symbol3, auto.assign = FALSE,
                    from = "2018-01-01", end = Sys.Date())
```


Esse relatório capta dinamicamente as cotações de tres ativos
  
* ``r params$symbol1`` Petrobras
* ``r params$symbol2`` Vale
* ``r params$symbol3`` Indice Bovespa

Os dados são originários do [Yahoo finance](http://finance.yahoo.com). As séries temporais se iniciam em 01/01/2018 e terminam no último valor de fechamento quase que em _real time_.

Navegue nele para ver a aplicação de modelos econométricos de volatilidade condicional para os dados da VALE.

Iniciamos observando o caso da maior estatal brasileira, a petrolífera Petrobras:


### ``r params$symbol1`` Preço de Fechamento do pregão

```{r echo = FALSE, fig.width=9,fig.height=3}

dygraph(Cl(ativo1))

```

### ``r params$symbol1`` Volume negociado

```{r echo = FALSE, fig.width=9,fig.height=3}

dygraph(Vo(ativo1))

```

A Operação Lava Jato é um conjunto de investigações, algumas controversas, em andamento pela Polícia Federal do Brasil, que cumpriu mais de mil mandados de busca e apreensão, de prisão temporária, de prisão preventiva e de condução coercitiva, visando apurar um esquema de lavagem de dinheiro que movimentou bilhões de reais em propina. 

A operação teve início em 17 de março de 2014 e conta com 71 fases operacionais autorizadas, entre outros, pelo então juiz Sérgio Moro, durante as quais prenderam-se e condenaram-se mais de cem pessoas. Investiga crimes de corrupção ativa e passiva, gestão fraudulenta, lavagem de dinheiro, organização criminosa, obstrução da justiça, operação fraudulenta de câmbio e recebimento de vantagem indevida. A Lava Jato foi apontada por críticos como uma das causas da crise político-econômica de 2014 no país. De acordo com investigações e delações premiadas, estavam envolvidos em corrupção membros administrativos da empresa estatal petrolífera Petrobras, políticos dos maiores partidos do Brasil, incluindo presidentes da República, presidentes da Câmara dos Deputados e do Senado Federal e governadores de estados, além de empresários de grandes empresas brasileiras. A Polícia Federal considera-a a maior investigação de corrupção da história do país.


***

### ``r params$symbol3`` Preço de Fechamento do pregão

```{r echo = FALSE, fig.width=9,fig.height=3}

presAnnotation <- function(dygraph, x, text) {
  dygraph %>%
    dyAnnotation(x, text, attachAtBottom = TRUE, width = 100, height=20)
}

dygraph(Cl(ativo3))%>%
   dyAnnotation("2019-01-25", text = "A", tooltip = "Rompimento da barragem em Brumadinho")%>%
presAnnotation("2019-01-25", text = "Rompimento da barragem em Brumadinho")%>%
  dyShading(from = "2019-01-25", to = "2019-02-26")%>%
  dyAnnotation("2020-03-02", text = "A", tooltip = "Corona Day")%>%
presAnnotation("2020-03-02", text = "Corona Day")%>%   
  dyShading(from = "2020-03-02", to = "2020-04-27")
  
```

### ``r params$symbol3`` Volume negociado

```{r echo = FALSE, fig.width=9,fig.height=3}
presAnnotation <- function(dygraph, x, text) {
  dygraph %>%
    dyAnnotation(x, text, attachAtBottom = TRUE, width = 100, height=20)
}
dygraph(Vo(ativo3))%>%
 dyAnnotation("2019-01-25", text = "A", tooltip = "Rompimento da barragem em Brumadinho")%>%
presAnnotation("2019-01-25", text = "Rompimento da barragem em Brumadinho")%>%
  dyShading(from = "2019-01-25", to = "2019-02-26")%>%
  dyAnnotation("2020-03-02", text = "A", tooltip = "Corona Day")%>%
presAnnotation("2020-03-02", text = "Corona Day")%>%   
  dyShading(from = "2020-03-02", to = "2020-04-27")
```

O índice bovespa, também chamado de IBOV, é o principal indicador médio de desempenho do mercado de ações no Brasil.

É chamado o “termômetro do mercado de ações”. Se um investidor quer saber como está sua carteira de ações, ele compara com o desempenho do índice bovespa. Se ele está melhor, pior ou com desempenho similar ao do índice.

Formado pela composição de ações das empresas com maior liquidez e maior volume financeiro negociado de todo o volume de negócios da bolsa.



***


### ``r params$symbol2`` Preço de Fechamento do pregão

```{r echo = FALSE, fig.width=9,fig.height=3}
presAnnotation <- function(dygraph, x, text) {
  dygraph %>%
    dyAnnotation(x, text, attachAtBottom = TRUE, width = 300, height=20)
}
dygraph(Cl(ativo2))%>% 
dyAnnotation("2019-01-25", text = "A", tooltip = "Rompimento da barragem em Brumadinho")%>%
presAnnotation("2019-01-25", text = "Rompimento da barragem em Brumadinho")%>%
dyShading(from = "2019-01-25", to = "2019-02-26")%>%
  
dyAnnotation("2020-03-02", text = "A", tooltip = "Corona Day")%>%
presAnnotation("2020-03-02", text = "Corona Day")%>%   
  dyShading(from = "2020-03-02", to = "2020-04-27")
```


### ``r params$symbol2`` Volume negociado

```{r echo = FALSE, fig.width=9,fig.height=3}

presAnnotation <- function(dygraph, x, text) {
  dygraph %>%
    dyAnnotation(x, text, attachAtBottom = TRUE, width = 300, height=20)
}


dygraph(Vo(ativo2))%>%
  dyAnnotation("2019-01-25", text = "A", tooltip = "Rompimento da barragem em Brumadinho")%>%
presAnnotation("2019-01-25", text = "Rompimento da barragem em Brumadinho")%>%
  dyShading(from = "2019-01-25", to = "2019-02-26")%>%
  dyAnnotation("2020-03-02", text = "A", tooltip = "Corona Day")%>%
presAnnotation("2020-03-02", text = "Corona Day")%>%   
  dyShading(from = "2020-03-02", to = "2020-04-27")
```


O rompimento de barragem em Brumadinho em **25 de janeiro de 2019** foi o maior acidente de trabalho no Brasil em perda de vidas humanas e o segundo maior desastre industrial do século. Foi um dos maiores desastres ambientais da mineração do país, depois do rompimento de barragem em Mariana.

Controlada pela Vale S.A., a barragem de rejeitos denominada barragem da Mina Córrego do Feijão, era classificada como de "baixo risco" e "alto potencial de danos" pela empresa. Acumulando os rejeitos de um mina de ferro, ficava no ribeirão Ferro-Carvão, na região de Córrego do Feijão, no município de Brumadinho, estado de Minas Gerais.


### Volatilidade Variável no Tempo e Modelos ARCH 

O modelo autoregressivo de heterocedasticidade condicional (ARCH) diz respeito a séries temporais com heterocedasticidade variável no tempo, onde a variância é condicional à informação existente em um determinado ponto no tempo.

#### O modelo ARCH

O modelo ARCH assume que a média condicional do termo de erro em um modelo de série temporal é constante (zero), ao contrário da série não estacionária, mas sua variância condicional não. Esse modelo pode ser descrito como nas Equações 1, 2 e 3.

\begin{equation}
y_{t}=\phi +e_{t}
\label{eq:archdefA14}
\end{equation}

\begin{equation}
e_{t} | I_{t-1} \sim N(0,h_{t})
\label{eq:archdefB14}
\end{equation}

\begin{equation}
h_{t}=\alpha_{0}+\alpha_{1}e_{t-1}^2, \;\;\;\alpha_{0}>0, \;\; 0\leq \alpha_{1}<1
\label{eq:archdefC14}
\end{equation}

As Equações 4 e 5 fornecem o modelo de teste e as hipóteses para testar os efeitos ARCH em uma série de tempo, onde os resíduos e $\hat e_{t}$ vêm da regressão da variável $y_{t}$ em uma constante, como 1, ou em uma constante mais outros regressores; o teste mostrado na Equação 4 pode incluir vários termos de defasagem, caso em que a hipótese nula (Equação 5) seria que todos eles são conjuntamente insignificantes.

\begin{equation}
\hat e_{t}^2 = \gamma_{0}+\gamma_{1}\hat e_{t-1}^2+...+\gamma_{q}e_{t-q}^2+\nu_{t}  
\label{eq:archeffectseqA14}
\end{equation}

\begin{equation}
H_{0}:\gamma_{1}=...=\gamma_{q}=0\;\;\;H_{A}:\gamma_{1}\neq 0\;or\;...\gamma_{q}\neq 0
\label{eq:archeffectseqB14}
\end{equation}


A hipótese nula é que não há efeitos ARCH. A estatística de teste é

$$
(T-q)R^2 \sim \chi ^2_{(1-\alpha,q)}
$$


***


#### Rodando o modelo ARCH e GARCH para os dados da VALE

```{r comment=NA}

ativo2[1:10,] # Gero as primeiras 10 linhas do dataset

Cl(ativo2) # Gero os dados para aqueles que desejem baixar por aqui

Vo(ativo2) # Gero os dados para aqueles que desejem baixar por aqui

# Voce pode usar o seguinte comando para exportar esse dataset 

write.csv(ativo2, file="VALE.csv")


library(xlsx)
write.xlsx(ativo2, file="VALE.xlsx")

#https://www.guru99.com/r-exporting-data.html#1 

```

Após vermos os precos de fechamento e volume, obtenho o log retorno dos precos 


```{r, fig.width=9,fig.height=3}

dlnVALEclose <- diff(log(Cl(ativo2)), lag=1) #ln(Pt/Pt-1)

dlnVALEclose<-dlnVALEclose[-1,]


presAnnotation <- function(dygraph, x, text) {
  dygraph %>%
    dyAnnotation(x, text, attachAtBottom = TRUE, width = 300, height=20)
}

dygraph(dlnVALEclose, main = "Retornos logarítmicos dos preços de fechamento VALE")%>%
   dyAnnotation("2019-01-25", text = "A", tooltip = "Rompimento da barragem em Brumadinho")%>%
presAnnotation("2019-01-25", text = "Rompimento da barragem em Brumadinho")%>%
  dyShading(from = "2019-01-25", to = "2019-02-26")%>%
  dyAnnotation("2020-03-02", text = "A", tooltip = "Corona Day")%>%
presAnnotation("2020-03-02", text = "Corona Day")%>%   
  dyShading(from = "2020-03-02", to = "2020-04-27")
  #Grafico dos retornos
```

Agora observo o padrão da distribuição dos log retornos:

```{r, fig.width=9,fig.height=5, message=FALSE}
hist(dlnVALEclose, main="", breaks=20, freq=FALSE, col="grey")
lines(density(dlnVALEclose, adjust=2, col="blue"))
```

Vamos iniciar carregando os pacotes necessários do R:

```{r message=FALSE}
#rm(list=ls()) #Removes all items in Environment!
library(FinTS) #for function `ArchTest()`
library(rugarch) #for GARCH models
library(tseries) # for `adf.test()`
library(dynlm) #for function `dynlm()`
library(vars) # for function `VAR()`
library(nlWaldTest) # for the `nlWaldtest()` function
library(lmtest) #for `coeftest()` and `bptest()`.
library(broom) #for `glance(`) and `tidy()`
#library(PoEdata) #for PoE4 datasets
library(car) #for `hccm()` robust standard errors
library(sandwich)
library(knitr) #for `kable()`
library(forecast) 
```

Vamos primeiro realizar, passo a passo, o teste ARCH na variável VALE.Close. Iremos transformar os dados numa série temporal para leitura do R:


```{r fig.width=9, fig.height=3}

library(dynlm)

rTS <- ts(dlnVALEclose) # A funcao ts eh o mesmo que timeseries

plot.ts(ativo2$VALE.Close) # Serie temporal de valor de fechamento da VALE

plot.ts(rTS) # Serie de retornos logaritmizados da VALE

```

Então obtemos os valores de estimativas dos parâmetros da regressão:

```{r comment=NA }

VALE.media <- dynlm(rTS~1)


```


&nbsp;

<center>
```{r echo=FALSE, message=FALSE, results='asis',warning=FALSE}
library(stargazer)
stargazer(VALE.media, type="html", 
          intercept.bottom = FALSE, 
          single.row=FALSE,     
          notes.append = FALSE,
          omit.stat=c("LL","ser","f"),
          header=FALSE) 
```

</center>

&nbsp;






```{r comment=NA}
ehatsq <- ts(resid(VALE.media)^2) # Obtenho os valores da serie de residuos do modelo ARCH elevado ao quadrado

VALE.ARCH <- dynlm(ehatsq~L(ehatsq)) # Agora estimo o modelo dinamico usando a serie de residuos

summary(VALE.ARCH) # Printa os resultados
```

&nbsp;

<center>
```{r echo=FALSE, message=FALSE, results='asis',warning=FALSE}
library(stargazer)
stargazer(VALE.ARCH , type="html", 
          intercept.bottom = FALSE, 
          single.row=FALSE,     
          notes.append = FALSE, 
          omit.stat=c("LL","ser","f"),
          header=FALSE) 
```

</center>

&nbsp;




```{r comment=NA}
library(broom)

T <- nobs(VALE.media)

q <- length(coef(VALE.ARCH))-1

Rsq <- glance(VALE.ARCH)[[1]]

LM <- (T-q)*Rsq

alpha <- 0.05

quiquadr <- qchisq(1-alpha, q)
```

O valor da estatística LM é de `r round(LM,2)` que deve ser comparado ao valor crítico do qui-quadrado com $\alpha = 0,05$ e $q=$ `r round(q,0)` grau de liberdade; este valor é $\chi^{2}_{(0,95,\,\, 1)}$  = `r round(quiquadr,2)`; isso indica que a hipótese nula é rejeitada, concluindo que a série tem efeitos ARCH.

A mesma conclusão pode ser alcançada se, em vez do procedimento passo a passo, usarmos um dos recursos de teste ARCH do R, a função ArchTest() no pacote FinTS.

```{r comment=NA}
library(FinTS)
VALEArchTest <- ArchTest(dlnVALEclose, lags=1, demean=TRUE)
VALEArchTest
```




A função garch() no pacote tseries torna-se um modelo ARCH quando usada com o order = argumento igual a c(0,1). Essa função pode ser usada para estimar e plotar a variância $h_{t}$ definida na Equação 3, conforme mostrado no código a seguir e na Figura abaixo.

```{r comment=NA}
library(tseries)

rTS<-rTS%>%
  na.omit() # Retiro os NAs da serie

VALE.arch <- garch(rTS,c(0,1))
```


```{r comment=NA}
sbydarch <- summary(VALE.arch)
sbydarch
```


```{r fig.width=9,fig.height=3}
hhat <- ts(2*VALE.arch$fitted.values[-1,1]^2)

plot.ts(hhat)
```

# O modelo GARCH

```{r comment=NA}
library(rugarch)
garchSpec <- ugarchspec(
           variance.model=list(model="sGARCH",
                               garchOrder=c(1,1)),
           mean.model=list(armaOrder=c(0,0)), 
           distribution.model="std")
garchFit <- ugarchfit(spec=garchSpec, data=rTS)
coef(garchFit)
```






```{r fig.width=9,fig.height=3}
rhat <- garchFit@fit$fitted.values
plot.ts(rhat)
hhat <- ts(garchFit@fit$sigma^2)
plot.ts(hhat)
```

```{r comment=NA}
# tGARCH 
garchMod <- ugarchspec(variance.model=list(model="fGARCH",
                               garchOrder=c(1,1),
                               submodel="TGARCH"),
           mean.model=list(armaOrder=c(0,0)), 
           distribution.model="std")
garchFit <- ugarchfit(spec=garchMod, data=rTS)
coef(garchFit)
```




```{r fig.width=9,fig.height=3}
rhat <- garchFit@fit$fitted.values
plot.ts(rhat)
hhat <- ts(garchFit@fit$sigma^2)
plot.ts(hhat)
```

```{r comment=NA}
# GARCH-in-mean
garchMod <- ugarchspec(
          variance.model=list(model="fGARCH",
                               garchOrder=c(1,1),
                               submodel="APARCH"),
           mean.model=list(armaOrder=c(0,0),
                          include.mean=TRUE,
                          archm=TRUE,
                          archpow=2
                          ), 
           distribution.model="std"
                           )
garchFit <- ugarchfit(spec=garchMod, data=rTS)
coef(garchFit)
```








```{r fig.width=9, fig.height=3, message=FALSE}
rhat <- garchFit@fit$fitted.values
plot.ts(rhat)
hhat <- ts(garchFit@fit$sigma^2)
plot.ts(hhat)
```

As Figuras anteriores mostram algumas versões do modelo GARCH. As previsões podem ser obtidas usando a função ugarchboot() do pacote ugarch.

***

# Outro script para a News Impact Curve


```{r message=FALSE}
library(PerformanceAnalytics)
library(quantmod)
library(rugarch)
library(car)
library(FinTS)
```

```{r comment=NA}
options(digits=4)

VALEfechamento<-ativo2$VALE.Close

# Calcula o log retorno dos precos de fechamento da VALE
VALE.ret = CalculateReturns(VALEfechamento, method="log")

VALE.ret[1:10,] # printa as primeiras dez linhas

VALE.ret=VALE.ret[-1,] # Removo o primeiro NA

VALE.ret[1:10,] # printa as primeiras dez linhas
```

## GARCH Assimétrico


Agora vamos definir o GARCH assimétrico

```{r comment=NA}
garch11.spec = ugarchspec(variance.model = list(garchOrder=c(1,1)), 
                          mean.model = list(armaOrder=c(0,0)))
VALE.garch11.fit = ugarchfit(spec=garch11.spec, data=VALE.ret,
                             solver.control=list(trace = 1))


VALE.garch11.fit

plot(residuals(VALE.garch11.fit))



```











Rodaremos o teste de Engle & NG. para o viés de sinal:

<!-- https://onlinelibrary.wiley.com/doi/full/10.1111/j.1540-6261.1993.tb05127.x  -->



O teste de viés de sinal considera a variável $S_{t-1}^{-}$, uma variável fictícia que assume o valor um quando $\epsilon_{t-1}$ é negativo e zero, caso contrário. Este teste examina o impacto de choques de retorno positivo e negativo sobre a volatilidade não prevista pelo modelo em consideração. O teste de viés de tamanho negativo utiliza a variável $S_{t-1}^{-}$ $\epsilon_{t-1}$. Ele se concentra nos diferentes efeitos que grandes e pequenos choques de retorno negativo têm sobre a volatilidade, o que não é previsto pelo modelo de volatilidade. O teste de viés de tamanho positivo utiliza a variável $S_{t-1}^{+}$ $\epsilon_{t-1}$ onde $S_{t-1}^{+}$ é definido como 1 menos $S_{t-1}$. Ele se concentra nos diferentes impactos que grandes e pequenos choques de retorno positivo podem ter sobre a volatilidade, que não são explicados pelo modelo de volatilidade.

```{r comment=NA}
signbias(VALE.garch11.fit)
```


Como apontado acima, o efeito de viés de negativo foi o que apresentou significância.


## Modelo EGARCH de Nelson

```{r comment=NA}
egarch11.spec = ugarchspec(variance.model=list(model="eGARCH",
                                               garchOrder=c(1,1)),
                           mean.model=list(armaOrder=c(0,0)))
VALE.egarch11.fit = ugarchfit(egarch11.spec, VALE.ret)
VALE.egarch11.fit

plot(residuals(VALE.egarch11.fit))
```

## Modelo GJR GARCH

```{r comment=NA}
gjrgarch11.spec = ugarchspec(variance.model=list(model="gjrGARCH",
                                                 garchOrder=c(1,1)),
                             mean.model=list(armaOrder=c(0,0)))
VALE.gjrgarch11.fit = ugarchfit(gjrgarch11.spec, VALE.ret)
VALE.gjrgarch11.fit

plot(residuals(VALE.gjrgarch11.fit))
```


## Modelo APARCH

```{r comment=NA}
aparch11.1.spec = ugarchspec(variance.model=list(model="apARCH",
                                                 garchOrder=c(1,1)),
                             mean.model=list(armaOrder=c(0,0)),
                             fixed.pars=list(delta=1))

VALE.aparch11.1.fit = ugarchfit(aparch11.1.spec, VALE.ret)
VALE.aparch11.1.fit

plot(residuals(VALE.aparch11.1.fit))
```

# Comparando as News Impact Curves

```{r comment=NA}
nic.garch11 = newsimpact(VALE.garch11.fit)
nic.egarch11 = newsimpact(VALE.egarch11.fit)
nic.gjrgarch11 = newsimpact(VALE.gjrgarch11.fit)
nic.aparch11.1 = newsimpact(VALE.aparch11.1.fit)
```

Via critério de informação, comparamos:

```{r comment=NA}
model.list = list(garch11 = VALE.garch11.fit,
                  egarch11 = VALE.egarch11.fit,
                  gjrgarch11 = VALE.gjrgarch11.fit,
                  aparch11.1 = VALE.aparch11.1.fit)
info.mat = sapply(model.list, infocriteria)
rownames(info.mat) = rownames(infocriteria(VALE.garch11.fit))
info.mat
```

Mostra a News Impact Curve estimada GARCH(1,1) e EGARCH(1,1)

```{r fig.width=9,fig.height=9}
par(mfrow=c(2,2))
plot(nic.garch11$zx, type="l", lwd=2, col="blue", main="GARCH(1,1)", 
     nic.garch11$zy, ylab=nic.garch11$yexpr, xlab=nic.garch11$xexpr)
plot(nic.egarch11$zx, type="l", lwd=2, col="blue", main="EGARCH(1,1)", 
     nic.egarch11$zy, ylab=nic.egarch11$yexpr, xlab=nic.egarch11$xexpr)
plot(nic.gjrgarch11$zx, type="l", lwd=2, col="blue", main="TGARCH(1,1)", 
     nic.gjrgarch11$zy, ylab=nic.gjrgarch11$yexpr, xlab=nic.gjrgarch11$xexpr)
plot(nic.aparch11.1$zx, type="l", lwd=2, col="blue", main="APARCH(1,1,1)", 
     nic.aparch11.1$zy, ylab=nic.aparch11.1$yexpr, xlab=nic.aparch11.1$xexpr)

```

# Modelo GARCH com erros não-normais

Vamos observar um modelo GARCH(1,1) normal, examinaremos os resíduos padronizados:

```{r comment=NA}
VALE.garch11.zt = residuals(VALE.garch11.fit)/sigma(VALE.garch11.fit)
VALE.garch11.zt = xts(VALE.garch11.zt, order.by=index(VALE.ret))
qqPlot(coredata(VALE.garch11.zt))
plot(VALE.garch11.fit, which=8)
plot(VALE.garch11.fit, which=9)

```


Rodaremos um modelo GARCH(1,1) com erros de Student $t$:

```{r comment=NA}
garch11.t.spec = ugarchspec(variance.model = list(garchOrder=c(1,1)), 
                            mean.model = list(armaOrder=c(0,0)),
                            distribution.model = "std")
VALE.garch11.t.fit = ugarchfit(spec=garch11.t.spec, data=VALE.ret)                             
VALE.garch11.t.fit

plot(VALE.garch11.t.fit, which=9)


aparch11.1.t.spec = ugarchspec(variance.model = list(model="apARCH",
                                                     garchOrder=c(1,1)), 
                               mean.model = list(armaOrder=c(0,0)),
                               distribution.model = "std",
                               fixed.pars=list(delta=1))
VALE.aparch11.1.t.fit = ugarchfit(spec=aparch11.1.t.spec, data=VALE.ret)                             
VALE.aparch11.1.t.fit

plot(residuals(VALE.aparch11.1.t.fit))
```

Ajustamos uma $t$ enviesada:

```{r comment=NA}
garch11.st.spec = ugarchspec(variance.model = list(garchOrder=c(1,1)), 
                            mean.model = list(armaOrder=c(0,0)),
                            distribution.model = "sstd")
VALE.garch11.st.fit = ugarchfit(spec=garch11.st.spec, data=VALE.ret)                             
VALE.garch11.st.fit

plot(VALE.garch11.st.fit, which=9)

```

## Plotamos os gráficos dos modelos da família ARCH

```{r comment=NA}
VALE.garch11.fcst = ugarchforecast(VALE.garch11.fit, n.ahead=250)
VALE.garch11.t.fcst = ugarchforecast(VALE.garch11.t.fit, n.ahead=250)
VALE.aparch11.1.fcst = ugarchforecast(VALE.aparch11.1.fit, n.ahead=250)
VALE.aparch11.1.t.fcst = ugarchforecast(VALE.aparch11.1.t.fit, n.ahead=250)
```

Ploto os gráficos

```{r fig.width=9,fig.height=9}
par(mfrow=c(2,2))

plot(sigma(VALE.garch11.fcst), type="l", col="blue")

plot(sigma(VALE.garch11.t.fcst), type="l", col="blue")

plot(sigma(VALE.aparch11.1.fcst), type="l", col="blue")

plot(sigma(VALE.aparch11.1.t.fcst), type="l", col="blue")
```


Extraio as projeções de volatilidades:

```{r comment=NA}

#VALE.garch11.sigma = as.data.frame(VALE.garch11.fcst)$sigma
#VALE.garch11.t.sigma = as.data.frame(VALE.garch11.t.fcst)$sigma
#VALE.aparch11.1.sigma = as.data.frame(VALE.aparch11.1.fcst)$sigma
#VALE.aparch11.1.t.sigma = as.data.frame(VALE.aparch11.1.t.fcst)$sigma

#ymax = max(VALE.garch11.sigma,VALE.garch11.t.sigma,VALE.aparch11.1.sigma, VALE.aparch11.1.t.sigma)
#ymin = min(VALE.garch11.sigma,VALE.garch11.t.sigma,VALE.aparch11.1.sigma, VALE.aparch11.1.t.sigma)

#plot.ts(VALE.garch11.sigma, main="Projeções de Volatilidades",
 #       ylim=c(ymin,ymax), col="black", 
  #      lwd=2, ylab="sigma(t+h|t)", xlab="h")
#lines(VALE.garch11.t.sigma, col="blue", lwd=2)
#lines(VALE.aparch11.1.sigma, col="green", lwd=2)
#lines(VALE.aparch11.1.t.sigma, col="red", lwd=2)
#legend(x="topleft", legend=c("GARCH-n", "GARCH-t", "APARCH-n", "APARCH-t"),
 #      col=c("black", "blue","green","red"), lwd=2, lty = "solid")

```


Reajusta os modelos, deixando 100 observações fora da amostra para estatísticas de avaliação de previsão

```{r comment=NA}
VALE.garch11.fit = ugarchfit(spec=garch11.spec, data=VALE.ret,
                             out.sample=100)
VALE.garch11.t.fit = ugarchfit(spec=garch11.t.spec, data=VALE.ret,
                               out.sample=100)
VALE.aparch11.1.fit = ugarchfit(aparch11.1.spec, VALE.ret,
                                out.sample=100)
VALE.aparch11.1.t.fit = ugarchfit(spec=aparch11.1.t.spec, data=VALE.ret,
                                  out.sample=100)
```



Compara a persistência com a variância incondicional:

```{r comment=NA}
c.mat = matrix(0, 4, 2)
colnames(c.mat) = c("Persistence", "E[sig(t)]")
rownames(c.mat) = c("GARCH-n", "GARCH-t", "APARCH-n","APARCH-t")
c.mat["GARCH-n","Persistence"] = persistence(VALE.garch11.fit)
c.mat["GARCH-t","Persistence"] = persistence(VALE.garch11.t.fit)
c.mat["APARCH-n","Persistence"] = persistence(VALE.aparch11.1.fit)
c.mat["APARCH-t","Persistence"] = persistence(VALE.aparch11.1.t.fit)

c.mat["GARCH-n","E[sig(t)]"] = sqrt(uncvariance(VALE.garch11.fit))
c.mat["GARCH-t","E[sig(t)]"] = sqrt(uncvariance(VALE.garch11.t.fit))
c.mat["APARCH-n","E[sig(t)]"] = sqrt(uncvariance(VALE.aparch11.1.fit))
c.mat["APARCH-t","E[sig(t)]"] = sqrt(uncvariance(VALE.aparch11.1.t.fit))

c.mat
```



Finaliza computando 100 previsões dinâmicas 1 passo à frente:

```{r comment=NA}
VALE.garch11.fcst = ugarchforecast(VALE.garch11.fit, n.roll=100, n.ahead=1)
VALE.garch11.t.fcst = ugarchforecast(VALE.garch11.t.fit, n.roll=100, n.ahead=1)
VALE.aparch11.1.fcst = ugarchforecast(VALE.aparch11.1.fit, n.roll=100, n.ahead=1)
VALE.aparch11.1.t.fcst = ugarchforecast(VALE.aparch11.1.t.fit, n.roll=100, n.ahead=1)
```

Vamos ver os resultados para os retornos esperados pelos 4 modelos ajustados:

```{r comment=NA}
VALE.garch11.fcst

VALE.garch11.t.fcst

VALE.aparch11.1.fcst

VALE.aparch11.1.t.fcst

```

Com os dados observados, comparamos o de melhor ajuste:


```{r comment=NA}
# Obtem comparativo de previsao estatistica
fcst.list = list(garch11=VALE.garch11.fcst,
                 garch11.t=VALE.garch11.t.fcst,
                 aparch11.1=VALE.aparch11.1.fcst,
                 aparch11.t.1=VALE.aparch11.1.t.fcst)
fpm.mat = sapply(fcst.list, fpm)
fpm.mat
```
















*** 

### Referências

Graves, Spencer. 2014. **_FinTS: Companion to Tsay (2005) Analysis of Financial Time Series._** https://CRAN.R-project.org/package=FinTS.

Ghalanos, Alexios. 2015. **_Rugarch: Univariate Garch Models._** https://CRAN.R-project.org/package=rugarch.


