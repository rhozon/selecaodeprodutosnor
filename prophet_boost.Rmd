---
title: "Forecasting de séries temporais com algoritmos de machine learning"
author: "Rodrigo Hermont Ozon"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: true
    toc_float: true
params:
  symbol1: CORN
  symbol2: CN21.CBT
  symbol3: Cz21.CBT
  symbol4: CU21.CBT
  symbol5: CH22.CBT
  symbol6: CK22.CBT
  symbol7: ZC=F
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE,
	comment = NA
)
knitr::opts_chunk$set(comment = NA) # Remove todos os coments # dos outputs do R
knitr::opts_chunk$set(warning = FALSE) # Remove todos os warnings # dos outputs do R
knitr::opts_chunk$set(message = FALSE) # Remove todas as mensagens # dos outputs do R

```


***

<style>
p.comment {
background-color: #DBDBDB;
padding: 10px;
border: 1px solid black;
margin-left: 25px;
border-radius: 5px;
font-style: italic;
}

</style>

<div class="alert alert-info">

  <strong>Economic Time Series Forecasting</strong> 
 
</div>



<p >
<p style="font-family: times, serif; font-size:11pt; font-style:italic"; class="comment">

Este post explora um teste com o pacote modeltime para forecasting de séries temporais combinando algoritmos de machine learning.

</p>




***

<p >
<p style="font-family: times, serif; font-size:10pt; font-style:italic"; class="quote">

Anunciai-nos as coisas que ainda hão de vir, para que saibamos que sois deuses; ou fazei bem, ou fazei mal, para que nos assombremos, e juntamente o vejamos.

Isaías 41:23

</p>

***

![](https://rhozon.github.io/site/me.jpg)

```{r echo=FALSE}

# Libraries
library(igraph)
library(networkD3)
library(dplyr)

# A = Economia
# B = Econometria
# C = Microeconometria
# D = Modelos preditivos
# E = Métodos estatísticos
# K = Data Viz
# M = Data Science
# Z = Linguagem R
# Y = Séries Temporais (forecasting)


# create a dataset:
data <- data_frame(
  from=c("Economia", "Economia", "Econometria", "Modelos preditivos", "Microeconometria", "Modelos preditivos", "Métodos estatísticos", "Econometria", "Microeconometria", "Modelos preditivos", "Data Viz", "Economia", "Data Science", "Séries Temporais (forecasting)"),
  
  to=c("Econometria", "Métodos estatísticos", "Analytics", "Economia", "Microeconometria", "Economia", "Econometria", "Linguagem R", "Economia", "Microeconometria", "Economia", "Econometria", "Data Viz", "Econometria")
)

# Plot
p <- simpleNetwork(data, height="100px", width="100px",        
        Source = 1,                 # column number of source
        Target = 2,                 # column number of target
        linkDistance = 10,          # distance between node. Increase this value to have more space between nodes
        charge = -900,                # numeric value indicating either the strength of the node repulsion (negative value) or attraction (positive value)
        fontSize = 14,               # size of the node names
        fontFamily = "serif",       # font og node names
        linkColour = "#666",        # colour of edges, MUST be a common colour for the whole graph
        nodeColour = "#69b3a2",     # colour of nodes, MUST be a common colour for the whole graph
        opacity = 0.9,              # opacity of nodes. 0=transparent. 1=no transparency
        zoom = T                    # Can you zoom on the figure?
        )

p


```


***


<center>

<p >
<p style="font-family: times, serif; font-size:11pt; font-style:italic"; class="comment">

<iframe width="560" height="315" src="https://www.youtube.com/embed/BuvrrjXaRaQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

</p>

</center>

***

$$\\[1in]$$


***

Carrego as bibliotecas necessárias


```{r}

library(xgboost)
library(earth)
library(tidymodels)
library(modeltime)
library(modeltime.ensemble)
library(tidyverse)
library(lubridate)
library(timetk)
library(quantmod)
library(tsibble)
library(tsibbledata)
library(dplyr)
library(tidyverse)
library(data.table)
library(tidyr)
library(TSstudio)
library(h2o)

```


# Baixo os dados e separo amostra de treino

Utilizarei novamente os mesmos dados das cotações do milho ``CORN`` negociados na bolsa de Chicago:

```{r}

CORN <- getSymbols("CORN", auto.assign = FALSE,
                   from = "1994-01-01", end = Sys.Date())
glimpse(CORN)

periodicity(CORN)

```

```{r}

CORN <- CORN %>%
  as.data.table() %>%
  as_tibble()

class(CORN)

glimpse(CORN)



```

```{r}

CORN %>%
  plot_time_series(index, CORN.Close, .interactive = FALSE)

```

# Separa a série temporal numa proporção 70/30

```{r}

splits <- initial_time_split(CORN, prop = 0.8)

```

# Estimando os modelos univariados contra o tempo

Os modelos aqui testados são 14, sendo que eles contemplam:

+ Família ARIMA e com erros XGBoost;

+ Ajuste/Alisamento Exponencial e com ajustes sazonais e também modelo Croston e Theta

+ TBATS;

+ ``prophet`` e ``prophet_xgboost``

+ Naive e SNaive

+ Rede Neural Artificial com componente Auto Regressivo

```{r}

# Modelo 1: auto_arima ----
model_fit_arima_no_boost <- arima_reg() %>%
  set_engine(engine = "auto_arima") %>%
  fit(CORN.Close ~  index, 
      data = training(splits))

```

```{r}

# Modelo 2: arima_boost ----
model_fit_arima_boosted <- arima_boost(
  min_n = 2,
  learn_rate = 0.9
) %>%
  set_engine(engine = "auto_arima_xgboost") %>%
  fit(CORN.Close ~ index,
      data = training(splits))

```

```{r}

# Modelo 3: ets ----
model_fit_ets <- exp_smoothing() %>%
  set_engine(engine = "ets") %>%
  fit(CORN.Close ~  index, 
      data = training(splits))

```

```{r}

# Modelo 4: tbats ----
model_fit_tbats <- seasonal_reg() %>%
  set_engine(engine = "tbats") %>%
  fit(CORN.Close ~ index,
      data = training(splits))

```

```{r}

# Modelo 5: prophet xgb ----
model_fit_prophet_xb <- prophet_boost(
  learn_rate = 0.8 ) %>%
  set_engine("prophet_xgboost") %>%
  fit(CORN.Close ~  index,
      data = training(splits))

```


```{r}

# Modelo 6: stlm_ets  ----
model_fit_stlm_ets <- seasonal_reg() %>%
  set_engine("stlm_ets") %>%
  fit(CORN.Close ~  index,
      data = training(splits))

```


```{r}

# Modelo 7: stlm arima  ----
model_fit_stlm_arima <- seasonal_reg() %>%
  set_engine("stlm_arima") %>%
  fit(CORN.Close ~  index,
      data = training(splits))

```

```{r}

# Modelo 8: arima xgb padrao  ----
model_fit_arima_padrao <-arima_boost(
                        # Padroes p, d, q
                        seasonal_period = 7,
                        non_seasonal_ar = 5,
                        non_seasonal_differences = 1,
                        non_seasonal_ma = 3,
                        seasonal_ar = 1,
                        seasonal_differences = 0,
                        seasonal_ma = 1,
                        # XGBoost 
                        tree_depth = 6,
                        learn_rate = 0.8
) %>%
  set_engine("arima_xgboost") %>%
  fit(CORN.Close ~  index,
      data = training(splits))

```


```{r}

# Modelo 9: ets padrao  ----
model_fit_ets_padrao <- exp_smoothing(
                        seasonal_period = 7, # padrao de 7 dias de trade
                        error = "multiplicative",
                        trend = "additive",
                        season = "multiplicative"
) %>%
  set_engine("ets") %>%
  fit(CORN.Close ~  index,
      data = training(splits))

```


```{r}

# Modelo 10: ets croston  ----
model_fit_ets_croston <- exp_smoothing(
  smooth_level = 0.2
) %>%
  set_engine("croston") %>%
  fit(CORN.Close ~  index,
      data = training(splits))

```


```{r}

# Modelo 11: ets theta  ----
model_fit_ets_theta <- exp_smoothing(
) %>%
  set_engine("theta") %>%
  fit(CORN.Close ~  index,
      data = training(splits))

```


```{r}

# Modelo 12: naive  ----
model_fit_naive <- naive_reg(
) %>%
  set_engine("naive") %>%
  fit(CORN.Close ~  index,
      data = training(splits))

```


```{r}

# Modelo 13: snaive  ----
model_fit_snaive <- naive_reg(
                      seasonal_period = 7
) %>%
  set_engine("snaive") %>%
  fit(CORN.Close ~  index,
      data = training(splits))

```


```{r}

# Modelo 14: rede neural autoregressiva  ----
model_fit_nnetar <-  nnetar_reg(
) %>%
set_engine("nnetar")

set.seed(123) 
model_fit_nnetar <- model_fit_nnetar %>%
  fit(CORN.Close ~  index,
      data = training(splits))

```



# Comparativo de perfomance preditiva

Avalio o ajuste de cada método para a mesma amostra da série temporal:


```{r}

models_tbl <- modeltime_table(

  # -- Modelo --                           -- Numero --
  
  model_fit_arima_no_boost,                 # Modelo 1
  model_fit_arima_boosted,                  # Modelo 2
  model_fit_ets,                            # Modelo 3
  model_fit_tbats,                          # Modelo 4
  model_fit_prophet_xb,                     # Modelo 5
  model_fit_stlm_ets,                       # Modelo 6
  model_fit_stlm_arima,                     # Modelo 7
  model_fit_arima_padrao,                   # Modelo 8
  model_fit_ets_padrao,                     # Modelo 9
  model_fit_ets_croston,                    # Modelo 10
  model_fit_ets_theta,                      # Modelo 11
  model_fit_naive,                          # Modelo 12
  model_fit_snaive,                         # Modelo 13
  model_fit_nnetar                          # Modelo 14

  ) 

models_tbl

```



## Compara a acurácia



```{r}

models_tbl %>%
  modeltime_calibrate(new_data = testing(splits)) %>%
  modeltime_accuracy(
  metric_set = metric_set(
    mape,
    smape,
    mae, 
    rmse,
    rsq # R^2
    )
)

```

Veremos o modelo ``prophet`` p. ex.:

```{r}

list(model_fit_prophet_xb) %>%
    as_modeltime_table()

```



## Calibração dos modelos



```{r}

calibration_tbl <- models_tbl %>%
  modeltime_calibrate(new_data = testing(splits), quiet = FALSE)

calibration_tbl

```


## Projeção (forecasting)


```{r}

calibration_tbl %>%
    modeltime_forecast(
        new_data    = testing(splits),
        actual_data = CORN
    ) %>%
    plot_modeltime_forecast(
      .legend_max_width = 25, # For mobile screens
      .interactive      = TRUE
    )
```


## Modelo combinado de projeção


O modelo do tipo ``ensemble`` é um modelo misto com os pesos ajustados pela acurácia de cada um dos 14 univariados estimados até aqui

```{r}

# Modelo 15: ensemble  ----
model_fit_ensemble <- models_tbl %>%
  ensemble_weighted(
    loadings = c
    (
      
#-- Peso --       # -- Modelo --
      
     1,           # Modelo 1
     2,           # Modelo 2
     5,           # Modelo 3
     6,           # Modelo 4
     10,          # Modelo 5
     9,           # Modelo 6
     8,           # Modelo 7 
     1,           # Modelo 8
     7,           # Modelo 9
     2,           # Modelo 10  
     2,           # Modelo 11 
     2,           # Modelo 12 
     1,           # Modelo 13 
     10           # Modelo 14 
      
      ),
    scale_loadings = TRUE
  )

model_fit_ensemble

```


Construimos a projeção com o modelo misto:


```{r fig.width=9}

# Calibragem

calibration_tbl <- modeltime_table(
    model_fit_ensemble
) %>%
    modeltime_calibrate(testing(splits), quiet = FALSE)

# Forecast vs amostra de teste (dados originais pra frente antes do corte pra amostra treino)

calibration_tbl %>%
    modeltime_forecast(
        new_data    = testing(splits),
        actual_data = CORN
    ) %>%
    plot_modeltime_forecast(.interactive = TRUE)

```


## Reamostragens


A reamostragem de séries temporais é uma estratégia importante para avaliar a estabilidade dos modelos ao longo do tempo. No entanto, é um tanto quanto penoso fazer isso, pois requer vários _loops for_ para gerar as previsões para vários modelos e, potencialmente, vários grupos de séries temporais. 

```{r}

resamples_tscv <- training(splits) %>%
    time_series_cv(
                  assess = "2 years",
                  initial = "5 years",
                  skip = "1 years",
# Normally we do more than one slice, but this speeds up the example
slice_limit = 1
)
# Fit and generate resample predictions
model_fit_ensemble_resample <- calibration_tbl %>%
modeltime_fit_resamples(
            resamples = resamples_tscv,
            control = control_resamples(verbose = TRUE)
)
# A new data frame is created from the Modeltime Table
# with a column labeled, '.resample_results'
model_fit_ensemble_resample

```

Plota o gráfico

```{r eval=FALSE}

model_fit_ensemble_resample %>%
  plot_modeltime_resamples(.interactive = TRUE)

```


## Revisão das projeções (forecast forward)


Constrói a projeção para fora da amostra desde a última observação para os próximos 24 meses:

```{r fig.width=9}

refit_tbl <- calibration_tbl %>%
    modeltime_refit(data = CORN)

refit_tbl %>%
    modeltime_forecast(h = "2 years", actual_data = CORN) %>%
    plot_modeltime_forecast(
      .legend_max_width = 25, # For mobile screens
      .interactive      = TRUE
    )

```


***

# Estimativa dos modelos bivariados do tipo preço x volume (fluxo de oferta e demanda)

Na forma bivariada inserimos o volume de negociação como variável explicativa, ainda mesmo que esperando uma performance estatística inferior, sabemos que pelo princípio econômico, a volatilidade é facilmente capturada ao observarmos os picos de volume negociados diariamente.


```{r}

# Modelo 1: auto_arima ----
model_fit_arima_no_boost_biv <- arima_reg() %>%
  set_engine(engine = "auto_arima") %>%
  fit(CORN.Close ~ CORN.Volume + index, 
      data = training(splits))

```


```{r}

# Modelo 2: arima_boost ----
model_fit_arima_boosted_biv <- arima_boost(
  min_n = 2,
  learn_rate = 0.9
) %>%
  set_engine(engine = "auto_arima_xgboost") %>%
  fit(CORN.Close ~ CORN.Volume + index,
      data = training(splits))

```


```{r }

# Modelo 3: ets ----
model_fit_ets_biv <- exp_smoothing() %>%
  set_engine(engine = "ets") %>%
  fit(CORN.Close ~ CORN.Volume + index, 
      data = training(splits))

```


```{r }

# Modelo 4: tbats ----
model_fit_tbats_biv <- seasonal_reg() %>%
  set_engine(engine = "tbats") %>%
  fit(CORN.Close ~ CORN.Volume + index,
      data = training(splits))

```


```{r }

# Modelo 5: prophet xgb ----
model_fit_prophet_xb_biv <- prophet_boost(
  learn_rate = 0.8 ) %>%
  set_engine("prophet_xgboost") %>%
  fit(CORN.Close ~  CORN.Volume + index,
      data = training(splits))

```


```{r }

# Modelo 6: stlm_ets  ----
model_fit_stlm_ets_biv <- seasonal_reg() %>%
  set_engine("stlm_ets") %>%
  fit(CORN.Close ~  CORN.Volume + index,
      data = training(splits))

```


```{r }

# Modelo 7: stlm arima  ----
model_fit_stlm_arima_biv <- seasonal_reg() %>%
  set_engine("stlm_arima") %>%
  fit(CORN.Close ~  CORN.Volume + index,
      data = training(splits))

```


```{r }

# Modelo 8: arima xgb padrao  ----
model_fit_arima_padrao_biv <-arima_boost(
                        # Padroes p, d, q
                        seasonal_period = 7,
                        non_seasonal_ar = 5,
                        non_seasonal_differences = 1,
                        non_seasonal_ma = 3,
                        seasonal_ar = 1,
                        seasonal_differences = 0,
                        seasonal_ma = 1,
                        # XGBoost 
                        tree_depth = 6,
                        learn_rate = 0.8
) %>%
  set_engine("arima_xgboost") %>%
  fit(CORN.Close ~  CORN.Volume + index,
      data = training(splits))

```


```{r }

# Modelo 9: ets padrao  ----
model_fit_ets_padrao_biv <- exp_smoothing(
                        seasonal_period = 7, # padrao de 7 dias de trade
                        error = "multiplicative",
                        trend = "additive",
                        season = "multiplicative"
) %>%
  set_engine("ets") %>%
  fit(CORN.Close ~  CORN.Volume + index,
      data = training(splits))

```


```{r }

# Modelo 10: ets croston  ----
model_fit_ets_croston_biv <- exp_smoothing(
  smooth_level = 0.2
) %>%
  set_engine("croston") %>%
  fit(CORN.Close ~ CORN.Volume + index,
      data = training(splits))

```


```{r }

# Modelo 11: ets theta  ----
model_fit_ets_theta_biv <- exp_smoothing(
) %>%
  set_engine("theta") %>%
  fit(CORN.Close ~ CORN.Volume + index,
      data = training(splits))

```


```{r }

# Modelo 12: naive  ----
model_fit_naive_biv <- naive_reg(
) %>%
  set_engine("naive") %>%
  fit(CORN.Close ~ CORN.Volume + index,
      data = training(splits))

```


```{r }

# Modelo 13: snaive  ----
model_fit_snaive_biv <- naive_reg(
                      seasonal_period = 7
) %>%
  set_engine("snaive") %>%
  fit(CORN.Close ~  CORN.Volume + index,
      data = training(splits))

```


```{r }

# Modelo 14: rede neural autoregressiva  ----
model_fit_nnetar_biv <-  nnetar_reg(
) %>%
set_engine("nnetar")

set.seed(123) 
model_fit_nnetar_biv <- model_fit_nnetar_biv %>%
  fit(CORN.Close ~  CORN.Volume + index,
      data = training(splits))

```



# Comparativo de perfomance preditiva (bivariado)

Avalio o ajuste de cada método para a mesma amostra da série temporal:


```{r}

models_tbl_bivariada <- modeltime_table(

  # -- Modelo --                                -- Numero --
  
  model_fit_arima_no_boost_biv,                 # Modelo 1
  model_fit_arima_boosted_biv,                  # Modelo 2
  model_fit_ets_biv,                            # Modelo 3
  model_fit_tbats_biv,                          # Modelo 4
  model_fit_prophet_xb_biv,                     # Modelo 5
  model_fit_stlm_ets_biv,                       # Modelo 6
  model_fit_stlm_arima_biv,                     # Modelo 7
  model_fit_arima_padrao_biv,                   # Modelo 8
  model_fit_ets_padrao_biv,                     # Modelo 9
  model_fit_ets_croston_biv,                    # Modelo 10
  model_fit_ets_theta_biv,                      # Modelo 11
  model_fit_naive_biv,                          # Modelo 12
  model_fit_snaive_biv,                         # Modelo 13
  model_fit_nnetar_biv                          # Modelo 14

  ) 

models_tbl_bivariada

```



## Compara a acurácia (bivariado)

Tabela de avaliação da acurácia dos modelos bivariados no tempo:

```{r}

models_tbl_bivariada %>%
  modeltime_calibrate(new_data = testing(splits)) %>%
  modeltime_accuracy(
  metric_set = metric_set(
    mape,
    smape,
    mae, 
    rmse,
    rsq # R^2
    )
)

```

Veremos o modelo ``prophet`` p. ex.:

```{r}

list(model_fit_prophet_xb) %>%
    as_modeltime_table()

```



## Calibração dos modelos (bivariado)


```{r}

calibration_tbl_bivariada <- models_tbl %>%
  modeltime_calibrate(new_data = testing(splits), quiet = FALSE)

calibration_tbl_bivariada

```

## Projeção (forecasting) (bivariado)


```{r}

calibration_tbl_bivariada %>%
    modeltime_forecast(
        new_data    = testing(splits),
        actual_data = CORN
    ) %>%
    plot_modeltime_forecast(
      .legend_max_width = 25, # For mobile screens
      .interactive      = TRUE
    )
```


## Modelo combinado de projeção (bivariado)

O modelo do tipo ``ensemble`` é um modelo misto com os pesos ajustados pela acurácia de cada um dos 14 univariados estimados até aqui

```{r}

# Modelo 15: ensemble  ----
model_fit_ensemble_bivariada <- models_tbl_bivariada %>%
  ensemble_weighted(
    loadings = c
    (
      
#-- Peso --       # -- Modelo --
      
     1,           # Modelo 1
     10,          # Modelo 2
     5,           # Modelo 3
     6,           # Modelo 4
     10,          # Modelo 5
     9,           # Modelo 6
     8,           # Modelo 7 
     10,          # Modelo 8
     7,           # Modelo 9
     2,           # Modelo 10  
     2,           # Modelo 11 
     2,           # Modelo 12 
     1,           # Modelo 13 
     6            # Modelo 14 
      
      ),
    scale_loadings = TRUE
  )

model_fit_ensemble_bivariada

```


Construimos a projeção com o modelo misto:

```{r fig.width=9}

# Calibragem

calibration_tbl_bivariada <- modeltime_table(
    model_fit_ensemble_bivariada
) %>%
    modeltime_calibrate(testing(splits), quiet = FALSE)

# Forecast vs amostra de teste (dados originais pra frente antes do corte pra amostra treino)

calibration_tbl_bivariada %>%
    modeltime_forecast(
        new_data    = testing(splits),
        actual_data = CORN
    ) %>%
    plot_modeltime_forecast(.interactive = TRUE)

```

## Reamostragens (bivariado)

A reamostragem de séries temporais é uma estratégia importante para avaliar a estabilidade dos modelos ao longo do tempo. No entanto, é um tanto quanto penoso fazer isso, pois requer vários _loops for_ para gerar as previsões para vários modelos e, potencialmente, vários grupos de séries temporais. 

```{r }

resamples_tscv <- training(splits) %>%
    time_series_cv(
                  assess = "2 years",
                  initial = "5 years",
                  skip = "1 years",

slice_limit = 1
)

# Fit and generate resample predictions

model_fit_ensemble_resample_bivariada <- calibration_tbl_bivariada %>%
modeltime_fit_resamples(
            resamples = resamples_tscv,
            control = control_resamples(verbose = TRUE)
)
# A new data frame is created from the Modeltime Table
# with a column labeled, '.resample_results'

model_fit_ensemble_resample_bivariada

```



## Revisão das projeções (forecast forward) (bivariado)

Constrói a projeção para fora da amostra desde a última observação para os próximos 24 meses:

```{r  fig.width=9, eval=FALSE}

refit_tbl_bivariada <- calibration_tbl_bivariada %>%
    modeltime_refit(data = CORN)

refit_tbl_bivariada %>%
    modeltime_forecast(h = "2 years", actual_data = CORN) %>%
    plot_modeltime_forecast(
      .legend_max_width = 25, # For mobile screens
      .interactive      = TRUE
    )

```




# Modelo bivariado combinado

Seleciono somente alguns modelos que julguei como melhor ajuste:

```{r eval=FALSE}

models_tbl_selecao <- modeltime_table(

  # -- Modelo --                                -- Numero --
  
  model_fit_arima_no_boost_biv,                 # Modelo 1
  model_fit_arima_boosted_biv,                  # Modelo 2
  model_fit_prophet_xb_biv,                     # Modelo 5
  model_fit_arima_padrao_biv,                   # Modelo 8

  ) 

models_tbl_selecao

```


Fazemos a calibração

```{r eval=FALSE}

calibration_tbl_selecao <- models_tbl_selecao %>%
  
  modeltime_calibrate(new_data = testing(splits), quiet = FALSE)


calibration_tbl_selecao

```


Criamos o ensemble:

```{r eval=FALSE}

model_fit_ensemble_selecao <- models_tbl_selecao %>%
  
  ensemble_average(type = "mean")

```

Construimos a projeção com o modelo misto:

```{r eval=FALSE}

# Calibragem

calibration_tbl_selecao <- modeltime_table(
    model_fit_ensemble_selecao
) %>%
    modeltime_calibrate(testing(splits), quiet = FALSE)

# Forecast vs amostra de teste (dados originais pra frente antes do corte pra amostra treino)

calibration_tbl_selecao %>%
    modeltime_forecast(
        new_data    = testing(splits),
        actual_data = CORN
    ) %>%
    plot_modeltime_forecast(.interactive = TRUE)

```


# AutoML com o pacote ``h2o``

O pacote ``h2o`` possui uma implementação automática de recomendação de modelo preditivo para os dados que o separamos.


``H2o`` é uma biblioteca de código aberto, distribuída e baseada em Java para aplicações de machine learning. Ele tem APIs para R (o pacote ``h2o``) e Python, e inclui aplicativos para modelos de aprendizagem supervisionados e não supervisionados. Isso inclui algoritmos como deep learning (DL), Gradient Boost Machine(GBM), XGBoost, Random Forest Distribuída (RF) e o Modelo Linear Generalizado (GLM).

A principal vantagem do pacote ``h2o`` é que ele se baseia em processamento distribuído e, portanto, pode ser usado na memória ou ampliado com o uso de computação externa potência. Além disso, os algoritmos do pacote ``h2o`` fornecem vários métodos para que possamos treinar e ajustar modelos de aprendizado de máquina, como o método de validação cruzada e a função grid search integrada.

O pacote ``h2o`` é baseado no uso de computação distribuída e paralela para acelerar o tempo de computação e possibilita escalonar para big data. Tudo isso é feito em qualquer parte da memória (com base na RAM interna do computador) ou processamento paralelo distribuído (para exemplo, AWS, Google Cloud e assim por diante) clusters. Portanto, vamos carregar o pacote e em seguida, definir o cluster na memória com a função ``h2o.init``:

```{r}

h2o.init(max_mem_size = "16G")

```


O comando ``h2o.init`` permite que você defina o tamanho da memória do cluster com o argumento ``max_mem_size``. A saída da função, conforme mostrado no código anterior, fornece informações sobre a configuração do cluster.

Quaisquer dados usados em todo o processo de treinamento e teste dos modelos pelo pacote ``H2o`` deve ser carregado no próprio cluster. A função ``as.h2o`` nos permite transformar qualquer objeto ``data.frame`` em um cluster ``h2o``:

```{r}

CORN <- getSymbols("CORN", auto.assign = FALSE,
                   from = "1994-01-01", end = Sys.Date())

# Convete para tsibble
CORN <- CORN %>%
  as.data.table() %>%
  as_tsibble()

# Separa treino

treino <- CORN %>%
  filter_index(~"2020-06") # Amostra de treino ate junho 2020

# Retiro os gaps implícitos
CORN <- CORN %>%
  fill_gaps() %>%
  fill(c(CORN.Open, CORN.High, CORN.Low, CORN.Close, CORN.Volume, CORN.Adjusted), .direction = "down") 
print(CORN)

# Separo treino sem gaps implicitos

treino <- treino %>%
  fill_gaps() %>%
  fill(c(CORN.Open, CORN.High, CORN.Low, CORN.Close, CORN.Volume, CORN.Adjusted), .direction = "down")
print(treino)

treino <- as.h2o(treino)

teste <- CORN %>%
  filter_index("2020-06" ~ .) 

teste <- as.h2o(teste)

```

Em seguida rodaremos o autoML para duas configurações:

+ univariada $\rightarrow$ CORN.Close no tempo;

+ bivariada $\rightarrow$ CORN.Close $x$ CORN.Volume no tempo;


A função ``h2o.automl`` fornece uma abordagem de sistema automatizada para treinar, ajustar e testar vários algoritmos de ML antes de selecionar o modelo com melhor desempenho com base nas métricas de avaliação. Ele utiliza algoritmos como RF, GBM, DL e outros usando diferentes abordagens de ajuste.

```{r}

autoML_univariada <- h2o.automl(training_frame = treino,
                      y = "CORN.Close",
                      nfolds = 5,
                      max_runtime_secs = 60*20,
                      seed = 1234)

autoML_univariada@leaderboard

autoML_bivariada <- h2o.automl(training_frame = treino,
                      y = "CORN.Close",
                      x = "CORN.Volume",
                      nfolds = 5,
                      max_runtime_secs = 60*20,
                      seed = 1234)

autoML_bivariada@leaderboard

```


Você pode ver que, neste caso, os modelos de topo são modelos os modelos sugeridos com diferentes configurações de tunelamento. Selecionaremos o modelo líder e testaremos seu desempenho no conjunto de teste:



```{r}

teste$pred_autoML_univariada <- h2o.predict(autoML_univariada@leader, teste)

teste_univariada <- as.data.frame(teste)

mape_autoML_univariada <- mean(abs(teste_univariada$CORN.Close - teste_univariada$pred_autoML_univariada) / teste_univariada$CORN.Close)
mape_autoML_univariada

teste$pred_autoML_bivariada <- h2o.predict(autoML_bivariada@leader, teste)

teste_bivariada <- as.data.frame(teste)

mape_autoML_bivariada <- mean(abs(teste_bivariada$CORN.Close - teste_bivariada$pred_autoML_bivariada) / teste_bivariada$CORN.Close)
mape_autoML_bivariada

```



















[continuar escrevendo...]





&nbsp;



&nbsp;

*** 

# Referências


Business Science in R bloggers **Introducing Modeltime Recursive: Tidy Autoregressive Forecasting with Lags**, Disponível em: https://www.r-bloggers.com/2021/04/introducing-modeltime-recursive-tidy-autoregressive-forecasting-with-lags/

Business Science in R bloggers **Introducing Modeltime: Tidy Time Series Forecasting using Tidymodels**, Disponível em: https://www.r-bloggers.com/2020/06/introducing-modeltime-tidy-time-series-forecasting-using-tidymodels/

Business Science, Github, **Ensemble Algorithms for Time Series Forecasting with Modeltime**, Disponível em: https://business-science.github.io/modeltime.ensemble/ acesso em junho de 2021.

CRAN, **Getting Started with Modeltime**, Disponível em: https://cran.r-project.org/web/packages/modeltime/vignettes/getting-started-with-modeltime.html

CRAN, **Package ‘modeltime’**, Disponível em: https://cran.r-project.org/web/packages/modeltime/modeltime.pdf junho de 2021.

CRAN, **Package ‘modeltime.ensemble’** Disponível em: https://cran.r-project.org/web/packages/modeltime.ensemble/modeltime.ensemble.pdf junho de 2021.

CRAN, **Package ‘modeltime.resample’** Disponível em: https://cran.r-project.org/web/packages/modeltime.resample/modeltime.resample.pdf junho de 2021.

Github, **Ensemble Algorithms for Time Series Forecasting with Modeltime**, Disponível em: https://github.com/business-science/modeltime.ensemble acesso em junho de 2021.

HANSEN, B. **Econometrics**, University of Wisconsin, Department of Economics. Disponível em: https://www.ssc.wisc.edu/~bhansen/econometrics/Econometrics.pdf March 11, 2021.

USAI, D. **Time Series Machine Learning Analysis and Demand Forecasting with H2O & TSstudio**, Disponível em: https://rpubs.com/DiegoUsai/565288

***

&nbsp;



