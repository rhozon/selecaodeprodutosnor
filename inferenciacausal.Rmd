---
title: "Inferência Causal na Economia"
author: "Rodrigo H. Ozon"
date: "21/09/2020"
output:
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


<!-- ================================================================================= -->

***

#### **Resumo**

<small>Este tutorial busca aplicar alguns dos conceitos de inferência causal em problemas econômicos reais e simulados, utilizando o software R, demonstrando e apresentando suas enormes vantagens em relação ao _data science_, _machine learning_ e até mesmo o _deep learning_.

[A inspiração de escrevê-lo veio ao cursar no coursera.org o ead fornecido pela Columbia University in the City of New York, encabeçado pelo prof. Michael E. Sobel.](https://www.coursera.org/learn/causal-inference)


Como a Economia trata de buscar respostas para problemas mais complexos (e interessantes), vamos _"muito além do simples ajuste de curvas"_ [(parafraseando o prof. Josh Angrist aqui)](https://www.youtube.com/watch?v=2EhRT2mOXm8)

**Palavras-chave:** Inferência Causal, Diff and Diff, Econometria
</small>


***

&nbsp;



# Introdução

***


Quero começar esse tutorial, destacando a principal diferença da Econometria para o _Data Science_ e demais técnicas e métodos. Enfatizo muito aqui o prof. Josh Angrist:


<p style="font-family: times, serif; font-size:11pt; font-style:italic">
"Eu diria que a principal diferença é a abordagem do problema da previsão.
</p>

<p style="font-family: times, serif; font-size:11pt; font-style:italic">
Os cientistas de dados geralmente se preocupam com as abordagens do tipo de ajuste de curva para a previsão. Portanto, qualquer modelo que se adapte bem aos dados servirá. Se é uma experiência passada, podemos estar interessados em usá-la para extrapolar para o futuro.
</p>

<p style="font-family: times, serif; font-size:11pt; font-style:italic">
Grande parte da agenda de ciência de dados está ligada aos problemas de marketing de alguém. Você está tentando descobrir quem comprará algo, quem tomará alguma ação. A econometria, na minha opinião, lida com uma classe de problemas mais difícil.
</p>

<p style="font-family: times, serif; font-size:11pt; font-style:italic">
Econometristas estão mais preocupados com relacionamentos causais. Em outras palavras, se manipularmos algo, por exemplo, seguro de saúde ou política monetária, como será o mundo em resposta a essa mudança? [Josh Angrist in Mastering Econometrics](https://mru.org/courses/mastering-econometrics/whats-difference-between-econometrics-and-data-science) 
</p> 

Como prof. do MIT, o pesquisador Josh Angrist é muito reconhecido no meio científico, sendo muitas vezes citado pelo grande microeconomista e ex-presidente do Google, Hall Varian, p. ex. Veremos sua entrevista onde ele expõe suas contribuições:

&nbsp;

<center>
```{r echo=FALSE}
#https://ijlyttle.github.io/vembedr/
#install.packages("vembedr")
library(htmltools)
library(vembedr)

embed_url("https://www.youtube.com/watch?v=2EhRT2mOXm8")
```
</center>

&nbsp;

<p style="font-family: times, serif; font-size:11pt; font-style:italic">
"É somente através da econometria, a ciência de dados original, que você pode conhecer o caminho da causa ao efeito." (Angrist, 2008)
</p>



Podemos estar interessados em questões causais e não causais:

+ *Descritivo* como a renda varia entre as ocupações ?
+ *Previsão* de qual será o preço do petróleo bruto no próximo ano ?
+ *Causa* se mudarmos a proporção de alunos para professores, as pontuações de aprendizagem melhoram ?

Se estivermos interessados na resposta às questões causais, gostaríamos de usar
inferência. Livros de estatística e econometria costumam variar em quão explícitos são
no tratamento da causalidade. A inferência causal é de grande relevância na ev olução do programa, um domínio que, de acordo com Abadie e Cattaneo (2018, p. 466), é
"_Expandindo as ciências sociais, biomédicas e comportamentais que estudam o efeito de
intervenções políticas. As políticas de interesse são frequentemente programas governamentais, como intervenções ativas do mercado de trabalho ou programas de combate à pobreza_”.

O maravilhoso livro de Morgan e Winship (2014) _Counterfactuals and Causal Inference_
tem a seguinte citação de Gary King na contracapa: "_Tenho aprendido mais sobre inferência causal nas últimas décadas do que a soma total de tudo que tinha sido aprendido sobre isso em toda a história registrada_". Em seu livro Morgan e Winship’s
fazem uso de duas abordagens para inferência causal: (1) resultados potenciais, ou
contrafactuais e (2) gráficos causais. Eles argumentam que estes são complementares,
e usar ambos, como fazem autores como Abadie e Catteneo (2018) p. ex.; e essa é a forma que nós veremos neste tutorial/artigo.

# Gráficos causais e resultados potenciais

Para ilustrar os gráficos causais e as abordagens de resultados potenciais, consideramos um caso de alguns indivíduos que sofrem de dores nas costas. Eles podem levar um remédio para aliviar sua dor.

Denotamos dor por $D$ e medicina por $M$, e os indivíduos são indexados por $i$.
queremos examinar o efeito de $D$ em $P$. $D$ é uma causa: queremos intervir para reduzir dor. Mas é eficaz? Podemos atribuir $D$ aleatoriamente a diferentes indivíduos.

Usaremos o modelo causal estrutural de Pearl et al. (2016) como uma estrutura para
compreender a inferência causal em relação a $D$. O modelo causal estrutural consiste
de um gráfico causal e respectivas equações estruturais que mostram nossas suposições
sobre o fenômeno. Aqui, o gráfico causal é $D\Rightarrow M$ e a equação estrutural
é (assumimos linearidade para simplificar; a abordagem de Pearl não requer a suposição
de linearidade) $D=\beta_{0}+\beta_{M}M+U_{D}$.

Como M é atribuído aleatoriamente, ele é independente de $U_D$. $U_D$ captura as outras causas ou fontes de variação em $D$. A equação estrutural, neste caso, tem uma linha para $M$ e uma linha ou componente para $U_D$. Faremos agora uma simulação. Nós assumimos que $\beta_{0}=10$, $\beta_{M}=-3$ e $U_M\sim N(0,1)$


```{r message=FALSE}
library(tidyverse)
set.seed(22)
beta0 <- 10
betaM <- -3
num <- 400
U_D <- rnorm(num)
```

Geramos o conjunto de dados Meds, que contém as variáveis M, D, U_D.


```{r message=FALSE}
set.seed(3)
M <- sample(c(0,1), num, replace = T)
Indiv <- 1:num
D <- beta0 + betaM * M + U_D
Meds <- tibble(Indiv, M, U_D, D)


library(knitr)
library(kableExtra)

kbl(cbind(round(head(Meds),2))) %>%
  kable_paper() %>%
  scroll_box(width = "200px", height = "200px")%>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

```


&nbsp;

$M\rightarrow D$



$P=\beta_0+\beta_1M+U_D$


Vemos nos dados gerados que o indivíduo 1 é atribuído a M = 0, ou seja, está no
grupo de controle. Observamos que o valor de D para pessoa um, quando atribuído M = 0
é 9,49. No caso do indivíduo 2, o valor de D para a pessoa dois, quando atribuído M
= 1 é 9,49.

Denotamos o resultado potencial para um indivíduo neste caso por $D_{i}(m)$ onde $i$
indexa o indivíduo em é 0 ou 1, dependendo do valor atribuído de M.

A Figura a seguir mostra como o gráfico causal estrutural está relacionado aos resultados potenciais.

Aqui, $P_{1} (0) = 9,49\,\, e\,\, P_{2} (1) = 9,49$. O efeito causal para um indivíduo é: $P_{i}(1) - P_{i}(0)$.


Infelizmente, e isso é chamado de dilema fundamental da inferência causal, nós não observamos ambos os resultados potenciais para um indivíduo. Portanto, não observamos neste caso o valor da dor para a pessoa 1 se caso ela tivesse recebido o medicamento, e a pessoa 2 com dor teria experimentado se ela não tivesse recebido o medicamento. Não observamos o contrafactual.


Temos que nos contentar com um efeito de tratamento médio, a diferença entre a dor
vivenciada pelo grupo de controle e pelo grupo de tratamento, que estimamos a seguir.
Rodamos uma regressão de D em M: $D = r_0 + r_{1}M + e$, sendo a equação de regressão.

A equação de regressão é diferente da equação estrutural. Neste caso, $r_1$ irá
dar-nos uma estimativa próxima do valor verdadeiro, ou do parâmetro estrutural, $\beta_{M}$; isto não é necessariamente o caso de um coeficiente de regressão nos dar uma boa estimativa do efeito causal.

```{r}

modd <- lm(D ~ M, data = Meds)

summary(modd)
```


$$
M|m\rightarrow D(m)
$$
Contrafatuais e resultados potenciais. Quando o valor de M é definido como m, D tem um potencial resultado denotado por D(m)


O coeficiente estimado (−3,1) está próximo do valor de $\beta M (−3)$


<!-- parei em 10.2.2 Randomized Assignment of Treatment (Causal Graphs) -->

# Atribuição aleatória de tratamento (gráficos causais)

Na ausência de atribuição aleatória de tratamento, o nível de medicamento e dor
pode ser influenciado por uma variável de confusão. Tentativas de atribuição aleatória
de garantir que os grupos de tratamento e controle diferem apenas no que diz respeito ao tratamento, tanto no que diz respeito às variáveis observadas como não observadas.

Uma vez que R faz a atribuição aleatória determina o valor de M, ou M é definido por R, o link entre C e M está quebrado. C não atua mais como um fator de confusão.



<center>
![](https://github.com/rhozon/Introdu-o-Econometria-com-Excel/raw/master/cmd.png){ width=30% }
</center>

&nbsp;

Na ausência de atribuição aleatória de M, uma variável C pode ser uma causa comum de M e D, e será uma variável de confusão.



<center>
![](https://github.com/rhozon/Introdu-o-Econometria-com-Excel/raw/master/cmd1.png){ width=30% }

</center>

&nbsp;

Uma vez que R (atribuição aleatória) determina o valor de M, ou M é definido por R, o link entre C e M está quebrado. C não atua mais como um fator de confusão


<small>**Tabela 1:** Resultados potenciais do paciente no exemplo médico perfeito de Rubin</small>

|  |$Y_{po1}$|$Y_{po0}$|$Eff$|   
|---|-------|-------|-------|
| 1 | 14.00 | 13.00 | 1.00  |   
| 2 | 0.00  | 6.00  | -6.00 |   
| 3 | 1.00  | 4.00  | -3.00 |   
| 4 | 2.00  | 5.00  | -3.00 |   
| 5 | 3.00  | 6.00  | -3.00 |   
| 6 | 1.00  | 6.00  | -5.00 |   
| 7 | 10.00 | 8.00  | 2.00  |   
| 8 | 9.00  | 8.00  | 1.00  |   

# Atribuição aleatória de tratamento (resultados potenciais)

Consideramos um exemplo intrigante fornecido por Rubin (2008). Um tratamento, uma cirurgia, que afeta os anos vividos. Deixe Y(0) denotar o resultado potencial sem cirurgia, e Y(1) denotar o resultado potencial com a cirurgia. Para codificação no software R, usamos Y_po0, e Y_po1, respectivamente.

Nós inserimos os dados.

```{r}
Y_po0 <- c(13,6,4,5,6,6,8,8)
Y_po0

Y_po1 <- c(14,0,1,2,3,1,10,9)
Y_po1
```


```{r}
Eff <- Y_po1 - Y_po0
```

Então criamos um dataframe:

```{r}
surg <- data.frame(Y_po1, Y_po0, Eff)
```

Imprimimos os dados para o exemplo médico perfeito (tabela 1 acima)

```{r echo=FALSE, include=FALSE}
library(xtable)
sable <- xtable(surg, caption = "Patient potential outcomes in
Rubin’s perfect doctor example")
print(sable, caption.placement = "top")
```


```{r echo=FALSE, include=FALSE}
library(skimr)
library(xtable)
skim1 <- surg %>%
skim_to_wide()
skimble <- xtable(skim1[,c(2,6)], caption = "Médias")
print(skimble, caption.placement = "top")
```


```{r}
library(knitr)
library(kableExtra)

kbl(cbind(surg)) %>%
  kable_paper() %>%
  scroll_box(width = "200px", height = "200px")%>%
   kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

Neste exemplo, os efeitos variam muito entre as 8 pessoas que são candidatas
para cirurgia. 

<small>**Tabela 2:** Médias</small>

|   | Variável | Média |   |   |
|---|----------|-------|---|---|
| 1 | Eff      | -2    |   |   |
| 2 | Y_po0    | 7     |   |   |
| 3 | Y_po1    | 5     |   |   |

<small>**Tabela 3:** Atribuição de tratamento e resultados observados</small>

|   | D    | Yi    |
|---|------|-------|
| 1 | 1.00 | 14.00 |  
| 2 | 1.00 | 0.00  | 
| 3 | 1.00 | 1.00  |  
| 4 | 1.00 | 2.00  |  
| 5 | 0.00 | 6.00  |  
| 6 | 0.00 | 6.00  |  
| 7 | 0.00 | 8.00  | 
| 8 | 0.00 | 8.00  |  

O verdadeiro efeito causal médio é -2 (Tabela 2). Observe que não podemos observar
ambos os resultados potenciais.

Denotando tratamento por Di, observaremos Yi(0) para a $i-$ésima pessoa se Di = 0, e
da mesma forma para Yi(1). Se denotarmos Y observado para a iª pessoa por Yi, temos

$$
Yi=Di\times Yi(1) + (1-Di)\times Yi(0)
$$


Considere a seguinte atribuição de tratamento:

```{r}
D <- c(rep(1,4), rep(0,4))
```

Os Ys observados com esta atribuição de tratamento são (Tabela 3):

```{r}
Yi <- D*Y_po1 + (1-D)*Y_po0
surg_D <- data.frame(D,Yi)


kbl(cbind(surg_D)) %>%
  kable_paper() %>%
  scroll_box(width = "200px", height = "200px")%>%
   kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
# Atribuição de tratamento e resultados observados
```


Estimamos a diferença de médias entre os grupos de tratamento e controle:

```{r}
lm(Yi ~ D)
```

Vemos que com esta atribuição de tratamento particular D, o efeito de tratamento médio
é -2,75.

Podemos randomizar a atribuição com:

```{r}
sample(D, replace = FALSE)

Atribuicao <- sample(D, replace = FALSE)
Atribuicao
```


Então, o que acontecerá se randomizarmos a atribuição? Nós olhamos para a distribuição de amostragem do efeito estimado usando um loop.

```{r }
iter <- 70
efeito.medio <- numeric(iter)
for(i in 1: iter) {
Atribuicao <- sample(D, replace = FALSE)
Resultado <- Atribuicao*Y_po1 + (1 - Atribuicao)*Y_po0
mod_r <- lm(Resultado ~ Atribuicao)
efeito.medio[i] <- mod_r$coeff[2]
}
round(mean(efeito.medio),2)
```

A média dos diferentes efeitos estimados está próxima do verdadeiro efeito médio (-2).
Nós traçamos a distribuição da amostra.

```{r fig.width=9, fig.height=3}
pdoc <- data.frame(efeito.medio)
ggplot(pdoc, aes(y = efeito.medio)) +
geom_boxplot() +
coord_flip()
```

O boxplot acima mostra a distribuição amostral dos efeitos estimados; o histograma abaixo mostra que a distribuição tem lacunas (_gaps_) e vários picos.

```{r fig.width=9, fig.height=3}
ggplot(pdoc, aes(x = efeito.medio)) +
geom_histogram(fill = "grey50") +
geom_vline(xintercept = quantile(efeito.medio, probs = c(0.25,0.5,0.75)),
linetype = "dashed")
```


### Exercício sugerido

Um médico perfeito, ou um médico com conhecimento perfeito dos resultados potenciais, atribuiria a cirurgia apenas aos pacientes que se beneficiarão com isso. (Claro, se o médico tivesse um conhecimento tão perfeito, não precisaríamos estudar os efeitos da cirurgia nas pessoas.) Qual será o efeito médio da cirurgia se o médico perfeito designar cirurgia ?


# Ajuste covariante

Quais co-variáveis ajustar? Os gráficos causais são chamados de gráficos acíclicos direcionados (DAGS).

De acordo com Elwert (2013, p. 246), "_DAGS são representações visuais de suposições causais._" ... DAGS são ferramentas rigorosas com regras formais para derivar provas matemáticas. E ainda, em muitas situações, o uso de DAGs na prática requer apenas treinamento formal modesto e algum treinamento elementar de probabilidade. DAGs são
portanto, extremamente eficazes para apresentar lições duramente conquistadas de metodologia de pesquisa moderna em uma linguagem compreensível para pesquisadores aplicados. "_Os gráficos causais são particularmente úteis para esclarecer questões de ajuste covariante_". Se $x$ causa $y$ e uma terceira variável está presente, devemos ajustar para a terceira variável em uma regressão de $y$ em $x$? Usamos simulação para responder à pergunta e considerar três casos:

1. $y1$ ← causa comum → $x1$. Aqui, a causa comum variável causa tanto $y1$ e $x1$.
2. $y2$ ← intermediário ← $x2$. Aqui $x2$ causa $y2$ por meio do intermediário variável.
3. $y3$ → colisor ← $x3$. Aqui, $x3$ e $y3$ causam o colisor.

Alguns exemplos de possível causa comum, variáveis intermediárias e de colisor
são:

1. Causa comum. _Mais assassinatos_ ← *Hora* → _Mais antibióticos_.
2. Intermediário. _Doença cardíaca_ ← *Colesterol* ← _Comer comida de baixa qualidade nutricional ou superprocessada._
3. Colisor. _Bateria descarregada_ → *carro não liga* ← _Sem gasolina_.


Nós podemos até acreditar nesses mecanismos, eles podem ou não ser verdadeiros.
Agora nos voltamos para a simulação, começando com o cenário de causa comum: $y1$ ←
causa.comum → $x1$.

```{r}
causa.comum <- runif(100, min = 10, max = 20)
x1 <- 2 * causa.comum + rnorm(100,0,0.5)
y1 <- 2 * causa.comum + rnorm(100,0,0.5)
```


Regredimos (1) y1 em x1 e (2) y1 em x1 e a causa comum.

```{r}
m1 <- lm(y1 ~ x1)
m2 <- lm(y1 ~ x1 + causa.comum)
```

Os resultados são:

&nbsp;

<center>
<small>**Tabela 4:** Causa comum (o efeito verdadeiro de x1 em y1 é 1)</small>

```{r echo=FALSE, results='asis', message = FALSE}
#http://people.virginia.edu/~jcf2d/exercises/getting_started_with_stargazer.html
library(stargazer)
stargazer(m1, m2, type="html", 
          column.labels = c("m1", "m2"), 
          intercept.bottom = FALSE, 
          single.row=FALSE,     
          notes.append = FALSE, 
          header=FALSE) 
```
</center>

&nbsp;


Geramos dados para o cenário de variável intermediária: $y2$ ← _inter_ ← $x2$


```{r}
x2 <- runif(100,min=10,max=20)
inter <- 2 * x2 + rnorm(100,0,0.5)
y2 <- 2 * inter + rnorm(100,0,0.5)
inter1 <- lm(y2 ~ x2)
inter2 <- lm(y2 ~ x2 + inter)
```

<center>
<small>**Tabela 5:** Variável intermediária (o verdadeiro efeito de $x2$ em $y2$ é 4)</small>

```{r echo=FALSE, results='asis', message = FALSE}
#http://people.virginia.edu/~jcf2d/exercises/getting_started_with_stargazer.html
library(stargazer)
stargazer(inter1, inter2, type="html", 
          column.labels = c("inter1", "inter2"), 
          intercept.bottom = FALSE, 
          single.row=FALSE,     
          notes.append = FALSE, 
          header=FALSE) 
```

</center>

&nbsp;

Nesse cenário, não devemos criar controle para a variável intermediária (Tabela 5).

### Exercício proposto

Depois de gerar $y2$, $x2$ e inter com o código acima, regredida $y2$ em $x2$, e $y2$ em $x2$ e inter. O que você observa ?

***

Voltemo-nos agora para o cenário _colisor_

$y$ → _colisor_ ← $x$

```{r}
x3 <- rnorm(100)
y3 <- rnorm(100)
colisor <- 4 * y3 + 4 * x3 + 0.3 * rnorm(100)
```

$y$ → _colisor_ ← $x$

```{r}
m5 <- lm(y3 ~ x3)
m6 <- lm(y3 ~ x3 + colisor)
```

<center>
<small>**Tabela 6:** Colisor (o verdadeiro efeito de $x3$ em $y3$ é 0)</small>

```{r echo=FALSE, results='asis', message = FALSE}
#http://people.virginia.edu/~jcf2d/exercises/getting_started_with_stargazer.html
library(stargazer)
stargazer(m5, m6, type="html", 
          column.labels = c("m5", "m6"), 
          intercept.bottom = FALSE, 
          single.row=FALSE,     
          notes.append = FALSE, 
          header=FALSE) 
```

</center>

&nbsp;


No caso do colisor, não devemos criar controle para o colisor (Tabela 6).

Vemos que 'controlar' nem sempre é bom.

+ **Bom controle** É bom controlar a causa comum.

+ **Controle ruim** O controle das variáveis intermediárias e do colisor é ruim.

Autores como Gelman e Hill (2007) enfatizam que não devemos controlar as variáveis de pós-tratamento. Aqui, mostramos que devemos controlar apenas as variáveis que afetam $x$, e não aquelas afetadas por $x$. No caso de uma variável intermediária, nós
podemos obter o efeito de $y$ no interior e no interior de $x$, e a partir deles obter o efeito de $y$ em $x$. Em certas situações, esta pode ser uma estratégia útil.

# Seleção de regressores por significância estatística

Esta seção procura iluminar o seguinte argumento de Freedman (1983, p. 152):

<p style="font-family: times, serif; font-size:11pt; font-style:italic">
"Quando as equações de regressão são usadas no trabalho empírico, a proporção de pontos de dados para parâmetros é frequentemente baixo; além disso, variáveis com pequenos coeficientes são frequentemente descartadas e as equações reestimadas sem eles. ... Tais práticas podem distorcer os níveis de significância convencionais dos testes estatísticos. A existência desse efeito é bem conhecida, mas sua magnitude pode vir como um surpresa, mesmo para um estatístico experiente."
</p>

Iremos gerar uma variável aleatória $y$ e 10 regressores, nenhum dos quais são causalmente relacionado com $y$.


```{r}
set.seed(80)
x1 <- rnorm(30)
x2 <- rnorm(30)
x3 <- rnorm(30)
x4 <- rnorm(30)
x5 <- rnorm(30)
x6 <- rnorm(30)
x7 <- rnorm(30)
x8 <- rnorm(30)
x9 <- rnorm(30)
x10 <- rnorm(30)
y <- rnorm(30)
mod1 <- lm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10)
mod2 <- lm(y ~ x2 + x10)
```


<center>
<small>**Tabela 7:** Seleção pela significância estatística </small>

```{r echo=FALSE, results='asis', message = FALSE}
#http://people.virginia.edu/~jcf2d/exercises/getting_started_with_stargazer.html
library(stargazer)
stargazer(mod1, mod2, type="html", 
          column.labels = c("mod1", "mod2"), 
          intercept.bottom = FALSE, 
          single.row=FALSE,     
          notes.append = FALSE, 
          header=FALSE) 
```
</center>

&nbsp;



Embora $y$ não esteja relacionado a nenhuma variável $x$, no Modelo 2 da Tabela 7, obtemos um alta significância estatística para o coeficiente de x10.

Com base no Modelo 1 da Tabela 7, selecionamos os regressores x2 e x10:

Embora $y$ não esteja relacionado a nenhuma variável $x$, no Modelo 2 da Tabela 7, obtemos um alta significância estatística para o coeficiente de x10.

### Exercício proposto

Gere seus dados como acima, alterando o valor dentro set.seed() a 999. Execute uma regressão de $y$ nas 10 variáveis $x$. Selecione os três $xs$ mais estatisticamente significativos e execute uma segunda regressão. O que você observa?

*** 

## Exemplo: Mulheres como _policymakers_

Duflo e Chattopadhyay (2004) estudaram o efeito de reservar posições de liderança em Conselhos de Aldeia na Índia sobre os tipos de projetos realizados por eles. Um subconjunto de seus dados é apresentado em Imai (2018), isso corresponde aos dados para Birbhum distrito no estado de West Bengal. Os dados podem ser acessados da seguinte forma (remova o símbolo de hash):

```{r message=FALSE}
library(tidyverse)

women<-read.csv(file="https://raw.githubusercontent.com/kosukeimai/qss/master/UNCERTAINTY/women.csv", head=TRUE,sep=",")

str(women)
```

Já temos os dados em nosso computador, então lemos as variáveis no conjunto de dados women de interesse para nós são:

+ Identificador **GP** para o Gram Panchayat.
+ identificador de **village** para cada aldeia.
+ **female** se o GP tinha uma líder feminina ou não.
+ **water**; número de instalações de água potável novas ou reparadas na aldeia desde que a política de reserva começou.

A reserva é feita por atribuição aleatória.


```{r}
women %>%
group_by(reserved) %>%
summarize(count_res = n(),
media_female = mean(female),
media_water = mean(water))
```

A média de water no grupo de tratamento é 24 e no de controle é 15.

```{r fig.width=9, fig.height=3}
ggplot(women,aes(y = water, x = factor(reserved))) +
geom_boxplot() +
coord_flip()
```

A Figura acima mostra que algumas das aldeias tratadas tinham níveis de água muito altos, uma característica da amostra que observamos graças aos boxplots.

Os dados são agrupados, então incorporamos isso ao realizar a randomização
inferência com o pacote ri2.



```{r fig.width=9, fig.height=3, message=FALSE}
library(randomizr) # Para rodar a funcao declare_ra
library(ri2) # Para a funcao conduct_ri

dat <- data.frame(Y = women$water, Z = women$reserved, cluster = women$GP)

head(dat)

declaracao <- with(dat, {declare_ra(clusters = cluster)} )

declaracao

ri2_resultado <- conduct_ri(Y ~ Z, sharp_hypothesis = 0, declaration = declaracao, data = dat)

summary(ri2_resultado)

plot(ri2_resultado, main="Distribuição de inferência randômica para reservados")
```


Obtemos uma estimativa de 9,25 com um valor $p$ baixo de 0,015 (figura acima).

Também usamos o pacote estimatr, e um modelo linear, e estimamos o cluster com erros padrão robustos. Os resultados do summary(mod_water_r) mostram os coeficientes e intervalos de confiança resultantes.

```{r}

women$reserved <- factor(women$reserved)

library(estimatr)

mod_water_r <- lm_robust(water ~factor(reserved), clusters = GP, data = women)

summary(mod_water_r)
```



## Exemplo: Programas educacionais

Vemos os dados de um experimento realizado por volta de 1970, apresentado no e-book de Gelman e Hill (2007, p. 174-181). O resultado foi a leitura das pontuações dos testes e o tratamento foi a exposição a um programa de televisão educacional.

+ [Acesse o e-book aqui](https://github.com/bgse-datascience-group8/Statistical-Modelling-and-Inference/blob/master/resources/Gelman%2C%20Hill-Data%20Analysis%20Using%20Regression%20(2007).pdf)

+ [Você pode baixar o conjunto de dados completo desse e-book aqui](https://stat.columbia.edu/~gelman/arm/software/)

```{r}
electric <- read.table(file="https://raw.githubusercontent.com/rhozon/datasets/master/electric.dat", header = TRUE) 

str(electric)
```

As principais variáveis no dataset eletric são:

+ *Grade*. Nota do aluno.
+ *treated.Pretest*. Pontuações do pré-teste dos alunos do grupo de tratamento.
+ *control.Pretest*. Pontuações do pré-teste dos alunos de controle.
+ *treated.Posttest*. Pontuações pós-teste dos alunos do grupo de tratamento.
+ *control.Posttest*. Pontuações pós-teste dos alunos de controle.

Temos que discutir os dados, precisamos combinar as variáveis de pré-teste para
o grupo de controle dos alunos, da mesma forma para o pós-teste, e criar um indicador para o tratamento.


```{r}
post.test <- c(electric$treated.Posttest, electric$control.Posttest)

pre.test <- c(electric$treated.Pretest, electric$control.Pretest)

grade <- rep(electric$Grade,2)

grade <- factor(grade)

rep(c(1,0),rep(3,2))

tratamento <- rep(c(1,0), rep(length(electric$treated.Posttest),2))

tratamento <- factor(tratamento)

n <- length(post.test)

elec <- tibble(post.test, pre.test,grade,tratamento)

elec

```

Vamos focar na grade1, filtrando os dados:

```{r}
library(tidyverse)
elec_1 <- elec %>%
filter(grade==1)
```

Nós plotamos boxplots de pontuações pós-teste do grupo de tratamento versus controle:

```{r fig.width=9, fig.height=3}
ggplot(elec_1, aes(y = post.test, x = tratamento)) +
geom_boxplot() +
coord_flip()
```

Um gráfico de dispersão de pós-teste versus pré-teste funciona bem neste caso:

```{r fig.width=9, fig.height=3, message=FALSE}
ggplot(elec_1, aes(x = pre.test, y = post.test, colour = tratamento)) +
geom_point() +
stat_smooth(method=lm, se = FALSE)
```

Como este é um experimento, não precisamos controlar as pontuações do pré-teste, mas incluir as pontuações do pré-teste, que nos fornecem estimativas mais precisas.

```{r}
mod1.1 <- lm(post.test ~ tratamento, data = elec_1)
mod1.2 <- lm(post.test ~ pre.test + tratamento, data= elec_1)
```




<center>
<small>**Tabela 8:** Efeito do programa nas pontuações </small>

```{r echo=FALSE, results='asis', message = FALSE}
#http://people.virginia.edu/~jcf2d/exercises/getting_started_with_stargazer.html
library(stargazer)
stargazer(mod1.1, mod1.2, type="html", 
          column.labels = c("mod1.1", "mod1.2"), 
          intercept.bottom = FALSE, 
          single.row=FALSE,     
          notes.append = FALSE, 
          header=FALSE) 
```
</center>

&nbsp;


### Exercício proposto

Analise os dados para as grades 2 e 4. Como os resultados podem se comparar com aqueles do grau 1?


## Exemplo: Estrela

O projeto Star foi um grande experimento conduzido no Tennessee, nos Estados Unidos.
Três tratamentos foram atribuídos em nível de sala de aula: turmas pequenas (13-17 alunos), classes regulares (22-25 alunos) e aulas regulares com um auxiliar que trabalharia com a professora. A análise aqui segue a apresentação na econometria
do clássico livro de Hill et al. (2018), e se concentra no tratamento de pequenas classes em comparação com o grupo de controle de classes de tamanho regular.

```{r}
library(tidyverse)
#library(POE5Rdata)
#data(star)

#star<-load(file="https://github.com/ccolonescu/POE5Rdata/blob/master/data/star.rda?raw=true")

load("C:/Users/rodri/Downloads/star.rda")

str(star)
```

As principais variáveis no dataset star são:


+ totalscore. Leitura mais pontuação em matemática.
+ small.. É 1 se o aluno foi designado para uma classe pequena.
+ boy, white-asian, freelunch. Descritores do aluno.
+ tchexper. Experiência do professor.

Um dos tratamentos foi usar um auxiliar de ensino; nós ignoramos essas observações
e focamos na comparação pequena versus regular.

```{r}
star <- star %>%
filter(aide == 0) %>%
dplyr::select(totalscore, small, tchexper, boy, freelunch, white_asian, schid) %>%
mutate(small_fac = ifelse(small == 1, "small", "regular"), sch_fac = factor(schid))

str(star)

star <- as_tibble(star)
```

```{r}
star %>%
group_by(small_fac) %>%
summarize(mscore = mean(totalscore),
          sdscore = sd(totalscore))
```


A pontuação média da turma regular foi 918, e da turma pequena foi 932.

```{r fig.width=9,fig.height=3, message=FALSE}
ggplot(star, aes(x = small_fac, y = totalscore)) +
geom_boxplot() +
coord_flip()+
  ggtitle("Boxplots de pontuação total para small e regular classes")
```

Na figura acima, vemos que a distribuição da pontuação total muda para a direita para o grupo de alunos em turmas pequenas. Também vemos que, em nossa amostra, os valores discrepantes mais baixos não estão lá nas classes pequenas, que notamos graças aos boxplots.

Podemos ver como as diferentes covariáveis variam entre as classes regulares e pequenas.

```{r message=FALSE}
star %>%
group_by(small_fac) %>%
summarize(mboy = mean(boy),
          mlunch = mean(freelunch),
          mw_a = mean(white_asian),
          mexper = mean(tchexper))
```


As diferenças nas médias covariáveis entre os grupos tratamento e de controle são
pequenas. O pacote cobalt (Greifer 2019) nos ajuda a avaliar o equilíbrio covariável


```{r message=FALSE, fig.width=9,fig.height=3}
library(cobalt)

love.plot(small ~ boy + freelunch + white_asian + tchexper, data = star, stars = "std")
```

Podemos realizar um teste formal de equilíbrio da seguinte forma, usando um modelo de probabilidade linear (Hill et al. 2018).

```{r}
mod_star_check <- lm(small ~ boy + white_asian + tchexper + freelunch, data = star)
mod_star_1 <- lm(totalscore ~ small_fac, data = star)
mod_star_2 <- lm(totalscore ~ small_fac + boy + freelunch + white_asian, data = star)
mod_star_3 <- lm(totalscore ~ small_fac + boy + freelunch + white_asian + tchexper, data = star)
```

<center>
<small>**Tabela 9:** Checando o balanço </small>

```{r echo=FALSE, results='asis', message = FALSE}
#http://people.virginia.edu/~jcf2d/exercises/getting_started_with_stargazer.html
library(stargazer)
stargazer(mod_star_check, type="html", 
          column.labels = c("mod_star_check"), 
          intercept.bottom = FALSE, 
          single.row=FALSE,     
          notes.append = FALSE, 
          header=FALSE) 
```
</center>

&nbsp;


O efeito de pequenas classes (cerca de 14 no modelo 1 e modelo 2 na Tabela 9) é
estável nas três especificações. No modelo 3, obtemos uma estimativa maior e com mais precisão.

```{r}
summary(mod_star_1)

summary(mod_star_2)

summary(mod_star_3)
```


Os detalhes do _matching_ podem ser um tanto técnicos e, portanto, contamos com dados simulados para que tenhamos intuição sobre a correspondência.

## Exemplo simples com dados sintéticos

A ideia básica do _matching_ é bastante intuitiva. Vemos um pequeno exemplo simulado.

Suponha que x, uma variável binária e w, sejam as causas de y. Também w afeta y de forma não linear.

Nós geramos os dados:

```{r}
library(tidyverse)

x <- c(rep(0,6),rep(1,6))
w <- c(30,18,20,10,10,17,20,18,10,10,17,3)
y <- (10 * x) + w + (0.2 * w^2) + (3 * (rnorm(12,1,1)))
wsq <- w^2
dat_mat <- data.frame(y,x,w,wsq)

dat_mat
```



Observe em dat_mat que a primeira observação tem um valor de w = 30, com x = 0
e o 12º tem o valor w = 3. Essa falta de sobreposição pode ser vista no gráfico abaixo:

```{r fig.width=9,fig.height=3}
ggplot(dat_mat, aes(x = w, y = y,
shape = factor(x),
linetype = factor(x))) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, col = "black")+
  ggtitle("Gráfico de dispersão de y versus w, dados incomparáveis")
```

Então rodamos três regressões diferentes:

```{r}
modelo1 <- lm(y ~ x + w + wsq, data = dat_mat)
modelo2 <- lm(y ~ x + w, data = dat_mat)
modelo3 <- lm(y ~ x , data = dat_mat)
```


<center>
<small>**Tabela 10:** Efeito da omissão de w e wsq (Efeito verdadeiro de x em y=10) </small>

```{r echo=FALSE, results='asis', message = FALSE}
#http://people.virginia.edu/~jcf2d/exercises/getting_started_with_stargazer.html
library(stargazer)
stargazer(modelo1, modelo2, modelo3, type="html", 
          column.labels = c("modelo1", "modelo2", "modelo3"), 
          intercept.bottom = FALSE, 
          single.row=FALSE,     
          notes.append = FALSE, 
          header=FALSE) 
```
</center>

&nbsp;

Se regredirmos y em x, w e wsq, nossa estimativa do efeito de y em x está perto da estimativa verdadeira (Tabela 10). Mesmo regredir y em x e w nos dá uma estimativa razoável. Mas a regressão simples de y em x fornece uma estimativa muito enviesada.
Agora usamos correspondência exata para combinar observações para as quais x = 0 com
observações para as quais x = 1 com exatamente o mesmo ws. Nós usamos o Pacote MatchIt e matchit(), com método = “exact”.

```{r message=FALSE}
library(MatchIt)
match.1 <- matchit(x ~ w, data = dat_mat, method = "exact", replace = FALSE)
match.1
```

A correspondência exata levou a 5 das observações do grupo de tratamento sendo controles correspondidas; Eu fui incomparável.

A função love.plot no pacote cobalt traça o equilíbrio da covariável antes e após o matching:

```{r message=FALSE, fig.width=9,fig.height=3}
library(cobalt)
love.plot(match.1, stars = "std")
```


Agora extraímos os dados correspondentes.

```{r}
match_dat <- match.data(match.1)
match_dat
```

Executamos as mesmas regressões que executamos anteriormente. Com a correspondência exata, a estimativa nas especificações de regressão é a mesma:

```{r}
mod_matched1 <- lm(y ~ x + w + wsq, data = match_dat)
mod_matched2 <- lm(y ~ x + w, data = match_dat)
mod_matched3 <- lm(y ~ x , data = match_dat)

summary(mod_matched1)

summary(mod_matched2)

summary(mod_matched3)
```

```{r fig.width=9,fig.height=3}
ggplot(match_dat, aes(x = w, y = y, shape = factor(x), linetype = factor(x))) +
geom_point() +
geom_smooth(method = "lm", se = FALSE, col = "black")+
  ggtitle("Gráfico de dispersão de y contra w depois de combinar")
```

Podemos comparar nossa figura anterior com os dados incomparáveis do gráfico inicial dessa seção. Ho et al. (2011) defendem a correspondência como um método não paramétrico para reduzir a dependência do modelo.

## Exemplo: Programa de Treinamento de Mão de Obra

Lalonde (1986) mostrou que a avaliação experimental e econométrica (com dados observacionais) de um programa de treinamento de mão-de-obra - o National Supported Work Demonstração - chegou a diferentes conclusões. No entanto, Dehejia andWahba (1999) subsequentemente usado correspondência; eles mostraram que um estudo observacional poderia chegar com os resultados do estudo experimental.
Trabalharemos com a versão dos dados disponíveis no pacote MatchIt.


```{r}
data(lalonde, package = "MatchIt")
#l1 <- read.csv("l1.csv")
#write.csv(l1,"l1.csv")
str(lalonde)
```

A variável de resultado são os ganhos em 1978, re78. O tratamento é treat.
Existem covariáveis demográficas e ganhos anteriores em 1974 re74 e 1975 re75.
Renomeamos lalonde para economizar digitação.


```{r fig.width=9,fig.height=3}
l1 <- lalonde

love.plot(treat ~ age + educ + black + hispan + married + nodegree + re74 + re75, data = l1, stars="std")
```

As covariáveis são desequilibradas, especialmente black e re74


```{r}
mod_la1 <- lm(re78 ~ treat, data = l1)
mod_la2 <- lm(re78 ~ treat + age + educ + black + hispan + married +
nodegree + re74 + re75, data = l1)

summary(mod_la1)

summary(mod_la2)

```


```{r}
set.seed(123)
match.l1 <- matchit(treat ~ age + educ + black + hispan + married +
nodegree + re74 + re75,
data = l1, method = "genetic",
replace = FALSE, pop.size = 50, print = 0)#, caliper = 0.4)
#print = 0)
match.l1
```

Todas as 185 observações tratadas foram combinadas

```{r fig.width=9,fig.height=3}
love.plot(match.l1, stars ="std")
```


O equilíbrio da covariada melhorou após a correspondência

```{r}
match_dat <- match.data(match.l1)
```


```{r fig.width=9,fig.height=3}
ggplot(l1, aes(x = factor(treat), y = re78)) +
geom_boxplot() + coord_flip()
```

```{r fig.width=9,fig.height=3}
ggplot(match_dat, aes(x = factor(treat), y = re78)) +
geom_boxplot() + coord_flip()
```

Nos dados não combinados, a mediana e os valores do 75º percentil de re78 são maiores
no grupo de controle, o oposto é verdadeiro em dados combinados. Além disso, observe os outliers nos grupos tratamento e de controle.

```{r fig.width=9,fig.height=3}
mod_la_match1 <- lm(re78 ~ treat, data = match_dat)
mod_la_match2 <- lm(re78 ~ treat + age + educ + black + hispan +
married + nodegree + re74 + re75, data = match_dat)

summary(mod_la_match1)

summary(mod_la_match2)
```

Nos resultados gerados, vemos que com os dados correspondentes, obtemos um efeito de tratamento de 756 estimando a diferença de médias. Recebemos uma estimativa de 1220, uma vez que incluímos os grupos de controle na regressão.


<!--parei em analise de sensibilidade -->
## Análise de Sensibilidade


Em um experimento, o tratamento é atribuído aleatoriamente. Como resultado da atribuição aleatória, unidades de tratamento e controle são balanceadas em relação às covariáveis observadas e não observadas.



Em um estudo observacional, por outro lado, o tratamento não é atribuído aleatoriamente. Combinamos para trazer equilíbrio entre as unidades de tratamento e controle com respeito às covariáveis observadas; mas covariáveis não observadas podem estar influenciando o tratamento.


<p style="font-family: times, serif; font-size:11pt; font-style:italic">
Embora não possamos observar o que não é observado, podemos conduzir uma análise de sensibilidade. O seguinte parágrafo de Rosenbaum (2005, p. 1809) resume a análise de sensibilidade:
</p>

<p style="font-family: times, serif; font-size:11pt; font-style:italic">
The sensitivity analysis imagines that in the population before matching or stratification, subjects are assigned to treatment or control independently with unkown probabilities. Specifically, two subjectswho look the same at baseline before treatment—that is, two subjectswith the same observed covariates—may nonetheless differ in terms of unobserved covariates, so that one subject has an odds of treatment that is up to $\Gamma$ ≥ 1 greater than the odds for another subject. In the simplest randomized experiment, everyone has the same chance of receiving the treatment, so $\Gamma$ = 1. If $\Gamma$ = 2 in an observational study, one subject might be twice as likely as another to receive the treatment because of unobserved pre-treatment differences.
</p>

<p style="font-family: times, serif; font-size:11pt; font-style:italic">
The sensitivity analysis asks how much hidden bias can be present—that is, how large can $\Gamma$ be—before the qualitative conclusions of the study begin to change. A study is highly sensitive to hidden bias if the conclusions change for $\Gamma$ just barely larger than 1, and it is insensitive if the conclusions change only for quite large values of $\Gamma$.
</p>

O pacote rbounds (Keele 2014) baseia-se no pacote Matching para fazer a correspondência genética e, em seguida, realiza uma análise de sensibilidade. Faremos isso para o dados lalonde no pacote MatchIt que analisamos anteriormente.

Precisamos fornecer os dados ao Matching em um determinado formato. Y abaixo é para o
resultado, Tr para tratamento, X para covariáveis.


```{r}
library(rbounds)
Y <- l1$re78
Tr <- l1$treat #o tratamento 
X <- cbind(l1$age, l1$educ, l1$black, l1$hispan, l1$married, l1$nodegree, l1$re74, l1$re75)
BalanceMat <- cbind(l1$age, I(l1$age^2), l1$educ, I(l1$educ^2), l1$black, l1$hispan, l1$married, l1$nodegree, l1$re74 , I(l1$re74^2), l1$re75, I(l1$re75^2), I(l1$re74*l1$re75), I(l1$age*l1$nodegree), I(l1$educ*l1$re74), I(l1$educ*75))
```


A função GenMatch() realiza a correspondência genética

```{r}
#Pesos geneticos
gen1 <- GenMatch(Tr=Tr, X=X, BalanceMat=BalanceMat, pop.size=50, data.type.int=FALSE, print=0, replace=FALSE)

#Match
mgen1 <- Match(Y=Y, Tr=Tr, X=X, Weight.matrix=gen1, replace=FALSE)

summary(mgen1)
```

A diferença de estimativa de médias fornecida pelo Matching é 765, com um Erro Padrão de Abadie-Imbens Erro padrão do  de 699. A função psens() fornece uma análise de sensibilidade:

se Gamma() mudar, como o valor $p$ do Rank assinado de Wilcoxon muda? Até com Gama = 1, o valor p está bem acima de 0,05 ou 0,1. Existe uma grande sensibilidade a um possível viés oculto devido a covariáveis ausentes.

```{r}
psens(mgen1, Gamma = 1.5, GammaInc = 0.1)
```


O hlsens() fornece uma análise de sensibilidade para a estimativa de ponto Hodges-Lehmann. Com um baixo gama de 1,1, o limite inferior e o limite superior são
-0,017 e 547, respectivamente.

```{r}
hlsens(mgen1, Gamma = 1.5, GammaInc = 0.1)
```

## Exemplo: Exposição ao chumbo

Rosenbaum (2017, p. 216) escreveu:

<p style="font-family: times, serif; font-size:11pt; font-style:italic">
Matching may use technical tools to balance many observed covariates, x, but it leaves in its wake a simple structure, perhaps matched pairs, in which treated and control groups are readily seen to be comparable in terms of each measured covariate.With concerns about the measured covariates removed from the picture, our attention turns to the challenging issues that determine whether or not an observational study is convincing.
</p>

A exposição de um pai ao chumbo no trabalho afeta seus filhos? Que tipo de comparações vai lançar luz sobre isso? No exemplo apresentado em Rosenbaum (2017), o
pais trabalharam em uma fábrica de baterias em Oklahoma.

Os dados estão no pacote DOS e as observações já estão combinadas.

```{r}
data(lead, package = "DOS")
head(lead)
```

Nossa primeira comparação é de crianças cujos pais trabalharam na fábrica de baterias com crianças combinadas de controle.

```{r fig.width=9,fig.height=3}
child_lead <- c(lead$control, lead$exposed)
treat <- c(rep("control",33), rep("exposed",33))
child_lead_dat <- data.frame(child_lead, treat)
ggplot(child_lead_dat, aes(x = treat, y = child_lead)) +
geom_boxplot() +
ylim(0,80) +
coord_flip()
```

A Figura acima mostra que a distribuição dos níveis de chumbo é muito maior para as crianças expostas.

Nossa segunda comparação é de crianças cujos pais tiveram diferentes níveis de exposição para liderar na fábrica da bateria.

```{r}
library(forcats)
llevel <- c("low", "medium", "high")
lead$F_level <- factor(lead$level, levels = llevel)
```

```{r fig.width=9,fig.height=3}
ggplot(lead, aes(x = F_level, y = exposed)) +
geom_boxplot() +
ylim(0,80) + coord_flip()
```

Crianças cujos pais tinham níveis mais altos de exposição tinham níveis mais altos de chumbo.

Nossa terceira comparação é entre as crianças do grupo de controle separadas com base na exposição do pai da criança no grupo de tratamento.

```{r fig.width=9,fig.height=3}
ggplot(lead, aes(x = F_level, y = control)) +
geom_boxplot() +
ylim(0,80) + coord_flip()
```

Finalmente pegamos crianças cujos pais tiveram alta exposição, e dentro deste grupo,
comparamos as crianças com base na higiene do pai.

```{r fig.width=9,fig.height=3}
lead$Hyg <- ifelse(lead$hyg == "poor", "poor", "ok")
lead %>%
filter(F_level == "high") %>%
ggplot(aes(x = Hyg, y = exposed)) +
geom_boxplot() +
ylim(0,80) + coord_flip()
```


A Figura acima mostra que as crianças cujos pais tinham higiene pior tiveram maior níveis de chumbo.

## Exemplo: Compensação por Lesões

Examinamos o efeito das leis de compensação do trabalhador no tempo que um trabalhador esteve fora do trabalho após lesão/acidente de trabalho. Este estudo de Meyer, Viscusi e Durbin (1995) é discutido em Rosenbaum (2017). Em julho de 1980, o Kentucky aumentou seu benefício máximo de 131 para 217 dólares por semana. Este aumento afetou apenas os trabalhadores que eram acima do limite anterior - ganhadores de níveis mais altos.

```{r message=FALSE}
library(wooldridge)
data(injury)
str(injury)
```

Removemos as observações com os missings:

```{r}
injury <- injury %>%
na.omit()
```

Subconjuntos dos ganhadores (indenizados) de níveis mais elevados que estavam em Kentucky.


```{r message=FALSE}
# subset highearners
library(tidyverse)
    library(lubridate)
inj_ky_h <- injury %>%
filter(ky == 1, highearn == 1)
```

Subamostra dos ganhadores de níveis mais baixos


```{r}
inj_ky_l <- injury %>%
filter(ky == 1, highearn == 0)
```

A variável afchnge é uma variável dummy para observações após a mudança de política.
Nós combinamos os dados.

```{r}
match.ky.h <- matchit(afchnge ~ male + married + hosp + indust + injtype + age + lprewage, data = inj_ky_h, method = "genetic", replace = FALSE, pop.size = 50, print = 0)

match.ky.h
```

Todas as 103 observações tratadas estão correspondidas. 


```{r fig.width=9,fig.height=3}
#library(precrec)
#love.plot(match.ky.h, stars ="std")

# Erro: `data` must be a data frame, or other object coercible by `fortify()`, not an S3 object with class matchit
```


Nós comparamos o log de duração entre os grupos antes e depois dos dados grupos combinados.

```{r fig.width=9,fig.height=3}
#ggplot(match.ky.h, aes(y = ldurat, x = factor(afchnge))) +
#geom_boxplot() +
#coord_flip()
```

```{r}
#match_dat_ky_h %>%
#group_by(afchnge) %>%
#summarize(mean_ld = mean(ldurat), median_ld = median(ldurat))
```


A média de ldurat antes era 1,39, depois era 1,61.

Usamos o pacote rbounds para estimar as diferenças nas médias depois e antes do grupo.


```{r}
#attach(match_dat_ky_h)
#Y <- ldurat
#Tr <- afchnge
#X <- cbind(male, married, hosp, indust, injtype, age, lprewage)
#gen1 <- GenMatch(Tr = Tr, X = X, pop.size = 50, print = 0)
#mgen1 <- Match(Y = Y, Tr = Tr, X = X, Weight.matrix = gen1, replace = FALSE)
#summary(mgen1)
```

Obtemos uma estimativa de 0,25 com um erro padrão de 0,05.

```{r}
#psens(mgen1, Gamma = 1.5, GammaInc = 0.1)

```


Em Gama = 1,3, o valor $p$ excede 0,05 na análise de sensibilidade.


```{r}
#hlsens(mgen1, Gamma = 1.5, GammaInc = 0.1)
```

A estimativa H-L é 0,25 em Gama = 0 e o limite cruza zero em Gama = 1,3.

Rosenbaum chama as contrapartes de baixa renda; eles não são afetados pela mudança
nas leis de compensação, para que possamos verificar nossos resultados para pessoas de alta renda avaliando se o tempo que os trabalhadores de baixa renda ficaram fora do trabalho aumenta ou não.

### Exercício proposto

Faça uma análise semelhante para as pessoas de baixa renda (temos os dados já filtrados para os valores acima para obter inj_ky_l).



# Descontinuidade na regressão

Em um projeto de descontinuidade de regressão, a atribuição de tratamento depende de um valor de corte de uma variável. Usamos esse conhecimento da atribuição de tratamento para estimar o efeito causal.

## Exemplo simples com dados sintéticos

Faremos uma simulação; então criaremos alguns dados sintéticos.

```{r}
library(tidyverse)
set.seed(12)
tamanho_amostra <- 1000
```

A variável running, run, é desenhada a partir de uma distribuição uniforme.

```{r}
run <- runif(tamanho_amostra, min = 10, max = 50)
```

A variável de tratamento, treat, é igual a 0 se a execução for $<$20, caso contrário, treat = 1.

```{r}
# tratamento, pontodecorte = 20
treat <- ifelse(run < 20,0,1)
```

O resultado é dado por: outcome = 10 treat - 0,4run + ruído

```{r}
# outcome
outcome <- 10 * treat - 0.4 * run + 3 * rnorm(tamanho_amostra)
```

Criamos um dataframe com essas variáveis:

```{r}

rd_data <- data.frame(treat = factor(treat), run, outcome)
```


Então plotamos os dados

```{r}
ggplot(rd_data) +
geom_point(aes(x = run, y = outcome, shape = treat), col = "grey60") + geom_smooth(aes(x = run, y = outcome, linetype = treat),
col = "black") + geom_vline(xintercept = 20)
```

Vemos que há um salto claro no ponto de corte.

Regredir a variável de resultado no tratamento e a variável em execução nos dá
estimativa próxima do efeito verdadeiro (10).

```{r}
lm(outcome ~ treat + run)
```

## Exemplo: Idade mínima legal para beber

Agora trabalhamos com o código R para analisar os dados relativos ao consumo mínimo de idade legal (MLDA) apresentado em Angrist e Pischke (2015). A MLDA de 21 afetou
taxas de mortalidade nos Estados Unidos ?

```{r}
# lendo os dados de exemplo do Stata
library(foreign)
#mlda=read.dta("AEJfigs.dta")

mlda<-read.dta(file="http://masteringmetrics.com/wp-content/uploads/2015/01/AEJfigs.dta")

str(mlda)
```

Temos dados sobre todas as taxas de mortalidade por todas as causas e idade em meses.
Criamos uma variável fictícia para maiores de 21 anos.

```{r}
mlda$over21 = mlda$agecell>=21
```

Então plotamos os dados

```{r fig.width=9,fig.height=3}
library(ggplot2)
age3=ggplot(mlda, aes(x = agecell, y = all,colour=over21)) +
geom_point() +
geom_vline(xintercept=21)
age3
```

Nós adicionamos smooth(). Independentemente do tipo, temos um efeito claro do
idade mínima legal para beber.

```{r fig.width=9, fig.height=3, message=FALSE}
age4=age3 + stat_smooth(method = "lm") +
stat_smooth(method = "loess")
age4
```

Agora usamos um dos pacotes especializados do R para descontinuidade de regressão,
rddtools (Stigler e Quast 2015).



```{r message=FALSE}
library(rddtools)
```

Removemos dados faltantes:

```{r}
mlda <- mlda %>%
na.omit()
```

Temos que declarar os dados para regressão com descontinuidades:

```{r}
rd_data_2 <- rdd_data(y = all, x=agecell, data=mlda, cutpoint=21 )

summary(rd_data_2)
```

Primeiro usamos uma regressão paramétrica para estimar o efeito do tratamento.

```{r}
reg_para <- rdd_reg_lm(rd_data_2, order=1)
reg_para
```

Temos uma estimativa de 7,7. Nós plotamos a linha de regressão paramétrica


```{r fig.width=9,fig.height=3}
plot(reg_para)
```


### Exercício proposto

Altere a ordem do polinômio no código acima, e então rode a regressão novamente.


***

Agora usamos uma regressão não paramétrica; primeiro obtemos o bandwidth ideal.


```{r}
bw_ik <- rdd_bw_ik(rd_data_2)
bw_ik
```

Em seguida, estimamos e plotamos a regressão não paramétrica

```{r}
reg_nonpara <- rdd_reg_np(rdd_object=rd_data_2, bw=bw_ik)
reg_nonpara
```

Fazemos testes de placebo e sensibilidade


```{r fig.width=9,fig.height=3}
plotPlacebo(reg_nonpara)
```

A figura acima mostra que usar pontos de corte diferentes de 21 não nos dá um efeito estatísticamente significativo.

```{r fig.width=9,fig.height=3}
plotSensi(reg_nonpara, from=0.05, to=3, by=0.15)
```

Isso nos mostra que os resultados não são sensíveis ao bandwidth.

# Diferenças em Diferenças (Diff and Diff)

O método diferença-em-diferença é freqüentemente usado para análise de políticas. Nós usamos primeiro um exemplo de Wooldridge (2013) para se ter a ideia básica.

## Exemplo: Taxa de rejeição e treinamento

Neste exemplo, o resultado é a taxa de sucateamento (quantos itens defeituosos devem ser jogados fora) em empresas de manufatura em Michigan durante 1987 e 1988. O tratamento é o recebimento de uma bolsa para treinamento profissional.


Podemos escrever a taxa de refugo para 1988 como:

$scrap_{1988} = \beta_{0} + \delta_{0}1 + β_{1}grant_{i1988} + a_{i} + u_{i1988}$

onde $i$ denota a empresa e $a_i$ é um fator específico da empresa.
A taxa de refugo para 1987 é:

$scrap_{1987} = β_{0} + β_{1}grant_{i1987} + a_{i} + u_{i1987}$

A diferença nas taxas de refugo entre 1988 e 1987 é:

$scrap_{1988} − scrap_{1987} = \Delta scrap_{i} = δ_{0} + β1\Delta grant_{i} + \Delta u_i$


A diferenciação nos ajuda a remover o efeito de confusão $a_{i}$. Os dados estão no pacote wooldridge.

```{r}
library(wooldridge)
data("jtrain")
```


Removemos os dados do ano de 1989.

```{r}
jtrain <- jtrain %>%
filter(year != 1989)
```

Usaremos o pacote plm, que trata dos dados do painel.

```{r}
library(plm)
jtrain_p <- pdata.frame(jtrain,
index = c("fcode","year"))
```


Usamos a função diff() para obter diferenças.

```{r}
jtrain_p$scrap_d <-
diff(jtrain_p$scrap)
jtrain_p$grant_d <-
diff(jtrain_p$grant)
```


Estimamos o efeito da concessão na sucata/descarte.

```{r}
mod_did <- lm(scrap_d ~ grant_d, data = jtrain_p)

summary(mod_did)
```


Obtemos uma estimativa estatisticamente insignificante de -0,74

## Simulação


Na subseção anterior, presumimos que havia um efeito fixo que era um causa comum do resultado e do tratamento. Chamemos este caso de A. Diferenciando removemos o efeito fixo.


No entanto, e se o valor inicial do resultado afetar o valor atual do resultado e o tratamento? Vamos chamar este caso B. Podemos controlar para o valor do resultado.
Mas não sabemos se os dados são gerados por um processo consistente com o caso A ou caso B. Portanto, usamos simulação para ver o que acontece quando diferimos ou controlamos para valores iniciais no caso A e no caso B. Geramos dados para o caso A.
Temos um resultado no período 0 que é uma função linear "fixa" e um prazo de erro:

$y_0 = fixed + u_{y0}$

Então, no período 1, temos um tratamento que é determinado por:

$treat = 1,\,\, if : fixed < 0,\,\, else = 0$

O tratamento tem um efeito eff, que afeta o resultado além de fixo.

$y_{1} = fixed + eff ∗ treat + u_{y1}$

Geramos os dados sintéticos com o seguinte código:

```{r}
ss <- 3000 # tamanho da amostra
eff <- 3 # efeito= 3
fixed <- rnorm(ss) # normal aleatoria
treat <- ifelse(fixed < 0,1,0)
uy1 <- rnorm(ss)
uy0 <- rnorm(ss)
y1 <- fixed + eff * treat + uy1
y0 <- fixed + uy0
```


Em m_d1, estimamos a diferença das médias. Em m_d2 nós controlamos para o valor inicial de y, y0. Em m_d3, usamos diferença em diferença.

```{r}
# diferenca das medias
m_d1 <- lm(y1 ~ treat)

# controle para y0
m_d2 <- lm(y1 ~ y0 + treat)

# diff in diff
m_d3 <- lm(I(y1 - y0) ~ treat)

summary(m_d1)

summary(m_d2)

summary(m_d3)
```

Nos resultados acima gerados, o Modelo 3 (diferença-em-diferença) chega perto do efeito verdadeiro. O modelo 2 (controlando para o valor inicial) nos dá uma subestimativa, e o modelo 1 (diferença das médias) está mais longe do verdadeiro efeito.

Geramos dados para o caso B.
Temos um resultado no período 0 que é uma variável aleatória:

$y_0 = u_{y0}$

O resultado inicial influencia o tratamento:

$treat = 1,\,\, if : y_0 < 2.5,\,\ else = 0$


No período 1, o tratamento tem um efeito $eff$, que afeta o resultado além do valor do resultado inicial.

$y_1 = beta ∗ y_0 + eff ∗ treat + u_{y1}$


Geramos os dados sintéticos com o seguinte código:

```{r}
ss <- 3000
eff <- 3
y0 <- runif(ss, min = 1, max = 4)
treat <- ifelse(y0 < 2.5,1,0)
uy1 <- rnorm(ss)
uy0 <- rnorm(ss)
y1 <- 0.3 * y0 + eff * treat + uy1
```


```{r}
# diferenca nas medias
m_d4 <- lm(y1 ~ treat)
# controlando para y0
m_d5 <- lm(y1 ~ y0 + treat)
# diff in diff
m_d6 <- lm(I(y1 - y0) ~ treat)

summary(m_d4)

summary(m_d5)

summary(m_d6)
```


Nos resultados acima gerados, vemos que a diferença em diferença nos dá uma superestimativa, modelo 2 (controlando para o valor inicial) é próximo e a diferença simples nas médias é uma grande subestimação.
Então, vemos que a diferença-em-diferença tem uma suposição crucial, que o tratamento e grupo de controle têm tendências paralelas. Isso pode ser examinado graficamente.
Portanto, como na descontinuidade da regressão, o exame gráfico pode nos ajudar a julgar a validade da diferença-em-diferença em um determinado contexto.

## Exemplo: bancos de negócios

Neste exemplo de Angrist e Pischke (2015), examinamos o papel da política monetária, durante a Grande Depressão em diferentes distritos do sistema do Federal Reserve dos EUA. Comparamos o efeito de empréstimos fáceis para bancos em dificuldades, conforme praticado pelo Atlanta Fed, que administrava o Sexto Distrito, à política restritiva do St. Louis Fed que dirigia o Oitavo Distrito. A variável de resultado é o número de bancos em atividade.

O grupo de tratamento é o sexto distrito e o grupo de controle é o oitavo distrito.
Recebemos os dados:

```{r}
# install.packages("devtools")
#devtools::install_github("jrnold/masteringmetrics", subdir = "masteringmetrics")

#data("banks", package = "masteringmetrics")


```

[Baixe os dados aqui](https://github.com/jjchern/mmdata/blob/master/data/banks.rda?raw=true)

Então carregue localmente:

```{r}
load("C:/Users/rodri/Downloads/banks.rda")

str(banks)
```

Calculamos o número médio de bancos em atividade a cada ano diariamente e nos distritos 6 e 8.

```{r}
library(tidyverse)
bankag <- banks %>%
group_by(year) %>%
summarize(bib6m=mean(bib6),
          bib8m=mean(bib8))

head(bankag)
```

Empilhamos, ou reunimos, os bancos em atividade para o sexto e o oitavo distritos em um coluna.

```{r}
bankag2 <- gather(bankag,
"bty","num",2:3)
```

Filtramos pelos anos 1930 e 1931.


```{r}
bankag3 <- filter(bankag2, year == 1930 | year == 1931)
bankag3
```

Traçamos os bancos em atividade em 1930 e 1931. Nossa diferença-indiferença a estimativa é = (120 - 136) - (132 - 165) = −16 - (−33) = 17.

```{r fig.width=9,fig.height=3}
ggplot(bankag3, aes(x=year, y=num,colour=bty)) +
geom_line()
```

Podemos explorar a suposição de tendências paralelas; Esse gráfico mostra que as tendências são de fato paralelas antes de 1930 e depois de 1931.

```{r fig.width=9,fig.height=3}
ggplot(bankag2, aes(x=year,y=log(num),colour=bty)) +
geom_line()
```






&nbsp;

***

### Referências

Abadie,A., M.D. Catteneo. 2018. _**Econometric methods for program evaluation**._ Annual Review of Economics 10: 465–503.

Angrist, J.D., J. Pischke. 2015. _**Mastering ‘metrics - The path from cause to effect**._ Princeton: Princeton University Press.

Elwert, F. 2013. _**Graphical causal models. In Handbook of causal analysis for social research,_** ed. S.L. Morgan, 245–274. New York: Springer.

Freedman, D.A. 1983. _**A note on screening regression equations. The American Statistician_** 37 (2): 152–155.

Greifer, N. 2019. _**cobalt: Covariate balance tables and plots_**. R package version 3.8.0. https://CRAN. R-project.org/package=cobalt.

Hill, R.C., W.E. Griffiths, and G.C. Lim. 2018. _**Principles of econometrics._** New York: Wiley.

Kahneman, D. 2011. _**Thinking, fast and slow._** London: Penguin Books.

Pearl, J., M. Glymour, and N.P. Jewell. 2016. _**Causal inference in statistics: A primer.**_ New York: Wiley.

Rosenbaum, P. 2005. _**Sensitivity analysis in observational studies. In Encyclopedia of statistics in behavioural science,_** ed. B.S. Everitt, D.C. Howell, 1809–1814. New York: Wiley.

Rosenbaum, P. 2017. _**Observation and experiment - An introduction to causal inference._** London: Harvard University Press.

Rubin, D.B. 2008. _**Statistical inference for causal effects, with emphasis on applications in epidemiology and medical statistics.**_ _In Handbook of Statistics_, vol. 27, ed. C.R. Rao, J.P. Miller, D.C. Rao. 2008. Amsterdam: Elsevier.

Stigler, M., and B. Quast. 2015. _**rddtools: Toolbox for Regression Discontinuity Design (‘RDD’)._** R package version 0.4.0. https://CRAN.R-project.org/package=rddtools.
