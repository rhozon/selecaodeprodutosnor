---
title: "Consulta e automação a base SECEX/MDiC "
author: "Ozon, R. H."
date: "02/12/2020"
output:
  html_document:
    toc: true
    toc_float: true
---

<!-- ================================================================================= -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#linha para retirar os [1] prefixo de resultados dos output dos comandos do r
# veja https://stackoverflow.com/questions/22524822/how-can-i-remove-the-prefix-index-indicator-1-in-knitr-output/22563357
knitr::opts_chunk$set(opts.label="kill_prefix")
```

```{r include=FALSE}
# cunhk para retiraar os prefixos
default_output_hook <- knitr::knit_hooks$get("output")
# Output hooks handle normal R console output.
knitr::knit_hooks$set( output = function(x, options) {

  comment <- knitr::opts_current$get("comment")
  if( is.na(comment) ) comment <- ""
  can_null <- grepl( paste0( comment, "\\s*\\[\\d?\\]" ),
                     x, perl = TRUE)
  do_null <- isTRUE( knitr::opts_current$get("null_prefix") )
  if( can_null && do_null ) {
    # By default R print output aligns at the right brace.
    align_index <- regexpr( "\\]", x )[1] - 1
    # Two cases: start or newline
    re <- paste0( "^.{", align_index, "}\\]")
    rep <- comment
    x <- gsub( re, rep,  x )
    re <- paste0( "\\\n.{", align_index, "}\\]")
    rep <- paste0( "\n", comment )
    x <- gsub( re, rep,  x )
  }

  default_output_hook( x, options )

})

knitr::opts_template$set("kill_prefix"=list(comment=NA, null_prefix=TRUE))

```

<!-- ================================================================================= -->

***

[em construção...]


## Download dos dados e conversão do formato

No chunk abaixo rodamos um procedimento de busca e coleta da base de dados completa das exportações e importações nacionais no período compreendido entre jan/1997 até o último mês disponível. Ao rodar o chunk a cada mês ele atualiza os arquivos, (se houver nova publicação no SECEX) sem a necessidade de baixá-los do site toda vez. 

Descomente o chunk (retirando as cerquilhas) onde os comandos estão presentes caso queira reproduzir na sua máquina ou adapte para setar um outro repositório para armazenar os arquivos.


```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

#Baixa a serie completa
#url_exp <- download.file("http://www.mdic.gov.br/balanca/bd/comexstat-bd/ncm/EXP_COMPLETA.zip") #Exportacoes
#url_imp <- download.file("http://www.mdic.gov.br/balanca/bd/comexstat-bd/ncm/IMP_COMPLETA.zip") #Importacoes

#Escrevo num local temporario
#temp_exp <- tempfile()
#temp_imp <- tempfile()

#Insiro os arquivos .zip na pasta local temporaria
#download.file(url_exp, temp_exp)
#download.file(url_imp, temp_imp)

#Deszipa os arquivos
#unzip_exp <- unz(temp_exp, "EXP_COMPLETA.csv") #Extrai as exportacoes na base completa
#unzip_imp <- unz(temp_imp, "IMP_COMPLETA.csv") #Extrai as importacoes na base completa
```

Após guardá-lo em um determinado local estipule uma rotina de em determinado dia do mês rodar o chunk acima para atualizar os arquivos da base completa.

Você poderá atualizar os arquivos quando criar um modelo de visualização de dados (assim como eu fiz uma usando o Power BI no final deste documento) sem se preocupar em reorganizá-los ou fazer o procedimento todo novamente. 

Isso lhe fornece velocidade e minimiza substancialmente quaisquer erros humanos no processo.

Neste tutorial, trabalho com um ETL menor para os dados de exportação disponível no último mês, como demonstração. Utilizo a linguagem R aqui dentro de um documento do tipo RMarkdown para elucidar mais claramente as nossas possibilidades.



## Pauta de Exportações

Primeiro baixo os dados de exportação:


```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
#expdwnld<-download.file("http://www.mdic.gov.br/balanca/bd/comexstat-bd/ncm/EXP_2020.csv", "exp.csv")
exp<-read.csv("exp.csv", head=TRUE, sep=";", encoding = "latin1")

head(exp)

#library(vctrs)
library(dplyr)
glimpse(exp)
```

## Agregando por mês/ano


Concateno CO_ANO com CO_MES

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
library(tidyverse)

exp<-exp%>%
  mutate(CO_MES = formatC(CO_MES, width = 2, flag = "0")) #Arrumo pra dois digitos no mes

library(lubridate)

exp$AnoMes<-str_c(exp$CO_ANO,"/",exp$CO_MES) #uno uma coluna com a outra e chamo ela de MesAno

glimpse(exp)

colSums(is.na(exp)) #Conta quantos missings temos em cada variavel
```

Agrego por período e organizo de modo decrescente temporalmente:


```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
expper<-exp%>%
  group_by(AnoMes)%>%
  summarise(Total_AnoMes =sum(VL_FOB, na.rm = TRUE))

arrange(expper, AnoMes)
```

Vamos ver num gráfico:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
library(plotly)
library(ggplot2)

ggplotly(ggplot(expper, aes(x=AnoMes, y=Total_AnoMes))+
  geom_bar(stat="identity")+
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)))


```



## Agregando por NCM

Baixo os dados de código NCM e nome

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
#ncmdwlnd<-download.file("http://www.mdic.gov.br/balanca/bd/tabelas/NCM.csv","NCM.csv")
ncm <- read.csv("NCM.csv", sep = ";", encoding = "latin1")

glimpse(ncm)
```

Então agrupo as exportações (em US$ FOB) por NCM: (O agruoamento é necessário por uma questão de limitação de processamento e memória)

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
#agrupa exp por ncm
expncm<-exp%>%
  group_by(CO_NCM)%>%
  summarise(Total_NCM = sum(VL_FOB, na.rm=TRUE))

arrange(expncm, desc(Total_NCM))
```

Caso os nomes dos produtos pelo NCM:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
library(tidyverse)
expncm <- left_join(expncm, ncm %>%
                             select(CO_NCM, NO_NCM_POR), by = c("CO_NCM" = "CO_NCM"))%>%
                             mutate(TotExpNCM = expncm$Total_NCM)
expncm<-expncm%>%
  select(-Total_NCM) #tiro fora a soma pra nao ficar em duplicidade

glimpse(expncm)

```

Vamos ver como fica a classificação:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

arrange(expncm,desc(TotExpNCM))

```

Podemos filtrar aqueles que possuem a string "soja" no nome do produto (NCM):

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
expncmsoja<-expncm%>%
  filter(grepl("soja", NO_NCM_POR ) | grepl("Soja", NO_NCM_POR))

expncmsoja
```

Ou então poderíamos filtrar com base em diferentes strings de produtos:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
expncmprodutos<-expncm%>%
  filter(grepl("soja", NO_NCM_POR ) | grepl("Soja", NO_NCM_POR) |
         grepl("milho", NO_NCM_POR ) | grepl("Milho", NO_NCM_POR) |
         grepl("açúcar", NO_NCM_POR ) | grepl("Açúcar", NO_NCM_POR))

expncmprodutos
```

Você poderia exportar esta tabela filtrada para um arquivo do tipo .csv:


```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

write.csv(expncmprodutos, "expncmprodutos.csv")

```

Poderíamos calcular uma estimativa de participação neste ano de 2020 da lista de nossos produtos exportados em relação ao total exportado pelo Brasil fazendo:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

round((sum(expncmprodutos$TotExpNCM, na.rm=TRUE)/sum(expncm$TotExpNCM, na.rm=TRUE))*100,digits = 2) 

```

Ou seja, cerca de `r round((sum(expncmprodutos$TotExpNCM, na.rm=TRUE)/sum(expncm$TotExpNCM, na.rm=TRUE))*100,digits=2)`% dos nossos produtos tiveram representatividade na pauta exportadora brasileira de janeiro até o último mês disponível na base de 2020.


Finalmente eu crio a tabela com somente os 10 primeiros produtos exportados no Brasil, por ordem de valor em dólares FOB:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
topten<-expncm%>%
  top_n(TotExpNCM, n=10)

arrange(topten, desc(TotExpNCM))
```  




```{r message=FALSE, warning=FALSE}
library(treemap)
#treemap(expncm, #Your data frame object
#        index=c("NO_NCM_POR"),  #A list of your categorical variables
#        vSize = "TotExpNCM",  #This is your quantitative variable
#        type="index", #Type sets the organization and color scheme of your treemap
#        palette = "Reds",  #Select your color palette from the RColorBrewer presets or make your own.
#        title="Produtos com maior fluxo financeiro de exportação no Brasil em 2020", #Customize your title
#        fontsize.title = 12 #Change the font size of the title
#        )

#library(treemapify)
#treemap<-ggplot(expncm, aes(area=TotExpNCM, fill = TotExpNCM, label = as.character(NO_NCM_POR))) +
#  geom_treemap()+
#  geom_treemap_text(fontface = "italic", colour = "white", place = "centre", grow=TRUE)  +
#  theme(legend.position = "none")

#treemap

```






## Agregando por UF

Provavelmente o estado que mais exporta deverá ser o de São Paulo. Vamos verificar em quanto:


```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

expuf<-exp%>%
  group_by(SG_UF_NCM)%>%
  summarise(TotalExp_UF = sum(VL_FOB, na.rm = TRUE))

arrange(expuf, desc(TotalExp_UF))

```

Vamos ver como ficam as descritivas:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

min(expuf$TotalExp_UF) 

mean(expuf$TotalExp_UF)

max(expuf$TotalExp_UF)

```


Determino o intervalo adequado de classe conforme [Regra de Sturges:](https://maestrovirtuale.com/regra-de-sturges-explicacao-aplicacoes-e-exemplos/#:~:text=A%20regra%20Sturges%20%C3%A9%20um%20m%C3%A9todo%20emp%C3%ADrico%20amplamente%20usado%20em,representando%20uma%20amostra%20ou%20popula%C3%A7%C3%A3o.&text=%E2%80%93%20N%20%C3%A9%20o%20n%C3%BAmero%20total%20de%20observa%C3%A7%C3%B5es%20na%20amostra.)


```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

k <- 1 + 3.322*log10(28)

round(k,digits = 0) # Numero ideal de classes a serem utilizadas

amplitude <- (max(expuf$TotalExp_UF) - min(expuf$TotalExp_UF)) / k

amplitude #Tamanho do intervalo
```


Determinando os intervalos de classes:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}


min(expuf$TotalExp_UF) 

min(expuf$TotalExp_UF) + amplitude - 1 

#primeira classe = de 13547392 a 3332244011 

3332244011 + 1 

3332244011 + 1 + amplitude - 1

#segunda classe = de 3332244012 a 6650940631 

6650940631 + 1 

6650940631 + 1 + amplitude - 1

#terceira classe = de 6650940632 a 9969637251

9969637251 + 1

9969637251 + 1 + amplitude - 1

#quarta classe = de 6650940633 a 13288333871

13288333871 + 1

13288333871 + 1 + amplitude - 1

#quinta classe = de 13288333872 a 16607030491

16607030491 + 1 

16607030491 + 1 + amplitude - 1

#sexta classe = de 16607030492 a 19925727111


```


Podemos também observar o novo dataset agrupado:
```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
write.csv(expuf, "expuf.csv")
```


Renomeio o nome da coluna SG_UF_NCM pra fazer o join:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

colnames(expuf)[1]<-"abbrev_state"

```` 


Vamos ver no mapa como fica. Inicialmente carrego as bibliotecas:


```{r mapa, message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE, results = 'hide'}

library(ggplot2)
library(geobr)

uf<-read_state(code_state="all")
```

Agora faço a junção:

```{r mapa2, message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

junta<-full_join(uf, expuf, by="abbrev_state")
```


Em seguida crio as categorias de classes pro mapa:

```{r mapa4, message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

junta$categorias_em_dolares<-
  cut(junta$TotalExp_UF,
      breaks=c(0, 3332244011, 6650940631, 9969637251, 13288333871, 16607030491, 19925727111),
  labels=c("de 13547392 a 3332244011",
           "de 3332244012 a 6650940631",
           "de 6650940632 a 9969637251", 
           "de 6650940633 a 13288333871",
           "de 13288333872 a 16607030491",
           "de 16607030492 a 19925727111"))

```

Então geramos o mapa:

```{r mapa3, message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE, fig.height=8, fig.width=12}
library(ggspatial) #pacote para carregar a escala no mapa (funcao annotation_scale)

ggplot(junta)+
  geom_sf(aes(fill=categorias_em_dolares))+
  scale_fill_manual(values=c('#999999','#F3D4D2','#E9A8A2','#E9635A','#C41617','#6A0002'))+
  annotation_scale(location = "br", height = unit(0.2,"cm"))+
  annotation_north_arrow(location="tr", style = north_arrow_nautical, height=unit(1.5,"cm"), width=unit(1.5,"cm"))+
  labs(x = "Longitude", y = "Latitude", title = "Mapa por estado do fluxo de exportações (em US$ FOB)")
  
  
```



Podemos ver que tipo de produto cada estado mais exporta:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
epufncm<-exp%>%
  group_by(SG_UF_NCM, CO_NCM)%>%
  summarise(TotExpUFNCM = sum(VL_FOB))

arrange(epufncm, desc(TotExpUFNCM))
```

Preciso substituir a coluna de códigos do NCM pelo nomes, para vermos o primeiro produto mais exportado por UF:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

epufncm <- left_join(epufncm, ncm %>%
                             select(CO_NCM, NO_NCM_POR), by = c("CO_NCM" = "CO_NCM"))%>%
  select(-CO_NCM)

arrange(epufncm, desc(TotExpUFNCM))
```

Caso queiramos ver quais foram os produtos exportados pelo estado do Paraná nesse ano, fazemos:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
epufncmPR <- epufncm%>%
  filter(SG_UF_NCM == "PR")

arrange(epufncmPR, desc(TotExpUFNCM))

```

## Agregando por país

Baixo os dados dos países:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
#paisesdwnld<-download.file("http://www.mdic.gov.br/balanca/bd/tabelas/PAIS.csv","paises.csv")
paises <- read.csv("paises.csv", sep = ";", encoding = "latin1")

glimpse(paises)

```

Então agrupo as exportações (em US$ FOB) por NCM: (O agrupamento é necessário por uma questão de limitação de processamento e memória)

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
#agrupa exp por pais
exppais<-exp%>%
  group_by(CO_PAIS)%>%
  summarise(Total_PAIS = sum(VL_FOB))

arrange(exppais, desc(Total_PAIS))
```

Caso os nomes dos produtos pelo nome do pais de destino:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
library(tidyverse)
exppais <- left_join(exppais, paises %>%
                             select(CO_PAIS, NO_PAIS), by = c("CO_PAIS" = "CO_PAIS"))%>%
                             mutate(TotExpPais = exppais$Total_PAIS)

glimpse(exppais)

head(exppais)
```

Vamos ver como fica a classificação:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

exppais<-exppais%>%
  select(-Total_PAIS)

arrange(exppais,desc(TotExpPais))

```



## Agregando por via


Baixo os dados descritores dos tipos de via (dicionário):

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
#viadwnld<-download.file("http://www.mdic.gov.br/balanca/bd/tabelas/VIA.csv","via.csv")
via <- read.csv("via.csv", sep = ";", encoding = "latin1")

glimpse(via)

```

Então agrupo as exportações (em US$ FOB) por via: (O agrupamento é necessário por uma questão de limitação de processamento e memória)

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
#agrupa exp por pais
expvia<-exp%>%
  group_by(CO_VIA)%>%
  summarise(Total_VIA = sum(VL_FOB))

arrange(expvia, desc(Total_VIA))
```

Caso os nomes das vias:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
library(tidyverse)
expvia <- left_join(expvia, via %>%
                             select(CO_VIA, NO_VIA), by = c("CO_VIA" = "CO_VIA"))%>%
                             mutate(TotExpVia = expvia$Total_VIA)

glimpse(expvia)

head(expvia)
```

Vamos ver como fica a classificação:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

expvia<-expvia%>%
  select(-Total_VIA)

arrange(expvia,desc(TotExpVia))

```



## Agregando por COD_URF

Baixo os dados descritores dos tipos de códigos na unidade da Receita Federal (dicionário):

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
#urfdwnld<-download.file("http://www.mdic.gov.br/balanca/bd/tabelas/URF.csv","urf.csv")
urf <- read.csv("urf.csv", sep = ";", encoding = "latin1")

glimpse(urf)

```

Então agrupo as exportações (em US$ FOB) por código da receita federal: (O agrupamento é necessário por uma questão de limitação de processamento e memória)

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
#agrupa exp por pais
expurf<-exp%>%
  group_by(CO_URF)%>%
  summarise(Total_URF = sum(VL_FOB))

arrange(expurf, desc(Total_URF))
```

Caso os nomes das URFs:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
library(tidyverse)
expurf <- left_join(expurf, urf %>%
                             select(CO_URF, NO_URF), by = c("CO_URF" = "CO_URF"))%>%
                             mutate(TotExpUrf = expurf$Total_URF)

glimpse(expurf)

head(expurf)
```

Vamos ver como fica a classificação:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

expurf<-expurf%>%
  select(-Total_URF)

arrange(expurf,desc(TotExpUrf))

```


***

## Visualização da base de dados completa 

***

(Abra no modo tela inteira)

<iframe width="600" height="373.5" src="https://app.powerbi.com/view?r=eyJrIjoiNjg2OGVhNzktMTRkNi00ZDc0LTk3YjItNzcyNGVjNjNmMzlmIiwidCI6IjNlNmRhYTJjLTlhYzUtNDhlYS1iMDBlLWE2MWFiYmZmYWNkYiJ9&pageName=ReportSectionfd057912b83c58976702" frameborder="0" allowFullScreen="true"></iframe>


***

### Referências

CRAN _The Comprehensive R Archive Network_. Disponível em < https://cran.r-project.org/ > 

Ministério da Defesa Indústria e Comércio Exterior. Disponível em < http://www.mdic.gov.br/index.php/comercio-exterior/estatisticas-de-comercio-exterior/base-de-dados-do-comercio-exterior-brasileiro-arquivos-para-download > 






