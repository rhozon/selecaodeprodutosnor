---
title: "Consulta e automação a base SECEX/MDiC "
author: "Ozon, R. H."
date: "02/12/2020"
output:
  html_document:
    toc: true
    toc_float: true
---

<!-- ================================================================================= -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#linha para retirar os [1] prefixo de resultados dos output dos comandos do r
# veja https://stackoverflow.com/questions/22524822/how-can-i-remove-the-prefix-index-indicator-1-in-knitr-output/22563357
knitr::opts_chunk$set(opts.label="kill_prefix")
```

```{r include=FALSE}
# cunhk para retiraar os prefixos
default_output_hook <- knitr::knit_hooks$get("output")
# Output hooks handle normal R console output.
knitr::knit_hooks$set( output = function(x, options) {

  comment <- knitr::opts_current$get("comment")
  if( is.na(comment) ) comment <- ""
  can_null <- grepl( paste0( comment, "\\s*\\[\\d?\\]" ),
                     x, perl = TRUE)
  do_null <- isTRUE( knitr::opts_current$get("null_prefix") )
  if( can_null && do_null ) {
    # By default R print output aligns at the right brace.
    align_index <- regexpr( "\\]", x )[1] - 1
    # Two cases: start or newline
    re <- paste0( "^.{", align_index, "}\\]")
    rep <- comment
    x <- gsub( re, rep,  x )
    re <- paste0( "\\\n.{", align_index, "}\\]")
    rep <- paste0( "\n", comment )
    x <- gsub( re, rep,  x )
  }

  default_output_hook( x, options )

})

knitr::opts_template$set("kill_prefix"=list(comment=NA, null_prefix=TRUE))

```

<!-- ================================================================================= -->

***

[em construção...]


![](https://vidadeempresa.com.br/wp-content/uploads/2018/12/shutterstock_x1ZxQ2N.jpghttps://vidadeempresa.com.br/wp-content/uploads/2018/12/shutterstock_x1ZxQ2N.jpg){width=80%}


## Download dos dados e conversão do formato

No chunk abaixo rodamos um procedimento de busca e coleta da base de dados completa das exportações e importações nacionais no período compreendido entre jan/1997 até o último mês disponível. Ao rodar o chunk a cada mês ele atualiza os arquivos, (se houver nova publicação no SECEX) sem a necessidade de baixá-los do site toda vez. 

Descomente o chunk (retirando as cerquilhas) onde os comandos estão presentes caso queira reproduzir na sua máquina ou adapte para setar um outro repositório para armazenar os arquivos.


```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

#Baixa a serie completa
#url_exp <- download.file("http://www.mdic.gov.br/balanca/bd/comexstat-bd/ncm/EXP_COMPLETA.zip") #Exportacoes
#url_imp <- download.file("http://www.mdic.gov.br/balanca/bd/comexstat-bd/ncm/IMP_COMPLETA.zip") #Importacoes

#Escrevo num local temporario
#temp_exp <- tempfile()
#temp_imp <- tempfile()

#Insiro os arquivos .zip na pasta local temporaria
#download.file(url_exp, temp_exp)
#download.file(url_imp, temp_imp)

#Deszipa os arquivos
#unzip_exp <- unz(temp_exp, "EXP_COMPLETA.csv") #Extrai as exportacoes na base completa
#unzip_imp <- unz(temp_imp, "IMP_COMPLETA.csv") #Extrai as importacoes na base completa
```

Após guardá-lo em um determinado local estipule uma rotina de em determinado dia do mês rodar o chunk acima para atualizar os arquivos da base completa.

Você poderá atualizar os arquivos quando criar um modelo de visualização de dados (assim como eu fiz uma usando o Power BI no final deste documento) sem se preocupar em reorganizá-los ou fazer o procedimento todo novamente. 

Isso lhe fornece velocidade e minimiza substancialmente quaisquer erros humanos no processo.

Neste tutorial, trabalho com um ETL menor para os dados de exportação disponível no último mês, como demonstração. Utilizo a linguagem R aqui dentro de um documento do tipo RMarkdown para elucidar mais claramente as nossas possibilidades.



## Pauta de Exportações

Primeiro baixo os dados de exportação:


```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
#expdwnld<-download.file("http://www.mdic.gov.br/balanca/bd/comexstat-bd/ncm/EXP_2020.csv", "exp.csv")
exp<-read.csv("exp.csv", head=TRUE, sep=";", encoding = "latin1")

head(exp)

#library(vctrs)
library(dplyr)
glimpse(exp)

```

## Agregando por mês/ano


Concateno CO_ANO com CO_MES

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE} 

library(tidyverse)

exp<-exp%>%
  mutate(CO_MES = formatC(CO_MES, width = 2, flag = "0")) # Arrumo pra dois digitos no mes

library(lubridate)

exp$AnoMes<- str_c(exp$CO_ANO,"/",exp$CO_MES) # uno uma coluna com a outra e chamo ela de AnoMes

glimpse(exp)

colSums(is.na(exp)) # Conta quantos missings temos em cada variavel

```

Agrego por período e organizo de modo decrescente temporalmente:


```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

expper<- exp %>%
  group_by(AnoMes)%>%
  summarise(TotalExp_AnoMes = sum(VL_FOB, na.rm = TRUE))

arrange(expper, AnoMes)

```

Vamos ver num gráfico:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE, fig.width=8}
library(plotly)
library(ggplot2)

ggplotly(ggplot(expper, aes(x=AnoMes, y=paste("US$ (FOB):",round(TotalExp_AnoMes/10^7,digits=2)), group=1))+
  geom_line(color="red")+
  geom_point(color="red")+ 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
        axis.title.y = element_blank())+
  labs(title="Exportações brasileiras em 2020 (em milhões de US$ FOB)"))


```

Agora seleciono algumas variáveis daqui e construo um dataframe:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

exp2020 <- exp%>%
  select(AnoMes, CO_NCM, CO_PAIS, SG_UF_NCM, CO_VIA, CO_URF, VL_FOB)

exp2020<-as.data.frame(exp2020)

glimpse(exp2020)

```




## Agregando por NCM

Baixo os dados de código NCM e nome

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
#ncmdwlnd<-download.file("http://www.mdic.gov.br/balanca/bd/tabelas/NCM.csv","NCM.csv")
ncm <- read.csv("NCM.csv", sep = ";", encoding = "latin1")

glimpse(ncm)
```







Então agrupo as exportações (em US$ FOB) por NCM: (O agrupamento é necessário por uma questão de limitação de processamento e memória)

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
#agrupa exp por ncm
expncm<-exp%>%
  group_by(CO_NCM)%>%
  summarise(Total_NCM = sum(VL_FOB, na.rm=TRUE))%>%
  mutate(NCM_percentual = (Total_NCM/sum(Total_NCM))*100)


options(scipen = 999) #nao mostra os numeros em notacao cientifica
arrange(expncm, desc(Total_NCM))
```

Caso os nomes dos produtos pelo NCM:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
library(tidyverse)
expncm <- left_join(expncm, ncm %>%
                             select(CO_NCM, NO_NCM_POR), by = c("CO_NCM" = "CO_NCM"))%>%
                             mutate(TotExpNCM = expncm$Total_NCM)

expncm <- left_join(expncm, ncm %>%
                      select(CO_NCM, CO_ISIC_CLASSE), by = c("CO_NCM" = "CO_NCM"))

expncm<-expncm%>%
  select(-Total_NCM) #tiro fora a soma pra nao ficar em duplicidade

glimpse(expncm)

```


Baixo a tabela de NCM ISIC por classe pra saber os nomes (mais agregados) dos grupos de macroprodutos:


```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
ncmisicdwlnd<-download.file("http://www.mdic.gov.br/balanca/bd/tabelas/NCM_ISIC.csv","NCM_ISIC.csv")
ncmisic <- read.csv("NCM_ISIC.csv", sep = ";", encoding = "latin1")

glimpse(ncmisic)
```

Agora faço o join pra casar o código isic com os nomes:
```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
expncm <- left_join(expncm, ncmisic %>%
                      select(CO_ISIC_CLASSE, NO_ISIC_CLASSE), by = c("CO_ISIC_CLASSE" = "CO_ISIC_CLASSE"))
    

glimpse(expncm)

```
A seguir insiro os nomes dos produtos (NCMs) na tabela de exportações:


```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

exp2020 <- left_join(exp2020, ncm %>%
                             select(CO_NCM, NO_NCM_POR), by = c("CO_NCM" = "CO_NCM"))


```



Faço um agrupamento por NCM e período:



```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

exp2020resumo<- exp2020%>%
  group_by(CO_NCM, AnoMes)%>%
  summarise(ExportNCM = sum(VL_FOB, na.rm = TRUE))

glimpse(exp2020resumo)

```

Agora faço o join pra inserir a variável de nome de NCM e nome de ISIC:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

exp2020resumo <- left_join(exp2020resumo, ncm %>%
                             select(CO_NCM, NO_NCM_POR), by = c("CO_NCM" = "CO_NCM"))

exp2020resumo <- left_join(exp2020resumo, ncm %>%
                      select(CO_NCM, CO_ISIC_CLASSE), by = c("CO_NCM" = "CO_NCM"))

exp2020resumo <- left_join(exp2020resumo, ncmisic %>%
                      select(CO_ISIC_CLASSE, NO_ISIC_CLASSE), by = c("CO_ISIC_CLASSE" = "CO_ISIC_CLASSE"))

glimpse(exp2020resumo)
```






Vamos filtrar por um grupo mais agregado ao longo do tempo usando os grupos ISIC:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

exp2020resumoa<-exp2020resumo%>%
  group_by(AnoMes, NO_ISIC_CLASSE)%>%
  summarise(Total_ISIC = sum(ExportNCM))

arrange(exp2020resumoa,AnoMes)

```


Insiro a soma do ISIC na tabela exp2020resumo:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

exp2020resumo <- left_join(exp2020resumo, exp2020resumoa %>%
                             select(NO_ISIC_CLASSE, Total_ISIC), by = c("NO_ISIC_CLASSE" = "NO_ISIC_CLASSE"))

exp2020resumo<-exp2020resumo%>%
  select(-AnoMes.y)%>%
  rename(AnoMes = AnoMes.x)

glimpse(exp2020resumo)
```


Agora podemos ver como fica numa visualização gráfica:

```{r}
#library(highcharter)

#treemap <- exp2020resumo %>%
#  hchart(
#    "treemap", 
#    hcaes(x = NO_ISIC_CLASSE, value = Total_ISIC, color = Total_ISIC)
#    )

#treemap
```



Em seguida faremos um gráfico animado:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

```






Caso queiramos ver como fica a lista de importância por produtos em 2020 até o último mês disppnível, veremos como fica a classificação:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

arrange(expncm,desc(TotExpNCM))

```



Podemos filtrar aqueles que possuem a string "soja" no nome do produto (NCM):

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

expncmsoja<-expncm%>%
  filter(grepl("soja", NO_NCM_POR ) | grepl("Soja", NO_NCM_POR))

arrange(expncmsoja, desc(NCM_percentual))

```

Ou então poderíamos filtrar com base em diferentes strings de produtos:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

expncmprodutos<-expncm%>%
  filter(grepl("soja", NO_NCM_POR ) | grepl("Soja", NO_NCM_POR) |
         grepl("milho", NO_NCM_POR ) | grepl("Milho", NO_NCM_POR) |
         grepl("açúcar", NO_NCM_POR ) | grepl("Açúcar", NO_NCM_POR))

arrange(expncmprodutos,desc(NCM_percentual))

```

Você poderia exportar esta tabela filtrada para um arquivo do tipo .csv:


```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

write.csv(expncmprodutos, "expncmprodutos.csv")

```

Poderíamos calcular uma estimativa de participação neste ano de 2020 da lista de nossos produtos exportados em relação ao total exportado pelo Brasil fazendo:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

round((sum(expncmprodutos$TotExpNCM, na.rm=TRUE)/sum(expncm$TotExpNCM, na.rm=TRUE))*100,digits = 2) 

```

Ou seja, cerca de `r round((sum(expncmprodutos$TotExpNCM, na.rm=TRUE)/sum(expncm$TotExpNCM, na.rm=TRUE))*100,digits=2)`% dos nossos produtos tiveram representatividade na pauta exportadora brasileira de janeiro até o último mês disponível na base de 2020.


Finalmente eu crio a tabela com somente os 10 primeiros produtos exportados no Brasil, por ordem de valor em dólares FOB:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

topten<-expncm%>%
  top_n(TotExpNCM, n=10)

arrange(topten, desc(TotExpNCM))

```  


Vamos ver como fica a participação acumulada (de jan 2020 até o último mês disponível) 


```{r message=FALSE, warning=FALSE}
library(highcharter)

tmap <- expncm %>%
  hchart(
    "treemap", 
    hcaes(x = NO_NCM_POR, value = TotExpNCM, color = TotExpNCM)
    )

tmap
```


Também podemos transformo esses dados resumidos em um dataframe, classificando pelo ISIC:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

expncmdf<-as.data.frame(expncm)

glimpse(expncmdf)

expncmdf<-expncmdf%>%
  group_by(NO_ISIC_CLASSE)%>%
  summarise(ISIC_TotExp = sum(TotExpNCM))

arrange(expncmdf,desc(ISIC_TotExp))

```





## Agregando por UF

Provavelmente o estado que mais exporta deverá ser o de São Paulo. Vamos verificar em quanto:


```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

expuf <- exp%>%
  group_by(SG_UF_NCM)%>%
  summarise(TotalExp_UF = sum(VL_FOB, na.rm = TRUE)) %>%
            mutate(ExpUFpercentual = (TotalExp_UF/sum(TotalExp_UF))*100)

arrange(expuf, desc(TotalExp_UF))

```

Vamos ver como ficam as descritivas:

Parâmetro | Valor (TotalExp_UF)
--------- | ------
Mínimo:   | ``r min(expuf$TotalExp_UF)/10^7``
Média:    | ``r mean(expuf$TotalExp_UF)/10^7``
Máximo:   | ``r max(expuf$TotalExp_UF)/10^7``



Determino o intervalo adequado de classe conforme [Regra de Sturges:](https://maestrovirtuale.com/regra-de-sturges-explicacao-aplicacoes-e-exemplos/#:~:text=A%20regra%20Sturges%20%C3%A9%20um%20m%C3%A9todo%20emp%C3%ADrico%20amplamente%20usado%20em,representando%20uma%20amostra%20ou%20popula%C3%A7%C3%A3o.&text=%E2%80%93%20N%20%C3%A9%20o%20n%C3%BAmero%20total%20de%20observa%C3%A7%C3%B5es%20na%20amostra.)


```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

k <- 1 + 3.322*log10(28)

round(k,digits = 0) # Numero ideal de classes a serem utilizadas

amplitude <- (max(expuf$TotalExp_UF) - min(expuf$TotalExp_UF)) / k

amplitude #Tamanho do intervalo

```

Os intervalos de classe são obtidos então:


```{r}
primclassmin <- min(expuf$TotalExp_UF)
primclassmax <- (min(expuf$TotalExp_UF) + amplitude - 1)

segclassmin <- primclassmax +1
segclassmax <- (segclassmin + amplitude -1)

terclassmin <- segclassmax +1
terclassmax <- (terclassmin + amplitude -1)

quaclassmin <- terclassmax +1
quaclassmax <- (quaclassmin + amplitude -1)

quiclassmin <- quaclassmax +1
quiclassmax <- (quiclassmin + amplitude -1)

sexclassmin <- quiclassmax +1
sexclassmax <- (sexclassmin + amplitude -1)

```


Então determinamos os intervalos de classes. P. ex., a primeira classe vai de ``r min(expuf$TotalExp_UF)/1000000`` até ``r (min(expuf$TotalExp_UF) + amplitude - 1)/1000000``. (Os valores foram divididos por 10000000 para facilitar a leitura)


Classe    | Intervalo
--------- | ------
Primeira:  | de ``r primclassmin/10^7`` até ``r primclassmax/10^7``
Segunda:  | de ``r segclassmin/10^7`` até ``r segclassmax/10^7``
Terceira:  | de ``r terclassmin/10^7`` até ``r terclassmax/10^7``
Quarta:    | de ``r quaclassmin/10^7`` até ``r quaclassmax/10^7``
Quinta:    | de ``r quiclassmin/10^7`` até ``r quiclassmax/10^7``
Sexta:     | de ``r sexclassmin/10^7`` até ``r sexclassmax/10^7``


Podemos também observar o novo dataset agrupado:
```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

write.csv(expuf, "expuf.csv")

```


Renomeio o nome da coluna SG_UF_NCM pra fazer o join:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

colnames(expuf)[1] <- "abbrev_state"

```


Vamos ver no mapa como fica. Inicialmente carrego as bibliotecas:


```{r mapa, message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

library(tmap)
library(sf)
library(leaflet)
library(tmaptools)
library(geobr)

uf <- read_state(code_state="all", showProgress = FALSE)

```

Agora faço a junção:

```{r mapa2, message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

junta <- full_join(uf, expuf, by="abbrev_state")

```


Em seguida crio as categorias de classes pro mapa:

```{r mapa4, message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

junta$categorias_em_dolares<-
  cut(junta$TotalExp_UF,
      breaks=c(0, 3332244011, 6650940631, 9969637251, 13288333871, 16607030491, 19925727111),
  labels=c("de 13547392 a 3332244011",
           "de 3332244012 a 6650940631",
           "de 6650940632 a 9969637251", 
           "de 6650940633 a 13288333871",
           "de 13288333872 a 16607030491",
           "de 16607030492 a 19925727111"))

```

Então geramos o mapa:

```{r mapa3, message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE, fig.height=8, fig.width=12}

library(ggspatial) #pacote para carregar a escala no mapa (funcao annotation_scale)

ggplot(junta)+
  geom_sf(aes(fill=categorias_em_dolares))+
  scale_fill_manual(values=c('#999999','#F3D4D2','#E9A8A2','#E9635A','#C41617','#6A0002'))+
  annotation_scale(location = "br", height = unit(0.2,"cm"))+
  annotation_north_arrow(location="tr", style = north_arrow_nautical, height=unit(1.5,"cm"), width=unit(1.5,"cm"))+
  labs(x = "Longitude", y = "Latitude", title = "Mapa por estado do fluxo de exportações (em US$ FOB)")
  
  
```

Ou então de um modo mais simples gero um mapa com as classes de cores graduada de modo automático pelo R.


```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

tm_shape(junta)+
  tm_polygons("TotalExp_UF", id="abbrev_state", palette = "Reds")

```

Tento criar um mapa interativo:


```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

tmap_mode("view")
tmap_last()

```

```{r}

str(junta) # Soh uma olhada nos dados que foram juntados

```

Um outro modelo de mapa no R pode ser gerado usando:

```{r eval=FALSE}

library(viridis)
junta %>% 
   ggplot(aes(fill = TotalExp_UF), color = "black") +
    geom_sf() + 
    scale_fill_viridis(name = "Exportações por UF", direction = -1)

```


Uma visualização de mapa mais adequada pode ser obtida com uma certa interatividade. Primeiro gero os centróides dos pontos no mapa:

```{r}

coord_pontos <- junta %>% 
                  mutate(ExpUFpercentual = TotalExp_UF/sum(TotalExp_UF,na.rm = FALSE)) %>% 
                  st_centroid()

#ggplot(junta)+ 
#  geom_sf() + 
#  geom_sf(data = coord_pontos, aes(size = ExpUFpercentual), col = "blue", alpha = .65,
#          show.legend = "point") + 
#  scale_size_continuous(name = "Exportações UF/US$ 1 MIlhão")

```

Em seguida geramos o mapa:

```{r}

data.frame(st_coordinates(coord_pontos), 
           ExpUFpercentual = coord_pontos$ExpUFpercentual, 
           UF = coord_pontos$abbrev_state) %>% 
  leaflet() %>% 
    addTiles() %>%
    addCircleMarkers(~ X, ~ Y,
                     label = ~ as.character(paste0(UF, ": ", round(ExpUFpercentual*100,digits = 2), "%")),
                     labelOptions = labelOptions(textsize = "13px"),
                     radius = ~ ExpUFpercentual*100,
                     fillOpacity = 0.5)

```




Podemos ver que tipo de produto cada estado mais exporta:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

epufncm<-exp%>%
  group_by(SG_UF_NCM, CO_NCM)%>%
  summarise(TotExpUFNCM = sum(VL_FOB))

arrange(epufncm, desc(TotExpUFNCM))

```

Preciso substituir a coluna de códigos do NCM pelo nomes, para vermos o primeiro produto mais exportado por UF:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

epufncm <- left_join(epufncm, ncm %>%
                             select(CO_NCM, NO_NCM_POR), by = c("CO_NCM" = "CO_NCM"))%>%
  select(-CO_NCM)

arrange(epufncm, desc(TotExpUFNCM))
```

Caso queiramos ver quais foram os produtos exportados pelo estado do Paraná nesse ano, fazemos:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
epufncmPR <- epufncm%>%
  filter(SG_UF_NCM == "PR")

arrange(epufncmPR, desc(TotExpUFNCM))

```

## Agregando por país de destino

Baixo os dados dos países:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
#paisesdwnld<-download.file("http://www.mdic.gov.br/balanca/bd/tabelas/PAIS.csv","paises.csv")
paises <- read.csv("paises.csv", sep = ";", encoding = "latin1")

glimpse(paises)

```

Então agrupo as exportações (em US$ FOB) por NCM: (O agrupamento é necessário por uma questão de limitação de processamento e memória)

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
#agrupa exp por pais
exppais<-exp%>%
  group_by(CO_PAIS)%>%
  summarise(Total_PAIS = sum(VL_FOB,na.rm=TRUE))%>%
  mutate(Participacao_pais = (Total_PAIS/sum(Total_PAIS))*100)

arrange(exppais, desc(Participacao_pais))
```


Caso os nomes dos produtos pelo nome do pais de destino:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
library(tidyverse)
exppais <- left_join(exppais, paises %>%
                             select(CO_PAIS, NO_PAIS), by = c("CO_PAIS" = "CO_PAIS"))%>%
                             mutate(TotExpPais = exppais$Total_PAIS)

glimpse(exppais)

head(exppais)
```

Vamos ver como fica a classificação:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

exppais<-exppais%>%
  select(-Total_PAIS)

arrange(exppais,desc(TotExpPais))

```

Podemos visualizar quais os principais destinos de nossas exportações nesse ano projetando um mapa. Primeiramente eu busco uma tabela contendo os dados de latitudes e longitudes dos países:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

latlong<- read.csv(file="https://raw.githubusercontent.com/rhozon/datasets/master/isoa3paises.csv", head=TRUE, sep=";")

str(latlong)

```

Renomeio as colunas de latitude e longitude:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}


colnames(latlong)[3]<-"lat"
colnames(latlong)[4]<-"long"
colnames(latlong)[5]<-"CO_PAIS"

glimpse(latlong)

```



Faço um join com a tabela de exportações por país:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

exppais <- left_join(exppais, paises %>%
                             select(CO_PAIS, CO_PAIS), by = c("CO_PAIS" = "CO_PAIS"))

str(exppais)
```

Também precisamos inserir o código ISOA3 dos nomes dos países:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

exppais<- left_join(exppais, latlong %>%
                      select(CO_PAIS, ISOA3), by = c("CO_PAIS" = "CO_PAIS"))
                    
glimpse(exppais)                    
```

Em seguida a latitude

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
exppais<- left_join(exppais, latlong %>%
                      select(CO_PAIS, lat), by = c("CO_PAIS" = "CO_PAIS"))
                    
glimpse(exppais)  

```

e também a longitude

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
exppais<- left_join(exppais, latlong %>%
                      select(CO_PAIS, long), by = c("CO_PAIS" = "CO_PAIS"))
                    
glimpse(exppais)  

```


Vamos ver se o mapa com o leaflet sai:
```{r}
library(leaflet)

# Cria as labels dos popups
make_label <- function(pais, vlrexportado) {
  txt <- stringr::str_glue(
    "<b>País</b>: {pais}<br>",
    "<b>Exportações</b>: {vlrexportado}"
  )
  htmltools::HTML(txt)
}


mapaleaflet<-exppais %>% 
  mutate(lab = map2(NO_PAIS, TotExpPais, make_label)) %>%
  leaflet() %>% 
  addTiles() %>% 
  addMarkers(lng = ~long, lat = ~lat, popup = ~lab,
             clusterOptions = markerClusterOptions())

mapaleaflet
```




## Agregando por via

Por qual modal o fluxo financeiro da pauta de exportações tupiniquim é mais proeminente ? Será que o rodoviário (mais caro) é também o mais eficiente ?


Baixo os dados descritores dos tipos de via (dicionário):

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
#viadwnld<-download.file("http://www.mdic.gov.br/balanca/bd/tabelas/VIA.csv","via.csv")
via <- read.csv("via.csv", sep = ";", encoding = "latin1")

glimpse(via)

```

Então agrupo as exportações (em US$ FOB) por via: (O agrupamento é necessário por uma questão de limitação de processamento e memória)

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
#agrupa exp por pais
expvia<-exp%>%
  group_by(CO_VIA)%>%
  summarise(Total_VIA = sum(VL_FOB))

arrange(expvia, desc(Total_VIA))
```

Caso os nomes das vias:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
library(tidyverse)
expvia <- left_join(expvia, via %>%
                             select(CO_VIA, NO_VIA), by = c("CO_VIA" = "CO_VIA"))%>%
                             mutate(TotExpVia = expvia$Total_VIA)

glimpse(expvia)

head(expvia)
```

Vamos ver como fica a classificação:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

expvia<-expvia%>%
  select(-Total_VIA)

arrange(expvia,desc(TotExpVia))

```



## Agregando por COD_URF

Baixo os dados descritores dos tipos de códigos na unidade da Receita Federal (dicionário):

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
#urfdwnld<-download.file("http://www.mdic.gov.br/balanca/bd/tabelas/URF.csv","urf.csv")
urf <- read.csv("urf.csv", sep = ";", encoding = "latin1")

glimpse(urf)

```

Então agrupo as exportações (em US$ FOB) por código da receita federal: (O agrupamento é necessário por uma questão de limitação de processamento e memória)

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
#agrupa exp por pais
expurf<-exp%>%
  group_by(CO_URF)%>%
  summarise(Total_URF = sum(VL_FOB))

arrange(expurf, desc(Total_URF))
```

Caso os nomes das URFs:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}
library(tidyverse)
expurf <- left_join(expurf, urf %>%
                             select(CO_URF, NO_URF), by = c("CO_URF" = "CO_URF"))%>%
                             mutate(TotExpUrf = expurf$Total_URF)

glimpse(expurf)

head(expurf)
```

Vamos ver como fica a classificação:

```{r message=FALSE, warning=FALSE, comment=NA, null_prefix=TRUE}

expurf<-expurf%>%
  select(-Total_URF)

arrange(expurf,desc(TotExpUrf))

```


***

## Visualização da base de dados completa 

***

(Abra no modo tela inteira)

<iframe width="600" height="373.5" src="https://app.powerbi.com/view?r=eyJrIjoiNjg2OGVhNzktMTRkNi00ZDc0LTk3YjItNzcyNGVjNjNmMzlmIiwidCI6IjNlNmRhYTJjLTlhYzUtNDhlYS1iMDBlLWE2MWFiYmZmYWNkYiJ9&pageName=ReportSectionfd057912b83c58976702" frameborder="0" allowFullScreen="true"></iframe>


***

### Referências

CRAN _The Comprehensive R Archive Network_. Disponível em < https://cran.r-project.org/ > 

Ministério da Defesa Indústria e Comércio Exterior. Disponível em < http://www.mdic.gov.br/index.php/comercio-exterior/estatisticas-de-comercio-exterior/base-de-dados-do-comercio-exterior-brasileiro-arquivos-para-download > 






