---
title: "Previsão (forecasting), simulação de cenários e análise de séries temporais"
author: "Rodrigo Hermont Ozon"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: true
    toc_float: true
params:
  symbol1: CORN
  symbol2: CN21.CBT
  symbol3: Cz21.CBT
  symbol4: CU21.CBT
  symbol5: CH22.CBT
  symbol6: CK22.CBT
  symbol7: ZC=F
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE,
	comment = NA
)
knitr::opts_chunk$set(comment = NA) # Remove todos os coments # dos outputs do R
knitr::opts_chunk$set(warning = FALSE) # Remove todos os warnings # dos outputs do R
knitr::opts_chunk$set(message = FALSE) # Remove todas as mensagens # dos outputs do R

```


***

<style>
p.comment {
background-color: #DBDBDB;
padding: 10px;
border: 1px solid black;
margin-left: 25px;
border-radius: 5px;
font-style: italic;
}

</style>

<div class="alert alert-info">

  <strong>Economic Time Series Forecasting</strong> 
 
</div>



<p >
<p style="font-family: times, serif; font-size:11pt; font-style:italic"; class="comment">

Uma série temporal é um conjunto de observações dos valores que uma variável assume em diferentes
momentos do tempo.

Enquanto que o forecasting envolve fazer previsões sobre o futuro. É necessário em muitas situações: 

- decidir se construirá outra usina de geração de energia nos próximos dez anos requer previsões de demanda futura; 

- agendar equipe em um call center na próxima semana exige previsões de volumes de chamadas; 

- armazenar um estoque requer previsões de necessidades de estoque. 

As previsões podem ser exigidas com vários anos de antecedência (para o caso de investimentos de capital), ou apenas alguns minutos antes (para roteamento de telecomunicações). Quaisquer que sejam as circunstâncias ou horizontes de tempo envolvidos, a previsão (forecasting) é uma ajuda importante para um planejamento eficaz e inteligente.

</p>

***



![](https://rhozon.github.io/site/me.jpg)

```{r echo=FALSE}

# Libraries
library(igraph)
library(networkD3)
library(dplyr)

# A = Economia
# B = Econometria
# C = Microeconometria
# D = Modelos preditivos
# E = Métodos estatísticos
# K = Data Viz
# M = Data Science
# Z = Linguagem R
# Y = Séries Temporais (forecasting)


# create a dataset:
data <- data_frame(
  from=c("Economia", "Economia", "Econometria", "Modelos preditivos", "Microeconometria", "Modelos preditivos", "Métodos estatísticos", "Econometria", "Microeconometria", "Modelos preditivos", "Data Viz", "Economia", "Data Science", "Séries Temporais (forecasting)"),
  
  to=c("Econometria", "Métodos estatísticos", "Analytics", "Economia", "Microeconometria", "Economia", "Econometria", "Linguagem R", "Economia", "Microeconometria", "Economia", "Econometria", "Data Viz", "Econometria")
)

# Plot
p <- simpleNetwork(data, height="100px", width="100px",        
        Source = 1,                 # column number of source
        Target = 2,                 # column number of target
        linkDistance = 10,          # distance between node. Increase this value to have more space between nodes
        charge = -900,                # numeric value indicating either the strength of the node repulsion (negative value) or attraction (positive value)
        fontSize = 14,               # size of the node names
        fontFamily = "serif",       # font og node names
        linkColour = "#666",        # colour of edges, MUST be a common colour for the whole graph
        nodeColour = "#69b3a2",     # colour of nodes, MUST be a common colour for the whole graph
        opacity = 0.9,              # opacity of nodes. 0=transparent. 1=no transparency
        zoom = T                    # Can you zoom on the figure?
        )

p


```


***

$$\\[1in]$$


***

# Conceitos iniciais

_Uma série temporal é um conjunto de observações dos valores que uma variável assume em diferentes momentos do tempo._ Esses dados podem ser coletados a intervalos regulares, como diariamente (preços das ações, relatórios meteorológicos), semanalmente (informações sobre oferta de moeda), mensalmente (taxa de desemprego, índice de preços ao consumidor [IPC]), trimestralmente (PIB), anualmente (orçamento do governo), quinquenalmente, isto é, a cada cinco anos (censo industrial dos Estados Unidos), ou decenalmente (censo demográfico). Às vezes, os dados estão disponíveis em séries trimestrais e anuais, como no caso do PIB e das despesas de consumo. Com o advento dos computadores de alta velocidade, _os <mark>dados agora podem ser coletados a intervalos extremamente curtos, como os relativos a preços das ações, obtidos de forma praticamente contínua (as chamadas cotações em tempo real)</mark>._



***

# Carregando as bibliotecas necessárias

```{r}

library(TTR)
library(FinTS)
library(rugarch)
library(zoo)
library(dynlm)
library(broom)
library(seasonal)
library(urca)
library(vars)
library(TSstudio)
library(timetk)
library(lmtest)
library(quantmod)
library(dygraphs)
library(tidyverse)
library(dplyr)
library(plotly)
library(ggplot2)
library(nonlinearTseries)
library(forecast)
library(astsa)
library(prophet)
library(DT)
library(fpp2)
library(tsbox)
library(lubridate)
library(data.table)
library(funtimes)
library(tseries)
library(strucchange)

```

# Ativos relacionados a _commoditie_ milho

Esse relatório capta dinamicamente as cotações dos seguintes ativos relacionados as negociações da _commoditie_ milho:
  
* ``r params$symbol1`` [CORN (Teucrium Corn Fund)](https://finance.yahoo.com/quote/CORN?p=CORN) $\Rightarrow$ <mark>última cotação ``r Sys.Date()-1``.</mark>

* ``r params$symbol2`` [CN21.CBT](https://finance.yahoo.com/quote/CN21.CBT/history?p=CN21.CBT) $\Rightarrow$ ``r Sys.Date()-1``

* ``r params$symbol3`` [Cz21.CBT](https://finance.yahoo.com/quote/CZ21.CBT/) $\Rightarrow$ ``r Sys.Date()-1``

* ``r params$symbol4`` [CU21.CBT](https://finance.yahoo.com/quote/CU21.CBT/) $\Rightarrow$ ``r Sys.Date()-1``

* ``r params$symbol5`` [CH22.CBT](https://finance.yahoo.com/quote/CH22.CBT/) $\Rightarrow$ ``r Sys.Date()-1``

* ``r params$symbol6`` [CK22.CBT](https://finance.yahoo.com/quote/CK22.CBT/) $\Rightarrow$ ``r Sys.Date()-1``

* ``r params$symbol7`` [ZC=F](https://finance.yahoo.com/quote/ZC%3DF/history?p=ZC%3DF) $\Rightarrow$ ``r Sys.Date()-1``

Os dados são oriundos do [Yahoo finance](http://finance.yahoo.com). As séries temporais se iniciam em 01/01/2018 e terminam no último valor de fechamento disponível na série, quase que em _real time_.


Vejamos as disponibilidades de cada um deles:

```{r}

CORN <- getSymbols("CORN", auto.assign = FALSE,
                    from = "1994-01-01", end = Sys.Date())

data_inicio <- start(CORN)
data_inicio # Mostra o primeiro registro disponivel na serie
data_fim <- end(CORN)
data_fim # Mostra o ultimo registro disponivel na serie

```

```{r}

CN21.CBT <- getSymbols("CN21.CBT", auto.assign = FALSE,
                    from = "1994-01-01", end = Sys.Date())

data_inicio <- start(CN21.CBT)
data_inicio # Mostra o primeiro registro disponivel na serie
data_fim <- end(CN21.CBT)
data_fim # Mostra o ultimo registro disponivel na serie

```

```{r}

Cz21.CBT <- getSymbols("Cz21.CBT", auto.assign = FALSE,
                    from = "1994-01-01", end = Sys.Date())

data_inicio <- start(Cz21.CBT)
data_inicio # Mostra o primeiro registro disponivel na serie
data_fim <- end(Cz21.CBT)
data_fim # Mostra o ultimo registro disponivel na serie

```

```{r}

CU21.CBT <- getSymbols("CU21.CBT", auto.assign = FALSE,
                    from = "1994-01-01", end = Sys.Date())

data_inicio <- start(CU21.CBT)
data_inicio # Mostra o primeiro registro disponivel na serie
data_fim <- end(CU21.CBT)
data_fim # Mostra o ultimo registro disponivel na serie

```

```{r}

CH22.CBT <- getSymbols("CH22.CBT", auto.assign = FALSE,
                    from = "1994-01-01", end = Sys.Date())

data_inicio <- start(CH22.CBT)
data_inicio # Mostra o primeiro registro disponivel na serie
data_fim <- end(CH22.CBT)
data_fim # Mostra o ultimo registro disponivel na serie

```

```{r}

CK22.CBT <- getSymbols("CK22.CBT", auto.assign = FALSE,
                    from = "1994-01-01", end = Sys.Date())

data_inicio <- start(CK22.CBT)
data_inicio # Mostra o primeiro registro disponivel na serie
data_fim <- end(CK22.CBT)
data_fim # Mostra o ultimo registro disponivel na serie

```

```{r}

ZC_F <- getSymbols("ZC=F", auto.assign = FALSE,
                    from = "1994-01-01", end = Sys.Date())

data_inicio <- start(ZC_F)
data_inicio # Mostra o primeiro registro disponivel na serie
data_fim <- end(ZC_F)
data_fim # Mostra o ultimo registro disponivel na serie

```




# Análise do ativo ``CORN``

Para começarmos baixamos os dados do Yahoo Finances usando os comandos abaixo:

```{r}

CORN <- getSymbols("CORN", auto.assign = FALSE,
                    from = "1994-01-01", end = Sys.Date())

data_inicio <- start(CORN)
data_inicio # Mostra o primeiro registro disponivel na serie
data_fim <- end(CORN)
data_fim # Mostra o ultimo registro disponivel na serie

```

A seguir inspecionamos os dados extraídos e visualizamos seu comportamento no tempo:


```{r fig.width=8, fig.height=3}

glimpse(CORN) # Perfil dos dados

# Função log retornos
ret<-function(x,k=1){
  return(diff(log(x),k))
}

grupo <- cbind(Cl(CORN), ret(Cl(CORN),1), Vo(CORN), ret(Vo(CORN),1))

dygraph(Cl(CORN), group = "grupo") %>% dyRangeSelector() # Grafico das cotacoes de Fechamento
dygraph(ret(Cl(CORN),1), group = "grupo") %>% dyRangeSelector() # Grafico dos retornos do Fechamento

dygraph(Vo(CORN), group = "grupo") %>% dyRangeSelector()  # Grafico do Volume negociado
dygraph(ret(Vo(CORN),1), group = "grupo") %>% dyRangeSelector() # Grefico dos retornos do Volume de negociacao

```

A função de log retornos acima demonstrada foi elaborada conforme recomendação presente na literatura. A sua construção e justificativa, seguem as recomendações presentes em Morettin (2006):

_"Um dos objetivos em finanças é avaliação de riscos de uma carteira de ativos (instrumentos) financeiros. O risco é frequentemente medido em termos de variações de preços dos ativos._

_Denotemos por $P_t$ o preço de um ativo no instante $t$, normalmente um dia de negócio._ _Suponha, primeiramente, que não haja dividendos pagos no período. A variação de preços entre os instantes_ $t-1$ e $t$ _é dada por_ $\Delta P_t = P_t - P_{t-1}$ _e a variação relativa de preços ou retorno líquido simples deste ativo entre os mesmos instantes é definido por:_


$$
R_t = \displaystyle\frac{P_t-P_{t-1}}{P_t}
$$

_Note que_ $R_t = P_t/P_{t-1}$: _Chamamos_ $1 + R_t = P_t-P_{t-1}$ _de retorno bruto simples. Usualmente expressamos $R_t$ em percentagem, relativamente ao período (um dia, um mês, um ano, etc).É também chamado de taxa de retorno._

_Denotando_ $pt = log Pt$ _(sendo o logaritmo na base $e$), definimos _o retorno composto continuamente_ _ou simplesmente log-retorno como_

$$
r_t = log\frac{P_t}{P_{t-1}} = log(1+R_t) = p_t - p_{t-1}
$$


_E<mark>sta definição será aquela comumemente utilizada e, muitas vezes, $r_t$ será chamado simplesmente de retorno.</mark>"_

<p >
<p style="font-family: times, serif; font-size:11pt; font-style:italic"; class="quote">

"Na prática é preferivel trabalhar com retornos, que são livres de escala, do que com preços, pois os primeiros têm propriedades estatísticas mais interessantes (como estacionariedade e ergodicidade). Um dos objetivos será, então, modelar retornos. Diversas classes de modelos podem ser utilizadas para esse fim, tais como os modelos ARMA, ARCH, GARCH, modelos de volatilidade estocástica, etc." (Morettin, p. 8, 2006)

</p>

## Causalidade x modelos de regressão em séries temporais

Embora a análise de regressão lide com a dependência de uma variável sobre outras variáveis, ela não implica necessariamente causação. <mark>Por este motivo, a compreensão da correta direção de uma variável e seu efeito em outra nos auxilia a descobrir se deveremos ajustar um modelo de regressão do tipo preço (``CORN.Close``) $\rightarrow$ quantidade (``CORN.Volume``) ou o contrário.</mark>

Nesses modelos, uma premissa básica é que a relação de causa e efeito, se houver, entre o $Y$ e os $X$ é unidirecional. As variáveis explanatórias são a causa e a variável dependente é o "efeito".

<p >
<p style="font-family: times, serif; font-size:11pt; font-style:italic"; class="quote">

"Grager parte da premissa de que o futuro não pode "causar" o presente ou o passado. Se o evento A ocorre após o evento B, sabemos que A não pode "causar" B. Ao mesmo tempo, se A ocorre antes de B, isso não implica necessariamente que A causa B. Por exemplo, a previsão do tempo ocorre antes da chuva. Isso não significa que a previsão "cause" a chuva. Na prática, observamos A e B como séries temporais e gostaríamos de saber se A precede B, ou se B precede A, ou se eles são contemporâneos. Por exemplo, se os preços precedem movimentos nas taxas de juros, ou ocorre o contrário, ou os movimentos são contemporâneos ? Esse é o propósito da causalidade de Granger, que não é causalidade conforme ela é geralmente compreendida." (Maddala, p. 202, 2003)

</p>

Entretanto, há situações nas quais existe um fluxo de influência de mão dupla entre as variáveis econômicas; ou seja, uma variável econômica afeta outra(s) variável(eis) econômica(s) e é, por sua vez, afetada por ela(s).

Em outras palavras, a existência de uma relação entre variáveis não prova causalidade ou a direção da influência. Mas, em regressões envolvendo dados de séries temporais, a situação pode ser um pouco diferente, porque, como coloca o autor,


<p >
<p style="font-family: times, serif; font-size:11pt; font-style:italic"; class="quote">

[. . .] o tempo não volta. Ou seja, se o evento A acontece antes do evento B, então é possível que A esteja causando B. No entanto, não é possível que B esteja causando A. Em outras palavras, os eventos passados podem levar ao acontecimento de eventos no presente. Os eventos futuros não podem. (Koop, p. 175, 2000)

</p>

Essa é a ideia aproximada do chamado teste de causalidade de Granger (Granger, p. 424-438, 1969). Mas deve-se observar que a questão da causalidade é profundamente filosófica, com todos os tipos de controvérsias. Em um extremo estão as pessoas que acreditam que _“tudo tenha uma causa”,_ e no outro estão aquelas que negam a existência de causação, seja qual for. O econometrista Edward Leamer prefere o termo precedência a causalidade. Francis Diebold prefere o termo causalidade preditiva. Como ele escreve:

<p >
<p style="font-family: times, serif; font-size:11pt; font-style:italic"; class="quote">

[. . .] a afirmação “ yi causa yj” é uma abreviação da afirmação mais exata, porém mais longa: “yi contém informações úteis para prever yj (no sentido dos mínimos quadrados lineares), acima e além das histórias passadas das outras variáveis no sistema”. Para poupar espaço, dizemos simplesmente que yi causa yj.

</p>


A clara e exata definição do termo aqui utilizado "causalidade" precisa ser bem esclarecido, uma vez que sua utilização na literatura econométrica esteja bem difundido:

<p >
<p style="font-family: times, serif; font-size:11pt; font-style:italic"; class="quote">

"Conforme mencionado anteriormente, Leamer sugere o uso da palavra "simples procedência" em vez das palavras complicadas da causalidade de Granger, uma vez que tudo que estamos testando é se uma certa variável precede a outra -- não estamos testando causalidade como ela é geralmente compreendida. Contudo, é muito tarde para reclamar sobre o termo, pois ele já foi bem estabelecido na literatura econométrica. Então, é importante compreender o que ele significa." (Maddala, p. 202, 2003)

</p>

A justificativa do uso do teste de causalidade se fundamenta na busca da seguinte resposta para a direção de causa e efeito entre preço do ativo ``CORN`` e quantidade transacionada dele próprio:

<p >
<p style="font-family: times, serif; font-size:11pt; font-style:italic"; class="quote">

Se, em um sistema de equações simultâneas que contenha duas ou mais equações, não for possível obter valores numéricos de cada parâmetro em cada equação, porque as equações são empiricamente indistinguíveis, ou muito parecidas, temos o problema da identificação. Sendo assim, na regressão da quantidade Q sobre o preço P, a equação resultante é uma função de demanda ou uma função de oferta (Q e P fazem parte de ambas as funções)? Se tivermos apenas dados sobre Q e P e nenhuma outra informação, será difícil, senão impossível, identificar a regressão como uma função de demanda ou oferta. É fundamental resolvermos o problema da identificação antes de procedermos à estimação, porque, se não sabemos
o que estamos estimando, a estimação per se não tem sentido.

</p>

### Teste de Causalidade de Granger

_O<mark> teste da causalidade de Granger pressupõe que as informações relevantes à previsão das respectivas variáveis preditivas, (p. ex. duas em duas como PIB e M), estão contidas unicamente nos dados de série temporal dessas variáveis._ </mark> (Gujarati e Porter, p. 647-653)

_Em que se supõe que os termos de erro_ $u_{1t}$ e $u_{2t}$ _não estejam correlacionados. A propósito, observe que, uma vez que temos duas variáveis, estamos lidando com a causalidade bilateral. Nas demais séries temporais econométricas, estenderemos isso à causalidade multivariada através da técnica de vetores autorregressivos (VAR)._

1. Uma _causalidade unidirecional_ de M para PIB será indicada se os coeficientes estimados das defasagens de M forem estatisticamente diferentes de zero como grupo e o conjunto de coeficientes estimados do PIB não for estatisticamente diferente de zero.

2. Por outro lado, a causalidade _unidirecional_ do PIB a M existe se o conjunto de coeficientes defasados não é estatisticamente diferente de zero e o conjunto dos coeficientes do PIB é estatisticamente diferente de zero.

3. _Feedback, ou causalidade bilateral,_ será sugerido quando os conjuntos de coeficientes de M e PIB forem estatisticamente diferentes de zero em ambas as regressões.

4. Por fim, a independência será sugerida quando os conjuntos de coeficientes de M e PIB não forem estatisticamente significativos em nenhuma das regressões.

Você pode encontrar um maior detalhamento [de modelagem econométrica utilizando Inferência Causal aqui](https://rhozon.github.io/selecaodeprodutosnor/inferenciacausal.html) ou então nas [literaturas recomendadas](https://book4you.org/s/Causal%20Inference)


```{r}

# Os preços (Granger) causam o volume ?

grangertest(CORN[,"CORN.Volume"] ~ CORN[,"CORN.Close"], order=4)

```

*Existem várias maneiras de encontrar o _lag_ ideal, que vou pular por causa do tempo, mas digamos que quatro seja um número mágico. (hehe)

O valor$-p$ é altamente significativo, mas e na outra direção ?

```{r}

# O volume (Granger) causa os precos ?

grangertest(CORN[,"CORN.Close"] ~ CORN[,"CORN.Volume"], order=4)

```


Como ele não é significativo, então podemos dizer que conforme o resultado do primeiro teste de causalidade, _.<mark>os preços Granger causam o volume de negociação do ativo ``CORN`` (milho)</mark>._

O sentido econômico disso se fundamenta na premissa da hipótese de mercados eficientes. Na definição clássica dessa hipótese, Fama (1970) definiu _"mercado financeiro eficiente como aquele em que o preço dos ativos negociados sempre reflete inteiramente as informações disponíveis sobre os mesmos."_

O poder dessa Hipótese é significativo, pois a HME descarta a possibilidade de ganhos consistentes com sistemas de negociação que se baseiem apenas nas informações disponíveis. Conforme Shleifer (2000), um investidor médio, seja ele indivíduo, fundo de pensão ou fundo mútuo, não deve esperar superar o mercado consistentemente, e os recursos que tais tipos de investidores utilizam para analisar e negociar ativos são desperdiçados, sendo melhor manter, passivamente, a carteira de mercado, esquecendo a gestão ativa de carteiras. Pode-se afirmar, seguramente, que o campo acadêmico das finanças em geral e, especificamente, o campo de análise e precificação de ativos foi construído com base na HME.

Afirmar, portanto, que um mercado é eficiente em termos de informação significa que não há maneiras de obtenção de lucros anormais mediante o uso da informação, visto que os preços já contemplam essa informação.

<p >
<p style="font-family: times, serif; font-size:11pt; font-style:italic"; class="quote">

"Aqueles que acreditam na hipótese de eficiência do mercado de capital argumentam que os preços das ações são essencialmente aleatórios e, por conseguinte, não há margem para especulação lucrativa no mercado de ações: se fosse possível prever o preço de amanhã com base no preço de hoje, todos seríamos milionários." (Gujarati e Porter, p. 736, 2011)

</p>

Esta é apenas a ponta do iceberg, mas deve ser suficiente para despertar sua curiosidade e torná-lo perigoso.


<p >
<p style="font-family: times, serif; font-size:11pt; font-style:italic"; class="quote">

Em termos mais gerais, uma vez que o futuro não pode prever o passado, se a variável X (Granger) causa a variável Y, variações em X deveriam preceder variações em Y. Portanto, em uma regressão de Y sobre outras variáveis (incluindo seus próprios valores passados), se incluirmos os valores passados ou defasados de X e ele aprimorar significativamente a previsão de Y, poderemos dizer que X (Granger) causa Y. Uma definição similar aplica-se se Y (Granger) causa X.

</p>

Um outro aspecto interessante (que possa ser averiguado em análises futuras), consiste no fato de compreendermos quanto tempo (delay) se faz presente no volume negociado de um ativo em relação ao seu preço estabelecido.

<p >
<p style="font-family: times, serif; font-size:11pt; font-style:italic"; class="quote">

Uma característica marcante da maioria das séries temporais econômicas é a inércia ou lentidão.

Como sabemos, séries temporais como o PNB, os índices de preços, a produção, o emprego e o desemprego registram ciclos (econômicos). Partindo do fundo da recessão, quando tem início a recuperação econômica, a maioria dessas séries começam a mover-se em um sentido ascendente. Nesse movimento, o valor da série em um ponto do tempo é maior que o anterior. Há um “impulso” embutido nele que continua até que algo aconteça (um aumento na taxa de juros, nos impostos ou em ambos) para desacelerá-lo. Portanto, em regressões que envolvem séries temporais, as observações
sucessivas tendem a ser interdependentes. (Gujarati e Porter, p. 417-418, 2011.)

</p>

Deste modo, a compreensão do aproximado intervalo de tempo dentre um patamar de preços para a janela de impacto no seu volume negociado, para mais ou para menos pode ser de grande valia para os tomadores de decisão nesse mercado.



## Características identificadas em séries temporais econômicas e financeiras


Em especial, como analisaremos aqui dados de séries temporais econômico-financeiras, os pesquisadores deste fenômeno até então que buscam pela sua modelagem ideal encontraram os seguintes fatos estilizados:

<p >
<p style="font-family: times, serif; font-size:11pt; font-style:italic"; class="quote">

<mark>Séries econômicas e financeiras apresentam algumas características que são comuns a outras séries temporais, como:

(a) tendências;

(b) sazonalidade;

(c) pontos influentes (atípicos);

(d) heteroscedasticidade condicional;

(e) não-linearidade.</mark>

O leitor está, certamente, familiarizado com as caracteríticas acima; para detalhes, veja Franses (1998). <mark>Dessas, a última talvez seja a mais complicada de definir. De um modo bastante geral, podemos dizer que uma série econômica ou financeira é não-linear quando responde de maneira diferente a choques grandes ou pequenos, ou ainda, a choques negativos ou positivos.</mark> (Morettin, p. 18, 2006)

</p>

A respeito disso, trataremos mais adiante sobre a aplicação de Vetores Autoregressivos e em especial de suas Funções de Impulso-Resposta e Decomposição de Variância, onde avaliaremos o horizonte estimado de tempo no futuro dado que alguma variável estudada sofra algum tipo de choque de quaisquer magnitude. Alguns testes de avaliação de hipótese de distribuição $idd$ nos dados de séries temporais também são muito bem fundamentados na literatura (*ver p. ex. o teste de BDS de Brock, Dechert and Scheinkman (1987) e depois publicado como Brock, Dechert, Scheinkman and LeBaron, 1996)

Em relação ao padrão de heterocedasticidade condicional e pontos atípicos presentes na volatilidade dos ativos financeiros, uma boa aplicação se dá com o uso dos modelos da família ARCH.

Já modelos que captam tendência e sazonalidade, em especial podem ser ajustados a cada série univariada ou em conjunto com a aplicação de modelos SARIMA e suas variantes p. ex. Modelos de Suavização Exponencial e Holt Winters também são muito utilizados em séries com essa característica.

<p >
<p style="font-family: times, serif; font-size:11pt; font-style:italic"; class="quote">

"Por muito tempo houve pouca comunicação entre econometristas e analistas de séries temporais. Os econometristas enfatizavam a teoria econômica e um estudo de relações contemporâneas. Variáveis defasadas foram introduzidas, mas não de maneira sistemática, e nenhuma tentativa séria foi feita para se estudar a estrutura temporal dos dados. As teorias eram impostas aos dados mesmo quando a estrutura temporal dos dados não estavam em conformidade com elas. Os analistas de séries temporais, todavia, não acreditavam em teorias econômicas e consideravam melhor permitir que os dados determinassem o modelo. Desde meados da década de 1970, essas duas abordagens -- a abordagem de séries temporais e a abordagem econométrica -- têm convergido. Agora, os econometristas usam alguns elementos básicos de análise de séries temporais na checagem da especificação dos seus modelos econométricos, e algumas teorias econômicas têm influenciado a direção dos trabalhos de séries temporais." (Maddala, p. 273, 2003)

</p>

## Características comuns de séries temporais

Além das características especificadas anteriormente como _fatos estilizados_ a respeito das séries temporais financeiras, descritas por Morettin (2006) anteriomente, destacamos alguns aspectos comuns na teoria de análise de séries temporais:

**Tendência**

Existe uma tendência quando há um aumento ou diminuição de longo prazo nos dados. Isto não precisa ser linear. Às vezes, nos referiremos a uma tendência como "mudança direção ”, quando pode passar de uma tendência crescente para uma tendência decrescente.

**Sazonalidade**

Já um padrão sazonal ocorre quando uma série temporal é afetada por fatores sazonais como a época do ano ou o dia da semana. A sazonalidade é sempre de uma frequência fixa e conhecida. Muitas séries temporais baseadas em dados mensais ou trimestrais exibem padrões sazonais (movimentos
oscilatórios regulares). Exemplos são as vendas de lojas de departamentos no Natal ou em outros dias importantes, a demanda por dinheiro (ou saldos) pelas famílias em datas comemorativas, a demanda de sorvete e refrigerantes durante o verão, preços das safras logo depois da temporada de colheita, a demanda por viagens aéreas etc. Com frequência, é desejável remover o fator sazonal, ou componente, de uma série temporal de modo que se possa concentrar nos demais componentes, como a tendência. O processo de remover o componente sazonal de uma série temporal é conhecido como dessazonalização ou ajustamento sazonal, e a série temporal assim obtida é chamada série temporal dessazonalizada, ou ajustada sazonalmente.


**Cíclico**

Um ciclo ocorre quando a exibição de dados sobe e desce que não são fixos frequência. Essas flutuações são geralmente devido às condições econômicas, e estão freqüentemente relacionados ao “ciclo de negócios”. A duração dessas flutuações geralmente é de pelo menos 2 anos.

<mark>Muitas pessoas confundem comportamento cíclico com comportamento sazonal, mas eles são realmente muito diferentes. Se as flutuações não são de frequência fixa, então eles são cíclicos; se a frequência é imutável e associada a algum aspecto do calendário, então o padrão é sazonal.</mark> Em geral, a duração média dos ciclos é mais longo do que a duração de um padrão sazonal, e as magnitudes dos ciclos tendem ser mais variável do que as magnitudes dos padrões sazonais.

Muitas séries temporais incluem tendência, ciclos e sazonalidade. <mark>Ao escolher um método de previsão, primeiro precisamos identificar os padrões de série temporal no dados e, em seguida, escolha um método que seja capaz de capturar os padrões de maneira adequada.</mark>

A seguir faremos uma análise conhecida como decomposição da série temporal com o intuito de "enxergarmos" melhor esses padrões.


## Análise de estacionariedade das séries de preço e volume

Para investigarmos cada uma dessas componentes como, tendência, sazonalidade, ciclo, _outliers_, heterocedasticidade condicional, não-linearidade, precisaremos iniciar avaliando a condição de estacionariedade das séries.

A maioria dos estudos empíricos na econometria das séries temporais embasados nesse tipo de dado pressupõe que a série temporal subjacente seja estacionária. De maneira _geral, <mark>uma série é estacionária se sua média e variância não variam sistematicamente ao longo do tempo</mark>,_
ou em termos não exatos, uma série temporal, por exemplo, $Y_t$, é estacionária se sua média e sua variância não mudam sistematicamente ao longo do tempo.


" _Na verdade, a maior parte das séries temporais que encontramos são não-estacionárias. Um modelo simples de série temporal não-estacionária é_ $X_{t} = \mu_t + e_t$, _em que a média_ $\mu_t$ _é uma função de tempo e_ $e_t$, _é uma série fracamente estacionária._ $\mu_t$, _por exemplo, pode ser uma função linear de_ $t$, _(uma tendência linear) ou uma função quadrática de_ $t$ _(uma tendência parabólica) (...) É claro que, separadamente de uma tendência linear, picos de períodos de férias dominam os movimentos da série._" (Maddala, p. 276, 2003) 


<p >
<p style="font-family: times, serif; font-size:11pt; font-style:italic"; class="quote">

<mark>"Por que as séries temporais estacionárias são tão importantes?</mark> Porque, se uma série temporal é não estacionária, podemos estudar seu comportamento apenas pelo período de tempo em consideração. Cada conjunto de dados de série temporal, portanto, será específico a cada episódio. Como consequência, não é possível generalizá-lo para outros períodos. <mark>Sendo assim, para o propósito de previsão, tal série temporal (não estacionária) pode ser de pouco valor prático.</mark>" (Gujarati e Porter, p. 735, 2011)

</p>









### Avaliando as funções de autocorrelação

A autocorrelação pode ser definida como <mark> _"correlação entre integrantes de séries de observações ordenadas no tempo [como as séries temporais]"_ </mark> ou no espaço [como nos dados de corte transversal]. Convém notar também que a autocorrelação pode ser tanto positiva quanto negativa, embora a maior parte das séries temporais econômicas em geral apresente autocorrelação positiva, pois, em sua maioria, evolui para cima ou para baixo por longos períodos e não apresenta oscilações constantes.

![](https://github.com/rhozon/datasets/raw/master/padroes_autocorrelacao.png)

<small> **Fonte:** Gujarati e Porter (p. 417, 2006) </small>

<p >
<p style="font-family: times, serif; font-size:11pt; font-style:italic"; class="quote">

Em análise de séries temporais, pois as observações de tais dados seguem um ordenamento natural, de modo que <mark> observações sucessivas costumam apresentar intercorrelações, especialmente se o intervalo de tempo entre observações sucessivas for curto, como um dia, </mark> uma semana ou um mês, e não um ano. <mark>Quando observamos índices de preços de ações, </mark> como o Dow Jones ou o S&P 500, durante dias sucessivos, não é raro verificar que esses índices sobem ou descem por vários dias seguidos. <mark>Obviamente, em situações como essa, a hipótese de ausência de autocorrelação ou ausência de correlação serial nos termos de erro que embasa o modelo clássico de regressão linear não será respeitada.</mark>

</p>


```{r fig.width=8, fig.height=3}

ggplotly(
ggAcf(CORN[,"CORN.Close"], na.action = na.interp) # Funcao de Autocorrelacao do Fechamento em nivel
)

ggplotly(
ggAcf(CORN[,"CORN.Volume"], na.action = na.interp) # Funcao de Autocorrelacao do Volume em nivel
)

ggplotly(
ggAcf(ret(CORN[,"CORN.Close"],1), na.action = na.interp) # Funcao de Autocorrelacao dos retornos do Fechamento
)

ggplotly(
ggAcf(ret(CORN[,"CORN.Volume"],1), na.action = na.interp) # Funcao de Autocorrelacao dos retornos do Volume
)

```

Note que os dois primeiros gráficos das funções de autocorrelação acima demonstram que os valores que ferem os intervalos (em linhas pontilhadas azuis) foram observados em praticamente ambas as séries. 

Já quando observamos a função de autocorrelação para os retornos, verificamos que em somente alguns _lags_ esse intervalo foram feridos. 

Para facilitar a escolha de um modelo ARIMA adequado, Gujarati e Porter (p. 775, 2011) clarificam com a representação gráfica a seguir:

![](https://github.com/rhozon/datasets/raw/master/pacepacf.png)

Uma maneira de determinar mais objetivamente se a diferenciação (integração) é necessária <mark>é usar um teste de raiz unitária. Estes são testes de hipótese estatística de estacionariedade que são projetados para determinar se a diferenciação é necessária.</mark>

Uma série de testes de raiz unitária estão disponíveis, que são baseados em diferentes suposições e pode levar a respostas conflitantes. Em nossa análise, usamos o Teste Kwiatkowski-Phillips-Schmidt-Shin (KPSS) (Kwiatkowski, Phillips, Schmidt e Shin, 1992). Neste teste, a hipótese nula é que os dados são estacionários, e procuramos evidências de que a hipótese nula é falsa.

Consequentemente, pequenos valores de $p$ (por exemplo, menores que 0,05) sugerem que a diferenciação é obrigatória.

```{r}

CORN[,"CORN.Close"] %>% ur.kpss() %>% summary() # Teste para preco de fechamento em nivel

CORN[,"CORN.Volume"] %>% ur.kpss() %>% summary() # Teste para volume em nivel

```

Observe que o resultado da estatística do teste apresenta valores superiores para os preços e volume em nível em relação aos valores críticos. Ou seja, <mark>em nível elas não são estacionárias;</mark> todavia quando utilizamos suas séries de retornos notamos a estacionariedade apontada pelo teste.

```{r}

ret(CORN[,"CORN.Close"],1) %>% ur.kpss() %>% summary() # Teste para retorno dos precos

ret(CORN[,"CORN.Volume"],1) %>% ur.kpss() %>% summary() # Teste para retorno do volume

```

Note que nas séries de retornos, os valores das estatísticas de teste se mostraram inferiores aos valores críticos do teste KPSS a 10, 5, 2.5 e 1 pct.

Portanto, <mark>concluímos que podemos trabalhar com as séries de retornos dos preços e volume do ativo em questão para construção com confiabilidade estatística de modelos preditivos acurados.</mark>





## Avaliando a decomposição das séries

Embora a decomposição clássica ainda seja amplamente usada, não é recomendada, pois agora existem vários métodos muito melhores. Alguns dos problemas com esse método são resumidos abaixo.

+ <mark>A estimativa do ciclo de tendência não está disponível para as primeiras e últimas observações.</mark> Por exemplo, se não houver estimativa de ciclo de tendência para as primeiras seis ou as últimas seis observações. Consequentemente, também não há estimativa do componente remanescente para os mesmos períodos de tempo. Por exemplo, se $m = 12$ a estimativa do ciclo de tendência tende a suavizar demais aumentos e quedas rápidos nos
dados.

+ <mark>Métodos clássicos de decomposição assumem que o componente sazonal repete-se de ano para ano. Para muitas séries, esta é uma suposição razoável, mas não é para algumas séries mais longas.</mark> Por exemplo, padrões de demanda de eletricidade mudaram com o tempo, à medida que o ar condicionado se tornou mais difundido. Especificamente, em muitos locais, o padrão de uso sazonal de vários décadas atrás teve sua demanda máxima no inverno (devido ao aquecimento), enquanto o padrão sazonal atual tem sua demanda máxima no verão (devido ao ar refrigerado). Os métodos clássicos de decomposição são incapazes de capturar essas mudanças sazonais ao longo do tempo.

+ <mark>Ocasionalmente, os valores da série temporal em um pequeno número de períodos podem ser particularmente incomuns.</mark> Por exemplo, o tráfego mensal de passageiros aéreos pode ser afetado por uma disputa industrial, tornando o tráfego durante a disputa diferente do normal. O método clássico não é robusto para esses tipos de valores incomuns.

Fora os problemas acima mencionados, notamos que <mark>em relação a uma _commoditie_ suas oscilações em preço e em volume negociado dificilmente apresentarão uma padrão sazonal bem definido, uma vez que atualmente qualquer pessoa pode negociar, comprar e vender suas posições simplesmente dando ordens de seus brokers em aparelhos celulares ou notebooks pessoais praticamente de qualquer lugar do mundo.</mark>

Todavia, <mark>o ciclo de colheita, safra varia de região produtora a região produtora/consumidora e isso precisa ser observado com cautela.</mark> Geramos uma análise com os dados do preço de fechamento do milho e do volume de negociação mensalizado:

<p >
<p style="font-family: times, serif; font-size:11pt; font-style:italic"; class="quote">

"Na análise aplicada, os dados brutos muitas vezes são “manipulados”. Por exemplo, em regressões de séries temporais que envolvem dados trimestrais, muitas vezes os dados são obtidos somando três observações mensais e dividindo a soma por três. Essas médias suavizam os dados amenizando as flutuações dos dados mensais. Portanto, a representação gráfica dos dados trimestrais é muito menos irregular que a dos dados mensais e essa mesma regularidade pode gerar um padrão sistemático nos termos de erro, introduzindo a autocorrelação." (Gujarati e Porter, p. 419, 2006)

</p>

```{r fig.width=8, fig.height=5}

fechamento_mensal <- ts(CORN[,"CORN.Close"], start = c(2010, 6), end = c(2021, 6), frequency = 12)
volume_mensal <- ts(CORN[,"CORN.Volume"], start = c(2010, 6), end = c(2021, 6), frequency = 12)

ggplotly(
ggsubseriesplot(fechamento_mensal) +
  ylab("US$/bushel") +
  ggtitle("Seasonal subseries plot: CORN.Close"))

```

Esta forma de gráfico permite que o padrão sazonal subjacente seja visto claramente, e também mostra o mudanças na sazonalidade ao longo do tempo. É especialmente útil na identificação de mudanças dentro de determinadas estações.

```{r fig.width=8, fig.height=5}

ggplotly(
ggsubseriesplot(volume_mensal) +
  ylab("US$/bushel") +
  ggtitle("Seasonal subseries plot: CORN.Volume"))

```


Note que as magnitudes das médias (linhas horizontais azuis) nos meses apontadas no gráfico acima são ainda muito difíceis de precisarmos a diferenciação em relação aos demais meses. Ainda que nos meses de fevereiro (volume de negociação) e de abril (cotações de fechamento) a média histórica se apresente ligeiramente superior aos demais meses, não podemos afirmar com clareza que neste mês a componente sazonal se apresenta com maior proeminência (para cima ou para baixo) em suas oscilações de forma recorrente.


Podemos "decompor" as séries temporais com auxílio de um método não clássico, com o objetivo de compreendermos com maior clareza esses padrões e características. Os modelos de estrutura de séries temporais são modelos de espaço de estado que utilizam uma decomposição da série temporal em uma série de componentes que são especificados por um conjunto de variações de perturbação. Assim, esses modelos podem ser considerados modelos de componentes de erro para dados de séries temporais. Harvey (1989) e Durbin e Koopman (2001) são referências padrão.

```{r fig.width=9, fig.height=9}

dd_stl <- stl(log(fechamento_mensal[,"CORN.Close"]), s.window = 12) # Estrutura da serie mensal de precos
plot(dd_stl)

```

Ao observarmos a componente de tendência nos preços e volume, notamos a sua evidente trajetória e provável continuidade de alta.

```{r fig.width=9, fig.height=9}

dd_stl <- stl(log(volume_mensal[,"CORN.Volume"]), s.window = 12) # Estrutura da serie mensal de volume
plot(dd_stl)

```


Note que facilmente identificamos uma diminuição progressiva no ciclo de sazonalidade do volume de negociação apesar dos sobressaltos se apresentarem de maneira mais proeminente nos fluxos mais recentes quando observamos a série original. Por outro lado o ciclo sazonal dos preços parece apresentar um padrão mais definido desde metade da série para frente.

## Quebra Estrutural nas séries temporais

Além dos componentes de tendência, ciclo e sazonalidade comum em séries temporais, podemos notar que especificamente para aquelas em que a frequência de eventos é maior, inversões e mudanças significativas/bruscas em sua trajetória são notáveis e recorrentes em suas trajetórias.

Neste sentido quando utilizamos um modelo de regressão que envolve o uso de séries temporais, pode acontecer que se <mark>verifique uma mudança estrutural</mark> na relação entre o regressando e os regressores. 

<p >
<p style="font-family: times, serif; font-size:11pt; font-style:italic"; class="quote">

"Por mudança estrutural entendemos que os valores dos parâmetros do modelo não se mantêm iguais durante todo o período de tempo. Às vezes, a mudança estrutural decorre de forças externas (por exemplo, os embargos do petróleo impostos pela Opep em 1973 e 1979 ou a Guerra do Golfo de
1990/1991) ou por mudanças na política econômica (como a passagem de um sistema de câmbio fixo para outro de taxa flutuante por volta de 1973) ou por ações tomadas pelo Congresso (como as mudanças tributárias promovidas pelo presidente Reagan ou alterações do salário mínimo) ou várias
outras causas." (Gujarati e Porter, p. 267, 2011)

</p>

Visualmente podemos separar os seguintes pontos de destaque na série de preços onde as inversões de trajetória se fizeram proeminentes:

```{r fig.width=8, fig.height=3}

presAnnotation <- function(dygraph, x, text) {
  dygraph %>%
dyAnnotation(x, text, attachAtBottom = TRUE, width = 60, height=20)
}

dygraph(Cl(CORN))%>%  
  
   dyAnnotation("2011-08-26", text = "A", tooltip = "Mudança")%>%
   presAnnotation("2011-08-26", text = "Mudança") %>%
   dyShading(from = "2011-08-26", to = "2011-10-18") %>%
  
   dyAnnotation("2012-06-12", text = "A", tooltip = "Inversão")%>%
   presAnnotation("2012-06-12", text = "Inversão")%>%   
   dyShading(from = "2012-06-12", to = "2012-07-18") %>%

   dyAnnotation("2014-01-06", text = "A", tooltip = "Inversão")%>%
   presAnnotation("2014-01-06", text = "Inversão")%>%   
   dyShading(from = "2014-01-06", to = "2014-04-29") %>%

   dyAnnotation("2015-06-12", text = "A", tooltip = "Mudança")%>%
   presAnnotation("2015-06-12", text = "Mudança")%>%   
   dyShading(from = "2015-06-12", to = "2015-08-03") %>%
  
   dyAnnotation("2016-06-08", text = "A", tooltip = "Inversão")%>%
   presAnnotation("2016-06-08", text = "Inversão")%>%   
   dyShading(from = "2016-06-08", to = "2016-07-08") %>%
  
   dyAnnotation("2020-08-06", text = "A", tooltip = "Mudança")%>%
   presAnnotation("2020-08-06", text = "Mudança")%>%   
   dyShading(from = "2020-08-06", to = "2021-01-11") %>%
   
   dyAnnotation("2021-02-10", text = "A", tooltip = "Inversão")%>%
   presAnnotation("2021-02-10", text = "Inversão") %>%   
   dyShading(from = "2021-02-10", to = "2021-05-07") %>%

dyRangeSelector()

```

Para testar se essas quebras estruturais são significativas, rodamos o teste de Chow: (para maiores detalhes deste teste vide Chow (1983))

```{r}

sctest(log(fechamento_mensal[,"CORN.Close"]) ~ 1, type = "Chow", point = 15) # Ponto 15 equivale a decima quinta obs, ou seja ao mes de ago/2011

```

<mark>Como o valor $p$ é menor que 0,05, podemos rejeitar a hipótese nula do teste para a mudança de trajetória demarcada na série em ago/2011. Isso significa que temos evidências suficientes para dizer que um ponto de quebra estrutural está presente na série de preços a partir deste ponto do tempo.</mark>

Podemos rodar o teste Chow para os demais pontos demarcados no gráfico de fechamento de preços acima (em cinza)

```{r}

sctest(log(fechamento_mensal[,"CORN.Close"]) ~ 1, type = "Chow", point = 25) # Em jun/2012
sctest(log(fechamento_mensal[,"CORN.Close"]) ~ 1, type = "Chow", point = 44) # jan/2014
sctest(log(fechamento_mensal[,"CORN.Close"]) ~ 1, type = "Chow", point = 61) # jun/2015
sctest(log(fechamento_mensal[,"CORN.Close"]) ~ 1, type = "Chow", point = 73) # jun/2016
sctest(log(fechamento_mensal[,"CORN.Close"]) ~ 1, type = "Chow", point = 123) # ago/2020
sctest(log(fechamento_mensal[,"CORN.Close"]) ~ 1, type = "Chow", point = 129) # fev/2021

```

Note que para todas as áreas demarcadas em cinza, o teste de Chow apontou para evidências estatísticas significativas de quebras (inversões ou mudanças) na trajetória da série naqueles pontos. Ainda que essas escolhas desses pontos demarcados em cinza no gráfico de cotações sejam feitas
visualmente, será que estatisticamente eles são válidos ?

Vamos utilizar um outro método de verificação dos pontos de quebra. O procedimento de datação de Bai e Perron (2003) emprega um algoritmo de programação dinâmico baseado no princípio de Bellman para encontrar aqueles $m$ pontos de interrupção que minimizam a soma residual dos quadrados (RSS) de um modelo com $m + 1$ segmentos, dado algum tamanho mínimo de segmento de $h \cdot n$ observações. Aqui, $h$ é um parâmetro de largura de banda/horizonte a ser escolhido pelo usuário.

Utilizando os seguintes comandos do R, fazemos:

```{r}

teste_quebra_fechamento <- breakpoints(log(fechamento_mensal[,"CORN.Close"]) ~ 1)
summary(teste_quebra_fechamento)

```

Dados $h$ e $m$, os pontos de interrupção que minimizam o RSS podem ser determinados; entretanto, normalmente o número de pontos de interrupção $m$ não sejam conhecidos previamente. O RSS e o BIC são mostrados nos gráficos a seguir

```{r fig.width=9, fig.height=5}

teste_quebra_fech_int_conf <- confint(teste_quebra_fechamento)
plot(teste_quebra_fechamento)
lines(teste_quebra_fechamento)
lines(teste_quebra_fech_int_conf ) # RSS e BIC para as quebras na serie de precos

```

Embora o RSS caia claramente até ``m = 1`` quebras e o BIC siga um movimento similar isso parece satisfatório, para a série de preços pois os testes de mudança estrutural mostraram claramente que os parâmetros do modelo são estáveis. 

```{r}

teste_quebra_volume <- breakpoints(log(volume_mensal[,"CORN.Volume"]) ~ 1)
summary(teste_quebra_volume)

```

```{r fig.width=9, fig.height=5}

teste_quebra_vol_int_conf <- confint(teste_quebra_volume)
plot(teste_quebra_volume)
lines(teste_quebra_volume)
lines(teste_quebra_vol_int_conf) # RSS e BIC para as quebras na serie de volume

```

Já a quebra estrutural identificada por RSS e BIC se demonstraram visualmente presentes em $m=$2 e 3, utilizaremos aqui para fins práticos de análise (orientado pelo resultado do teste de causalidade de Granger anteriormente) somente a série de preços com uma maior atenção em nossa investigação.

Vale destacar que o BIC foi considerado pouco confiável para modelos autorregressivos por Bai e Perron (2003), contamos com a interpretação da visualização dos testes de mudança estrutural e usamos o modelo com ``m = 3`` quebras. Seus coeficientes podem ser extraídos via


```{r}

coef(teste_quebra_fechamento, breaks = 1) # Mostre os intervalos de periodos das quebras para precos

coef(teste_quebra_volume, breaks = 2) # Mostre os intervalos de periodos das quebras para volume

```

Mesmo a série de volume sendo mais volátil do que a dos preços, pois apresenta muitos _outliers_, notamos que os pontos de quebra propostas pelo método para a série de preços sugeriu a presença de duas regressões, anteriores as quebras, que poderiam ser estimadas com base na relação dela própria contemplando o período compreendido entre jun/2010 a set/2015 e de out/2015 até o último dado disponível (jun/2021).

A enorme dificuldade de estimar um modelo de regressão/projeção de séries temporais tradicional para as séries de preços e volume do ativo escolhido demonstram a substancial necessidade de observarmos com cuidado e informações de mercado os motivos pelos quais tais pontos discrepantes se pronunciaram. Como descrito anteriormente as origens são multicausais e na maioria dos casos indetectável ou inquantificável. 

Todavia, até aqui sabemos que o procedimento de simplesmente excluirmos esses outliers empobrecem substancialmente a qualidade de análise preditiva pois não se trata de um erro do levantamento estatístico dos dados e sim um fato fora do comum, que sim precisa ser considerado! 


## Avaliando a heterocedasticidade condicional nas séries

<p >
<p style="font-family: times, serif; font-size:11pt; font-style:italic"; class="quote">

"Os preços dos ativos são caracterizados pelo fenômeno conhecido como aglomeração de volatilidade, isto é, períodos nos quais eles exibem grandes oscilações para um período prolongado de tempo seguido por um período de tranquilidade comparativa. Deve-se observar o índice Dow Jones no passado recente. Os assim chamados modelos heterocedasticidade condicional autorregressiva (ARCH) ou heterocedasticidade condicional
autorregressiva generalizada (GARCH) podem capturar tal aglomeração de volatilidade." (Gujarati e Porter, p. 767, 2011) 

</p>


Como Philip Franses observa:

<p >
<p style="font-family: times, serif; font-size:11pt; font-style:italic"; class="quote">

Uma vez que os dados [da série temporal financeira] refletem o resultado do comércio entre compradores
e vendedores em, por exemplo, mercados de ações, muitas fontes de notícias e outros eventos econômicos
exógenos podem ter um impacto no padrão da série temporal dos preços dos ativos. Dado que
as notícias podem levar a interpretações variadas, e também dado que eventos econômicos específicos
como uma crise do petróleo podem durar por algum tempo, frequentemente observamos que grandes
observações positivas ou grandes observações negativas em séries temporais financeiras tendem a aparecer
em aglomerados.

</p>

Os autores da literatura conhecida enfatizam que a justificativa em se modelar a volatilidade de ativos financeiros se faz fundamental

<p >
<p style="font-family: times, serif; font-size:11pt; font-style:italic"; class="quote">

O conhecimento da volatilidade é de suma importância em muitas áreas. Por exemplo, trabalho
macroeconômico considerável foi feito para estudar a variabilidade da inflação ao longo do tempo.
Para alguns tomadores de decisão, a inflação em si mesma pode não ser ruim, porém sua variabilidade
é ruim, porque torna o planejamento financeiro difícil.

O mesmo é verdadeiro quanto aos importadores, exportadores e comerciantes nos mercados
de câmbio, porque a variabilidade nas taxas de câmbio pode significar grandes perdas ou lucros.
Os investidores, no mercado de ações, estão obviamente interessados na volatilidade dos preços
das ações, pois a alta volatilidade poderia significar grandes perdas ou ganhos e, portanto, maior
incerteza. Em mercados voláteis, é difícil para as empresas aumentar o capital nos mercados de
capitais.

Como modelar uma série temporal financeira que pode experimentar tal volatilidade? Por exemplo,
como modelar a série temporal dos preços das ações, das taxas de câmbio, da inflação etc? Uma
característica da maioria dessas séries temporais financeiras é que na sua forma em nível elas são
passeios aleatórios; isto é, são não estacionárias. Por outro lado, na forma de primeira diferença,
são em geral estacionárias (...)


Sendo assim, em vez de modelar os níveis da série temporal financeira, por que não modelar as
suas primeiras diferenças? Essas primeiras diferenças frequentemente exibem grandes oscilações,
ou volatilidade, sugerindo que a variância da série temporal financeira muda ao longo do tempo.
Como podemos modelar tal “variância variável”? É aqui que o chamado modelo de heterocedasticidade
condicional autorregressiva (ARCH) originalmente desenvolvido por Engle vem a calhar.

Como o nome sugere, a heterocedasticidade ou variância desigual pode ter uma estrutura autorregressiva
na qual a heterocedasticidade observada ao longo de diferentes períodos pode ser autocorrelacionada. (Gujarati e Porter, 2011, p. 784-785)

</p>

### Uma breve digressão a respeito dos retornos


Observemos os gráficos do ativo CORN para preço e volume novamente

```{r fig.width=9, fig.height=3}

dygraph(Cl(CORN), group = "grupo") %>% dyRangeSelector() # Grafico das cotacoes de Fechamento
dygraph(ret(Cl(CORN),1), group = "grupo") %>% dyRangeSelector() # Grafico dos retornos do Fechamento

dygraph(Vo(CORN), group = "grupo") %>% dyRangeSelector()  # Grafico do Volume negociado
dygraph(ret(Vo(CORN),1), group = "grupo") %>% dyRangeSelector() # Grefico dos retornos do Volume de negociacao

```



No caso do ``CORN``, você pode ver que o retorno médio diário é próximo a zero e que sua variabilidade muda com o tempo. Existem períodos com baixa variabilidade e períodos com alta variabilidade. Você pode quantificar essa variabilidade calculando o desvio padrão de retorno.

Os investidores chamam isso de volatilidade do retorno e a denotam pelo caractere grego sigma com o índice t ($\sigma_{t}$) para enfatizar que seu valor muda a cada dia.

Obter a volatilidade certa é, portanto, de extrema importância. Podemos estimar o desvio padrão de retorno no R simplesmente aplicando a função ``sd()`` à série de retorno.


```{r}

dlnCORNclose <- diff(log(Cl(CORN)), lag=1) # ln(Pt/Pt-1), o mesmo que a funcao ret()

dlnCORNclose <- dlnCORNclose[-1,]

sd(dlnCORNclose)

```

Para os retornos diários do ``CORN``, isso dá a você uma volatilidade diária de cerca de ``r round(sd(dlnCORNclose),2)*100`` %. A fórmula subjacente é que o desvio padrão é igual à raiz quadrada do desvio quadrado médio do retorno de sua média.

Os operadores financeiros anualizam a volatilidade diária multiplicando-a pela raiz quadrada do número de dias de negociação em um ano, ou seja, 252.

```{r}

sqrt(252) * sd(dlnCORNclose)

```

O que nos fornece o desvio padrão dos retornos anuais. Para o CORN, obtemos uma volatilidade anualizada de ``r round((sqrt(252) * sd(dlnCORNclose))*100,2)`` %.

Ao avaliarmos a dinâmica da distribuição de retorno quando calculamos esse desvio padrão anualizado em subamostras de um ano, obtemos números diferentes ao longo do tempo: obviamente eles variam entre um mínimo e um máximo.

Esta estimativa de volatilidade móvel pode ser calculada quando retiramos da volatilidade amostras de estimativa rotativa/periódica. Em seguida, "rolamos" a amostra no tempo, adicionando a observação mais recente e removendo a mais distante. Uma questão prática é, então, escolher o comprimento da janela de estimativa. Normalmente, a duração da janela é um múltiplo de 22, que é o número de dias de negociação em um mês.

```{r fig.width = 9, fig.height = 3}

library(PerformanceAnalytics)

chart.RollingPerformance(R = dlnCORNclose,
                         width = 22,
                         FUN = "sd.annualized",
                         scale = 252,
                         main = "Volatilidade mensalizada")

```

Esse gráfico nos facilita ao observermos as mudanças entre os períodos de baixa e alta volatilidade.

Logo, quanto mais curta a janela, mais responsiva é a estimativa de volatilidade móvel aos retornos recentes. Quanto mais longa for a janela, mais suave será. A função ``sd.annualized`` permite calcular a volatilidade anualizada assumindo que o número de dias de negociação em um ano é igual ao número especificado no argumento ``scale``.

```{r fig.width=9}

# Plota dois graficos um em cima do outro
par(mfrow=c(3,1)) 

# Volatilidade movel para um mes
chart.RollingPerformance(R = dlnCORNclose["2010::2021"], width = 22,
     FUN = "sd.annualized", scale = 252, main = "Volatilidade móvel para um mês")

# Volatilidade movel para trimestre
chart.RollingPerformance(R = dlnCORNclose["2010::2021"], width = 22*3,
     FUN = "sd.annualized", scale = 252, main = "Volatilidade móvel para trimestre")

# Volatilidade movel para o semestre
chart.RollingPerformance(R = dlnCORNclose["2010::2021"], width = 22*6,
     FUN = "sd.annualized", scale = 252, main = "Volatilidade móvel para semestre")

# Volatilidade movel para doze meses
chart.RollingPerformance(R = dlnCORNclose["2010::2021"], width = 22*12,
     FUN = "sd.annualized", scale = 252, main = "Volatilidade móvel para doze meses")

```


Logo, podemos de outra forma, obter os desvios-padrão para os anos disponíveis na série histórica a saber:

```{r}

# Como anteriormente, o desvio padrao dos retornos para dados diarios   
sd(dlnCORNclose)

# Calcula a volatilidade anualizada para a série completa 
sqrt(252) * sd(dlnCORNclose)

# Calcula o desvio padrao anualizado para o cada ano disponivel na serie
sqrt(252) * sd(dlnCORNclose["2010"])
sqrt(252) * sd(dlnCORNclose["2011"])
sqrt(252) * sd(dlnCORNclose["2012"])
sqrt(252) * sd(dlnCORNclose["2013"])
sqrt(252) * sd(dlnCORNclose["2014"])
sqrt(252) * sd(dlnCORNclose["2015"])
sqrt(252) * sd(dlnCORNclose["2016"])
sqrt(252) * sd(dlnCORNclose["2017"])
sqrt(252) * sd(dlnCORNclose["2018"])
sqrt(252) * sd(dlnCORNclose["2019"])
sqrt(252) * sd(dlnCORNclose["2020"])
sqrt(115) * sd(dlnCORNclose["2021"]) # Numero aproximado de dias uteis ate a data de hoje -1

```

















### O modelo ARCH

O modelo ARCH assume que a média condicional do termo de erro em um modelo de série temporal é constante (zero), ao contrário da série não estacionária que discutimos até agora), mas sua variância condicional não. As equações que o descrevem são:

\begin{equation}
y_{t}=\phi +e_{t}
\label{eq:archdefA14}
\end{equation}

\begin{equation}
e_{t} | I_{t-1} \sim N(0,h_{t})
\label{eq:archdefB14}
\end{equation}

\begin{equation}
h_{t}=\alpha_{0}+\alpha_{1}e_{t-1}^2, \;\;\;\alpha_{0}>0, \;\; 0\leq \alpha_{1}<1
\label{eq:archdefC14}
\end{equation}

As equações 4 e 5 a seguir fornecem o modelo de testagem e a possibilidade de avalira a hipótese da presença dos efeitos ARCH em uma série de tempo, onde os resíduos $\hat e_{t}$ vêm da regressão da variável $y_t$ contendo uma constante, como 1, ou em uma constante mais outros regressores; o teste mostrado na Equação 4 pode incluir vários termos de defasagem, caso em que a hipótese nula (Equação 5) seria que todos eles são conjuntamente insignificantes.

\begin{equation}
\hat e_{t}^2 = \gamma_{0}+\gamma_{1}\hat e_{t-1}^2+...+\gamma_{q}e_{t-q}^2+\nu_{t}  
\label{eq:archeffectseqA14}
\end{equation}

\begin{equation}
H_{0}:\gamma_{1}=...=\gamma_{q}=0\;\;\;H_{A}:\gamma_{1}\neq 0\;or\;...\gamma_{q}\neq 0
\label{eq:archeffectseqB14}
\end{equation}

Sendo a hipótese nula de que não existam efeitos ARCH. A estatística de teste é

$$
(T-q)R^2 \sim \chi ^2_{(1-\alpha,q)}
$$

Primeiramente transformo as variáveis de volume e fechamento para objeto ``ts()`` do R, ou seja _time series_ para aplicar um ARCH:

```{r }

fech_diario <- ts(Cl(CORN))
vol_diario <- ts(Vo(CORN))

ret_fech_diario <- ts(ret(Cl(CORN),1))
ret_vol_diario <- ts(ret(Vo(CORN),1))

```


Como já transformamos os dados da série de preços e de volume em retornos, podemos inspecionar suas respectivas distribuições de probabilidade.

```{r fig.width=8, fig.height=4}

ggplotly(
ggplot(CORN, aes(x=ret(Cl(CORN)))) + 
 geom_histogram(aes(y=..density..), colour="black", fill="white")+
 geom_density(alpha=.2, fill="#FF6666")+
ggtitle("Histograma e densidade dos retornos dos preços do ativo CORN")  
)

ggplotly(
ggplot(CORN, aes(x=ret(Vo(CORN)))) + 
 geom_histogram(aes(y=..density..), colour="black", fill="white")+
 geom_density(alpha=.2, fill="#FF6666")+
ggtitle("Histograma e densidade dos retornos do volume negociado do ativo CORN")  
)

```


O QQPlot nos fornece o nivel de distorção em relação a normalidade

```{r fig.width=8, fig.height=4}

#QQ-plot
qqnorm(Cl(CORN))
qqline(Cl(CORN), col = 2) 

```

Como pode ser visto no histograma e no gráfico QQ, a série tem uma distribuição um tanto normal com caudas grossas (pesadas) em ambas as extremidades; ou seja leptocúrticas com caudas pesadas. 


Então seguindo o passo a passo das equações acima apresentadas, rodamos um modelo do tipo:

```{r}

ret_fech_diario.mean <- dynlm(ret_fech_diario~1) # Serie dos retornos dos precos
summary(ret_fech_diario.mean)

ret_vol_diario.mean <- dynlm(ret_vol_diario~1) # Serie dos retornos dos precos
summary(ret_vol_diario.mean)

```


Estimo os resíduos do modelo

```{r}

e.chapeu.fech <- ts(resid(ret_fech_diario.mean)^2)
ret_fech_diario.ARCH <- dynlm(e.chapeu.fech ~ L(e.chapeu.fech))
summary(ret_fech_diario.ARCH) 

e.chapeu.vol <- ts(resid(ret_vol_diario.mean)^2)
ret_vol_diario.ARCH <- dynlm(e.chapeu.vol~L(e.chapeu.vol))
summary(ret_vol_diario.ARCH) 

```

Obtenho os parâmetros:

```{r}

T <- nobs(ret_fech_diario.mean)
q <- length(coef(ret_fech_diario.ARCH ))-1
Rsq <- glance(ret_fech_diario.ARCH)[[1]]
LM <- (T-q)*Rsq
LM
alpha <- 0.05
qui_quadr <- qchisq(1-alpha, q)

```

O resultado da estatística LM, igual a ``r round(LM, 2)``, que deve ser comparada ao valor qui-quadrado crítico com $α = 0,05$ e $q = 1$ grau de liberdade; este valor é $\chi^2_{(0.95, 1)} =$ ``r round(qui_quadr,2)``; <mark>isso indica que a hipótese nula é rejeitada, concluindo que a série de preços tem efeitos ARCH.</mark>

A mesma conclusão pode ser alcançada se, em vez do procedimento passo a passo, usarmos um dos recursos de teste ARCH de R, a função ``ArchTest()`` no pacote ``FinTS``.

```{r}

ArchTest(fech_diario, lags=1, demean=TRUE) # Precos em nivel
ArchTest(ret_fech_diario, lags=1, demean=TRUE) # Retornos do precos 

ArchTest(vol_diario, lags=1, demean=TRUE) # Volume em nivel
ArchTest(ret_vol_diario, lags=1, demean=TRUE) # Retornos do volume 

```


A função ``garch()`` estima um modelo do tipo ARCH quando determinamos sua ordem ($p,q$) para (0,1). Esta função pode ser empregada para estimarmos e plotarmos a variância $h_t$ definida na equação 3 


```{r}

ret_fech_diario <- na.remove(ret_fech_diario) 
ret_vol_diario <- na.remove(ret_vol_diario)

fech.arch <- garch(ret_fech_diario,c(0,1)) # Modelo ARCH estimado para os retornos de precos
summary(fech.arch)

vol.arch <- garch(ret_vol_diario,c(0,1)) # Modelo ARCH estimado para os retornos do volume
summary(vol.arch)

```


Vamos plotar o ARCH(1) para a variância dos dados de fechamento e volume

```{r fig.width=8, fig.height=4}

hhat.fech <- ts(2*fech.arch$fitted.values[-1,1]^2)
plot.ts(hhat.fech) # Variancia estimada ARCH(1) para as cotacoes de fechamento do ativo CORN

hhat.vol <- ts(2*vol.arch$fitted.values[-1,1]^2)
plot.ts(hhat.vol) # Variancia estimada ARCH(1) para o volume negociado do ativo CORN

```

### Estimando o modelo GARCH

O modelo GARCH exerce uma vantagem em relação ao modelo ARCH, pois ele pode ser utilizado para descrever a volatilidade com menos parâmetros.

```{r}

garchSpec <- ugarchspec(
           variance.model=list(model="sGARCH",
                               garchOrder=c(1,1)),
           mean.model=list(armaOrder=c(0,0)), 
           distribution.model="std") # Especificacao do modelo GARCH

garch.fech <- ugarchfit(spec=garchSpec, data=ret_fech_diario) 
coef(garch.fech) # Coeficientes estimados para os retornos dos precos

garch.vol <- ugarchfit(spec=garchSpec, data=ret_vol_diario) 
coef(garch.vol) # Coeficientes estimados para os retornos dos precos

```

O gráfico a seguir nos fornece um preview do output da estimativa de um modelo GARCH padrão:

```{r fig.width=8, fig.height=4}

rhat <- garch.fech@fit$fitted.values
#plot.ts(rhat) # Coeficientes GARCH(1,1) da serie de retornos de precos
hhat <- ts(garch.fech@fit$sigma^2)
plot.ts(hhat) # GARCH(1,1) na volatilidade da Serie de Retornos de precos

```



```{r fig.width=9}

# Uso o metodo sigma para ver as volatilidades estimadas
garchvolatilidade <- sigma(garch.fech)

# Plota a volatilidade para 2021
plot(garchvolatilidade["2021"])

```



Como existem muitas variantes dos modelos da família GARCH, estimo aqui sua variante popularmente conhecida em trabalhos empíricos, o GARCH-M, ou GARCH na média.

```{r}
# GARCH-M
garchM <- ugarchspec(
          variance.model=list(model="fGARCH",
                               garchOrder=c(1,1),
                               submodel="APARCH"),
           mean.model=list(armaOrder=c(0,0),
                          include.mean=TRUE,
                          archm=TRUE,
                          archpow=2
                          ), 
           distribution.model="std"
                           )
garchM.fech <- ugarchfit(spec=garchM, data=ret_fech_diario)
coef(garchM.fech ) # Coeficientes estimados dos retornos de precos

garchM.vol <- ugarchfit(spec=garchM, data=ret_vol_diario)
coef(garchM.vol) # Coeficientes estimados dos retornos de volume

```

Veremos o padrão de resultado do modelo estimado para preços:

```{r fig.width=8, fig.height=4}

# Padrao da variância condicional de precos

plot.ts(sigma(garchM.fech), ylab="sigma(t)", col="blue")

```


Essas são as estimativas para os preços. Vejamos agora para o volume:


```{r fig.width=8, fig.height=4}

# Padrao da variância condicional de volume

#plot.ts(sigma(garchM.vol), ylab="sigma(t)", col="blue")

```

Uma projeção pode ser feita com o modelo GARCH(1,1) para a série de retornos de preços:

```{r}

bootpred <- ugarchboot(garchM.fech, method = "Partial", n.ahead = 120, n.bootpred = 2000)

bootpred

```



```{r eval = FALSE}
#Forecasting

forecastGARCH(garchM.fech,garchM.vol,r=6,trace=TRUE)
forecastGARCH(garchM.fech,garchM.vol,r=6)

```


Mas se quisermos comparar qual modelo GARCH obtém o melhor ajuste aos dados, precisaremos partir de ajustes de modelos de ordem mais baixa até aquele de melhor ajuste conforme os critérios de informação AIC e BIC.

Começamos especificando as ordens do modelo:

```{r}

# GARCH(1,2)
garchM12 <- ugarchspec(
          variance.model=list(model="fGARCH",
                               garchOrder=c(1,2),
                               submodel="APARCH"),
           mean.model=list(armaOrder=c(0,0),
                          include.mean=TRUE,
                          archm=TRUE,
                          archpow=2
                          ), 
           distribution.model="std"
                           )
# GARCH(2,1)
garchM21 <- ugarchspec(
          variance.model=list(model="fGARCH",
                               garchOrder=c(2,1),
                               submodel="APARCH"),
           mean.model=list(armaOrder=c(0,0),
                          include.mean=TRUE,
                          archm=TRUE,
                          archpow=2
                          ), 
           distribution.model="std"
                           )
# GARCH(2,2)
garchM22 <- ugarchspec(
          variance.model=list(model="fGARCH",
                               garchOrder=c(2,2),
                               submodel="APARCH"),
           mean.model=list(armaOrder=c(0,0),
                          include.mean=TRUE,
                          archm=TRUE,
                          archpow=2
                          ), 
           distribution.model="std"
                           )


```


Estimamos cada um dos modelos para as séries de retornos dos preços e do volume

```{r}

# GARCH(1,1) ja temos que
garchM.fech <- ugarchfit(spec=garchM, data=ret_fech_diario)
coef(garchM.fech ) # Coeficientes estimados dos retornos de precos

garchM.vol <- ugarchfit(spec=garchM, data=ret_vol_diario)
coef(garchM.vol) # Coeficientes estimados dos retornos de volume

# GARCH(1,2)
garchM.fech12 <- ugarchfit(spec=garchM12, data=ret_fech_diario)
coef(garchM.fech ) # Coeficientes estimados dos retornos de precos

garchM.vol12 <- ugarchfit(spec=garchM12, data=ret_vol_diario)
coef(garchM.vol) # Coeficientes estimados dos retornos de volume

# GARCH(2,1)
garchM.fech21 <- ugarchfit(spec=garchM21, data=ret_fech_diario)
coef(garchM.fech ) # Coeficientes estimados dos retornos de precos

garchM.vol21 <- ugarchfit(spec=garchM21, data=ret_vol_diario)
coef(garchM.vol) # Coeficientes estimados dos retornos de volume

# GARCH(2,2)
garchM.fech22 <- ugarchfit(spec=garchM22, data=ret_fech_diario)
coef(garchM.fech ) # Coeficientes estimados dos retornos de precos

garchM.vol22 <- ugarchfit(spec=garchM22, data=ret_vol_diario)
coef(garchM.vol) # Coeficientes estimados dos retornos de volume

```


Comparamos com os critérios de informação:


```{r eval=FALSE}

infocriteria(garchM.fech) # GARCH(1,1) retornos dos precos
infocriteria(garchM.fech12) # GARCH(1,2) retornos dos precos
infocriteria(garchM.fech21) # GARCH(2,1) retornos dos precos
infocriteria(garchM.fech22) # GARCH(2,2) retornos dos precos
infocriteria(garchM.vol) # GARCH(1,1) retornos do volume
infocriteria(garchM.vol12) # GARCH(1,2) retornos do volume
infocriteria(garchM.vol21) # GARCH(2,1) retornos do volume
infocriteria(garchM.vol22) # GARCH(2,2) retornos do volume

```










<mark>[CONTINUAR ESCREVENDO]</mark>





***

&nbsp;


## Seleção de modelos pela acurácia e ajuste


&nbsp;

***


## Simulação de cenários











$$\\[1in]$$










$$\\[1in]$$


***

# Referências


Brock, W.A., W.D. Dechert, J.A. Scheinkman and B. LeBaron. **A Test for Independence Based on the Correlation Dimension**, Econometric Reviews, 15, 197-235, 1996.

Chow, Gregory C. **Econometric methods.** Nova York: McGraw-Hill, 1983.

Diebold, Francis X. **Elements of forecasting.** 2. ed. South Western Publishing, 2001. p. 254.

Franses, P.H. **Time Series Models for Business and Economic Forecasting.** Cambridge: Cambridge University Press, 1998.

R Core Team (2020). **R: A language and environment for statistical computing.** R Foundation for Statistical Computing, Vienna, Austria.
URL https://www.R-project.org/. 

Granger, C. W. J. **Investigating causal relations by econometric models and cross-spectral methods**. _In_ Econometrica, p. 424-438, jul. 1969.

Gujarati, D. N., Porter, D. **Econometria Básica**, quinta ed. São Paulo, 2011.

Hyndman, R., J., Athanasopoulos, G. **Forecasting:Principles and Practice**, Monash University, Australia, 2018.

Hull, J.C. **Options, Futures & Other Derivatives,** 5Th ed, 2002, Prentice Hall

J. Durbin, S. J. Koopman,  **A simple and efficient simulation smoother for state space time series analysis** Biometrika, Volume 89, Issue 3, August 2002, Pages 603–616, https://doi.org/10.1093/biomet/89.3.603 Published: 01 August 2002.

Koop, G. **Analysis of economic data.** Nova York: John Wiley & Sons, 2000.

Kwiatkowski, D., Phillips, P. C. B., Schmidt, P., & Shin, Y. **Testing the null hypothesis of stationarity against the alternative of a unit root: How sure are we that economic time series have a unit root?** Journal of Econometrics, 54(1-3), 159–178, 1992. https://doi.org/10.1016/0304-4076(92)90104-Y

Maddala, G. S., **Introdução à Econometria**, 3a ed. LTC, Rio de Janeiro, 2003.

Morettin, P. **Econometria Financeira: Um curso de séries temporais financeiras**, 2a. ed. revista e ampliada, São Paulo, 2006.

Shleifer, A. **Inefficient Markets: an introduction to Behavioral Finance.** Oxford University Press, 2000.

Thurman W.N. & Fisher M.E, **Chickens, Eggs, and Causality, or Which Came First?**, _American Journal of Agricultural Economics_, 1988, 237-238.

*** 
