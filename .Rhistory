amplitude_picos <- 5  # Amplitude dos picos
prob_pico <- 0.01  # Probabilidade de ocorrer um pico em cada ponto
# Criar vetor de tempos
tempos <- seq(0, duração, by = frequência)
# Gerar série temporal
serie <- rep(media, length(tempos))  # Inicializar a série com o valor médio
# Adicionar picos imprevisíveis
for (i in 2:length(tempos)) {
if (runif(1) < prob_pico) {
serie[i] <- serie[i] + rnorm(1, mean = 0, sd = amplitude_picos)
}
}
# Criar data frame com os dados
dados <- data.frame(Tempo = tempos, Valor = serie)
# Plotar série temporal
ggplot(dados, aes(x = Tempo, y = Valor)) +
geom_line() +
labs(x = "Tempo (s)", y = "Valor") +
theme_minimal()
# Carregar pacotes necessários
library(ggplot2)
# Definir a semente aleatória para reprodução dos resultados
set.seed(123)
# Definir parâmetros
duração <- 3 * 60 * 60  # Duração em segundos (3 horas)
frequência <- 1  # Frequência de amostragem em segundos
media <- 10  # Valor médio da série
amplitude_picos <- 5  # Amplitude dos picos acima de 10
prob_pico <- 0.01  # Probabilidade de ocorrer um pico em cada ponto
# Criar vetor de tempos
tempos <- seq(0, duração, by = frequência)
# Gerar série temporal
serie <- rep(media, length(tempos))  # Inicializar a série com o valor médio
# Adicionar picos imprevisíveis acima de 10
for (i in 2:length(tempos)) {
if (serie[i-1] > 10 & runif(1) < prob_pico) {
serie[i] <- serie[i] + abs(rnorm(1, mean = 0, sd = amplitude_picos))
}
}
# Criar data frame com os dados
dados <- data.frame(Tempo = tempos, Valor = serie)
# Plotar série temporal
ggplot(dados, aes(x = Tempo, y = Valor)) +
geom_line() +
labs(x = "Tempo (s)", y = "Valor") +
theme_minimal()
# Carregar pacotes necessários
library(ggplot2)
# Definir a semente aleatória para reprodução dos resultados
set.seed(123)
# Definir parâmetros
duração <- 3 * 60 * 60  # Duração em segundos (3 horas)
frequência <- 1  # Frequência de amostragem em segundos
media <- 10  # Valor médio da série
amplitude_picos <- 5  # Amplitude dos picos acima de 10
prob_pico <- 0.01  # Probabilidade de ocorrer um pico em cada ponto
# Criar vetor de tempos
tempos <- seq(0, duração, by = frequência)
# Gerar série temporal
serie <- rep(media, length(tempos))  # Inicializar a série com o valor médio
# Adicionar picos imprevisíveis acima de 10
for (i in 2:length(tempos)) {
if (serie[i-1] > 10 & runif(1) < prob_pico) {
pico <- rnorm(1, mean = 0, sd = amplitude_picos)
serie[i] <- ifelse(serie[i-1] + pico > 10, serie[i-1] + pico, serie[i-1] - pico)
}
}
# Criar data frame com os dados
dados <- data.frame(Tempo = tempos, Valor = serie)
# Plotar série temporal
ggplot(dados, aes(x = Tempo, y = Valor)) +
geom_line() +
labs(x = "Tempo (s)", y = "Valor") +
theme_minimal()
# Carregue os pacotes necessários
if(!require(dplyr)) install.packages('dplyr')
if(!require(ggplot2)) install.packages('ggplot2')
# Configurações
set.seed(123)  # para resultados reprodutíveis
freq <- 1       # frequência de 1 segundo
total_time <- 3 * 60 * 60  # total de 3 horas em segundos
# Gerar a série temporal
time <- seq(0, total_time, by = freq)
amplitude <- sin(2 * pi * time / 60) + rnorm(length(time), sd = 0.2)  # série sinusoidal com ruído
# Converter para data frame
ecg_df <- data.frame(Time = time, Amplitude = amplitude)
# Criar picos aleatórios
num_peaks <- total_time / 60  # suponha um pico a cada minuto
peak_indices <- sample(1:length(time), num_peaks)
ecg_df$Amplitude[peak_indices] <- ecg_df$Amplitude[peak_indices] + rnorm(num_peaks, mean = 2, sd = 0.5)
# Visualizar o ECG simulado
ggplot(ecg_df, aes(x = Time, y = Amplitude)) +
geom_line() +
labs(title = "ECG Simulado", x = "Tempo (segundos)", y = "Amplitude")
# Carregue o pacote necessário
if(!require(sets)) install.packages('sets')
# Defina as funções de pertinência para os conjuntos fuzzy
membership_function_failure <- function(x) {
return(exp(-((x - 2)^2) / (2 * 0.5^2)))  # suponha que falhas estejam normalmente em torno de 2 com desvio padrão 0.5
}
membership_function_corrupt <- function(x) {
return(exp(-((x - 3)^2) / (2 * 1^2)))  # suponha que dados corrompidos estejam normalmente em torno de 3 com desvio padrão 1
}
# Defina os conjuntos fuzzy
set_failure <- fuzzy_set(membership_function_failure)
return(exp(-((x - 2)^2) / (2 * 0.5^2)))  # suponha que falhas estejam normalmente em torno de 2 com desvio padrão 0.5
# Defina as funções de pertinência
membership_function_failure <- function(x) {
return(exp(-((x - 2)^2) / (2 * 0.5^2)))  # suponha que falhas estejam normalmente em torno de 2 com desvio padrão 0.5
}
membership_function_corrupt <- function(x) {
return(exp(-((x - 3)^2) / (2 * 1^2)))  # suponha que dados corrompidos estejam normalmente em torno de 3 com desvio padrão 1
}
# Aplique as funções de pertinência aos picos
ecg_df$FailureMembership <- sapply(ecg_df$Amplitude[peak_indices], membership_function_failure)
ecg_df$CorruptMembership <- sapply(ecg_df$Amplitude[peak_indices], membership_function_corrupt)
# Inicialize as colunas de pertinência com zeros
ecg_df$FailureMembership <- rep(0, nrow(ecg_df))
ecg_df$CorruptMembership <- rep(0, nrow(ecg_df))
ecg_df$Classification <- rep(NA, nrow(ecg_df))
# Aplique as funções de pertinência apenas aos picos
ecg_df$FailureMembership[peak_indices] <- sapply(ecg_df$Amplitude[peak_indices], membership_function_failure)
ecg_df$CorruptMembership[peak_indices] <- sapply(ecg_df$Amplitude[peak_indices], membership_function_corrupt)
# Classifique os picos de acordo com a maior pertinência
ecg_df$Classification[peak_indices] <- ifelse(ecg_df$FailureMembership[peak_indices] > ecg_df$CorruptMembership[peak_indices], "failure", "corrupt")
ecg_df
# Visualizar o ECG simulado com classificações
ggplot(ecg_df, aes(x = Time, y = Amplitude)) +
geom_line() +
geom_point(data = ecg_df[peak_indices, ], aes(color = Classification), size = 3) +
labs(title = "ECG Simulado com Classificações", x = "Tempo (segundos)", y = "Amplitude") +
scale_color_manual(values = c("failure" = "red", "corrupt" = "blue")) +
theme_minimal()
table(ecg_df$Classification)
ggplot(ecg_df[peak_indices, ], aes(x = Amplitude, fill = Classification)) +
geom_histogram(position = "identity", alpha = 0.5, bins = 30) +
labs(title = "Distribuição de Amplitudes por Classificação", x = "Amplitude", y = "Contagem") +
scale_fill_manual(values = c("failure" = "red", "corrupt" = "blue")) +
theme_minimal()
ggplot(ecg_df[peak_indices, ], aes(x = Time, fill = Classification)) +
geom_histogram(position = "identity", alpha = 0.5, bins = 30) +
labs(title = "Distribuição de Tempo por Classificação", x = "Tempo (segundos)", y = "Contagem") +
scale_fill_manual(values = c("failure" = "red", "corrupt" = "blue")) +
theme_minimal()
ggplot(ecg_df[peak_indices, ], aes(x = Time, color = Classification)) +
geom_line(aes(y = FailureMembership), linetype = "dashed") +
geom_line(aes(y = CorruptMembership), linetype = "dotted") +
labs(title = "Pertinência ao longo do Tempo", x = "Tempo (segundos)", y = "Pertinência") +
scale_color_manual(values = c("failure" = "red", "corrupt" = "blue")) +
theme_minimal()
table(ecg_df$Classification)
return(exp(-((x - 2)^2) / (2 * 1^2)))  # aumente o desvio padrão para classificar mais picos como "failure"
# Ajuste as funções de pertinência
membership_function_failure <- function(x) {
return(exp(-((x - 2)^2) / (2 * 1^2)))  # aumente o desvio padrão para classificar mais picos como "failure"
}
membership_function_corrupt <- function(x) {
return(exp(-((x - 3)^2) / (2 * 0.5^2)))  # diminua o desvio padrão para classificar menos picos como "corrupt"
}
# Aplique as funções de pertinência apenas aos picos
ecg_df$FailureMembership[peak_indices] <- sapply(ecg_df$Amplitude[peak_indices], membership_function_failure)
ecg_df$CorruptMembership[peak_indices] <- sapply(ecg_df$Amplitude[peak_indices], membership_function_corrupt)
# Classifique os picos de acordo com a maior pertinência
ecg_df$Classification[peak_indices] <- ifelse(ecg_df$FailureMembership[peak_indices] > ecg_df$CorruptMembership[peak_indices], "failure", "corrupt")
table(ecg_df$Classification)
# Visualizar o ECG simulado com classificações
ggplot(ecg_df, aes(x = Time, y = Amplitude)) +
geom_line() +
geom_point(data = ecg_df[peak_indices, ], aes(color = Classification), size = 3) +
labs(title = "ECG Simulado com Classificações", x = "Tempo (segundos)", y = "Amplitude") +
scale_color_manual(values = c("failure" = "red", "corrupt" = "blue")) +
theme_minimal()
# Plotar série temporal
ggplot(dados, aes(x = Tempo, y = Valor)) +
geom_line() +
labs(x = "Tempo (s)", y = "Valor") +
theme_minimal()
# Visualizar o ECG simulado
ggplot(ecg_df, aes(x = Time, y = Amplitude)) +
geom_line() +
labs(title = "ECG Simulado", x = "Tempo (segundos)", y = "Amplitude")
# Gerar a série temporal
time <- seq(0, total_time, by = freq)
amplitude <- abs(sin(2 * pi * time / 60) + rnorm(length(time), sd = 0.2))  # série sinusoidal com ruído
# Converter para data frame
ecg_df <- data.frame(Time = time, Amplitude = amplitude)
# Criar picos aleatórios
num_peaks <- total_time / 60  # suponha um pico a cada minuto
peak_indices <- sample(1:length(time), num_peaks)
ecg_df$Amplitude[peak_indices] <- abs(ecg_df$Amplitude[peak_indices] + rnorm(num_peaks, mean = 2, sd = 0.5))
ecg_df
ggplot(ecg_df, aes(x = Time,
y = Amplitude )) +
geom_line()
# Ajuste as funções de pertinência
membership_function_failure <- function(x) {
return(exp(-((x - 2)^2) / (2 * 1^2)))  # aumente o desvio padrão para classificar mais picos como "failure"
}
membership_function_corrupt <- function(x) {
return(exp(-((x - 3)^2) / (2 * 0.5^2)))  # diminua o desvio padrão para classificar menos picos como "corrupt"
}
# Aplique as funções de pertinência apenas aos picos
ecg_df$FailureMembership[peak_indices] <- sapply(ecg_df$Amplitude[peak_indices], membership_function_failure)
ggplot(ecg_df, aes(x = Time,
y = Amplitude )) +
geom_line() +
labs(x = "Tempo (s)", y = "Valor") +
theme_minimal()
# Defina as funções de pertinência
membership_function_failure <- function(x) {
return(exp(-((x - 3)^2) / (2 * 0.5^2)))  # os picos menores terão pertinência maior para "failure"
}
membership_function_corrupt <- function(x) {
return(exp(-((x - 2)^2) / (2 * 1^2)))  # os picos maiores terão pertinência maior para "corrupt"
}
# Inicialize as colunas de pertinência e classificação
ecg_df$FailureMembership <- 0
ecg_df$CorruptMembership <- 0
ecg_df$Classification <- "normal"
# Aplique as funções de pertinência apenas aos picos
ecg_df$FailureMembership[peak_indices] <- sapply(ecg_df$Amplitude[peak_indices], membership_function_failure)
ecg_df$CorruptMembership[peak_indices] <- sapply(ecg_df$Amplitude[peak_indices], membership_function_corrupt)
# Classifique os picos de acordo com a maior pertinência
ecg_df$Classification[peak_indices] <- ifelse(ecg_df$FailureMembership[peak_indices] > ecg_df$CorruptMembership[peak_indices], "failure", "corrupt")
table(ecg_df$Classification)
ecg_df
# Gerar a série temporal
time <- seq(0, total_time, by = freq)
amplitude <- abs(sin(2 * pi * time / 60) + rnorm(length(time), sd = 0.2)) + 5  # série sinusoidal com ruído
# Converter para data frame
ecg_df <- data.frame(Time = time, Amplitude = amplitude)
# Criar picos aleatórios
num_peaks <- total_time / 60  # suponha um pico a cada minuto
peak_indices <- sample(1:length(time), num_peaks)
ecg_df$Amplitude[peak_indices] <- abs(ecg_df$Amplitude[peak_indices] + rnorm(num_peaks, mean = 2, sd = 0.5)) + 5
ggplot(ecg_df, aes(x = Time,
y = Amplitude )) +
geom_line() +
labs(x = "Tempo (s)", y = "Valor") +
theme_minimal()
# Defina as funções de pertinência
membership_function_failure <- function(x) {
return(exp(-((x - 7)^2) / (2 * 0.5^2)))  # os picos menores terão pertinência maior para "failure"
}
membership_function_corrupt <- function(x) {
return(exp(-((x - 10)^2) / (2 * 1^2)))  # os picos maiores terão pertinência maior para "corrupt"
}
# Inicialize as colunas de pertinência e classificação
ecg_df$FailureMembership <- 0
ecg_df$CorruptMembership <- 0
ecg_df$Classification <- "normal"
# Aplique as funções de pertinência apenas aos picos
ecg_df$FailureMembership[peak_indices] <- sapply(ecg_df$Amplitude[peak_indices], membership_function_failure)
ecg_df$CorruptMembership[peak_indices] <- sapply(ecg_df$Amplitude[peak_indices], membership_function_corrupt)
# Classifique os picos de acordo com a maior pertinência
ecg_df$Classification[peak_indices] <- ifelse(ecg_df$FailureMembership[peak_indices] > ecg_df$CorruptMembership[peak_indices], "failure", "corrupt")
table(ecg_df$Classification)
return(exp(-((x - 6)^2) / (2 * 1^2)))  # os picos menores terão pertinência maior para "failure"
# Defina as funções de pertinência
membership_function_failure <- function(x) {
return(exp(-((x - 6)^2) / (2 * 1^2)))  # os picos menores terão pertinência maior para "failure"
}
membership_function_corrupt <- function(x) {
return(exp(-((x - 10)^2) / (2 * 1^2)))  # os picos maiores terão pertinência maior para "corrupt"
}
# Inicialize as colunas de pertinência e classificação
ecg_df$FailureMembership <- 0
ecg_df$CorruptMembership <- 0
ecg_df$Classification <- "normal"
# Aplique as funções de pertinência apenas aos picos
ecg_df$FailureMembership[peak_indices] <- sapply(ecg_df$Amplitude[peak_indices], membership_function_failure)
ecg_df$CorruptMembership[peak_indices] <- sapply(ecg_df$Amplitude[peak_indices], membership_function_corrupt)
# Classifique os picos de acordo com a maior pertinência
ecg_df$Classification[peak_indices] <- ifelse(ecg_df$FailureMembership[peak_indices] > ecg_df$CorruptMembership[peak_indices], "failure", "corrupt")
table(ecg_df$Classification)
# Defina as funções de pertinência
membership_function_failure <- function(x) {
return(exp(-((x - 6)^2) / (2 * 2^2)))  # centro em 6, largura de 2
}
membership_function_corrupt <- function(x) {
return(exp(-((x - 12)^2) / (2 * 2^2)))  # centro em 12, largura de 2
}
# Inicialize as colunas de pertinência e classificação
ecg_df$FailureMembership <- 0
ecg_df$CorruptMembership <- 0
ecg_df$Classification <- "normal"
# Aplique as funções de pertinência apenas aos picos
ecg_df$FailureMembership[peak_indices] <- sapply(ecg_df$Amplitude[peak_indices], membership_function_failure)
ecg_df$CorruptMembership[peak_indices] <- sapply(ecg_df$Amplitude[peak_indices], membership_function_corrupt)
# Classifique os picos de acordo com a maior pertinência
ecg_df$Classification[peak_indices] <- ifelse(ecg_df$FailureMembership[peak_indices] > ecg_df$CorruptMembership[peak_indices], "failure", "corrupt")
table(ecg_df$Classification)
# Gerar tempos de espera entre picos
wait_times <- rexp(num_peaks, rate = 1/60)
# Converter para índices de tempo
peak_indices <- cumsum(wait_times)
# Ajustar para a escala de tempo do nosso conjunto de dados
peak_indices <- round(peak_indices * freq) + 1
# Remover quaisquer índices que sejam maiores do que o tamanho do nosso conjunto de dados
peak_indices <- peak_indices[peak_indices <= length(time)]
# Agora podemos criar os picos como antes
ecg_df$Amplitude[peak_indices] <- abs(ecg_df$Amplitude[peak_indices] + rnorm(length(peak_indices), mean = 2, sd = 0.5)) + 5
peak_indices <- sample(1:length(time), num_peaks)
ecg_df$Amplitude[peak_indices] <- abs(ecg_df$Amplitude[peak_indices] + rnorm(num_peaks, mean = 2, sd = 0.5)) + 5
ggplot(ecg_df, aes(x = Time,
y = Amplitude )) +
geom_line() +
labs(x = "Tempo (s)", y = "Valor") +
theme_minimal()
library(xts)
# Defina o número de segundos (por exemplo, 1 dia)
n <- 24*60*60
# Crie uma série temporal com valores aleatórios em torno de um número positivo (por exemplo, 10)
set.seed(123) # para reprodutibilidade
data <- rnorm(n, mean=10, sd=1)
# Adicione alguns picos aleatórios
peak_indices <- sample(1:n, size=10)
data[peak_indices] <- data[peak_indices] + rnorm(10, mean=20, sd=5)
# Crie um objeto de série temporal indexado por data/hora
time_index <- seq(from=as.POSIXct("2023-06-09 00:00:00"), by="sec", length.out=n)
ts <- xts(data, order.by=time_index)
# Visualize a série temporal
plot(ts)
head(ts)
# Visualize a série temporal
plotly::ggplotly(
plot(ts)
)
str(ts)
# Função de pertinência triangular
triangular_membership_function <- function(x, a, b, c) {
return(max(min((x-a)/(b-a), (c-x)/(c-b)), 0))
}
# Definir os parâmetros para as funções de pertinência
# Estes devem ser ajustados de acordo com o seu conhecimento do domínio
a_fail <- 10
b_fail <- 20
c_fail <- 30
a_corrupt <- 20
b_corrupt <- 30
c_corrupt <- 40
# Aplicar as funções de pertinência aos dados
membership_fail <- sapply(data, triangular_membership_function, a=a_fail, b=b_fail, c=c_fail)
membership_corrupt <- sapply(data, triangular_membership_function, a=a_corrupt, b=b_corrupt, c=c_corrupt)
# Classificar os dados
classification <- ifelse(membership_fail > membership_corrupt, "fail", "corrupt")
classification
# Função de pertinência triangular
triangular_membership_function <- function(x, a, b, c) {
return(max(min((x-a)/(b-a), (c-x)/(c-b)), 0))
}
# Definir os parâmetros para as funções de pertinência
# Estes devem ser ajustados de acordo com o seu conhecimento do domínio
a_fail <- 10
b_fail <- 20
c_fail <- 30
# Definir os parâmetros para a função de pertinência "normal"
a_normal <- 5
b_normal <- 10
c_normal <- 15
a_corrupt <- 20
b_corrupt <- 30
c_corrupt <- 40
# Aplicar as funções de pertinência aos dados
membership_fail <- sapply(data, triangular_membership_function, a=a_fail, b=b_fail, c=c_fail)
membership_corrupt <- sapply(data, triangular_membership_function, a=a_corrupt, b=b_corrupt, c=c_corrupt)
membership_normal <- sapply(data, triangular_membership_function, a=a_normal, b=b_normal, c=c_normal)
# Aplicar a função de pertinência aos dados
membership_normal <- sapply(data, triangular_membership_function, a=a_normal, b=b_normal, c=c_normal)
# Classificar os dados
classification <- ifelse(membership_fail > membership_corrupt & membership_fail > membership_normal, "fail",
ifelse(membership_corrupt > membership_normal, "corrupt", "normal"))
classification
library(ggplot2)
# Adicione a classificação ao objeto xts
ts$Classification <- classification
# Crie um objeto xts para a classificação
classification_ts <- xts(classification, order.by=time_index)
# Adicione a classificação ao objeto xts
ts <- merge(ts, classification_ts)
# Renomeie as colunas
colnames(ts) <- c("Value", "Classification")
# Converta o objeto xts para um data frame para usar com ggplot2
df <- data.frame(Time = index(ts), coredata(ts))
# Crie o gráfico
ggplot(df, aes(x=Time, y=Value, color=Classification)) +
geom_point() +
scale_color_manual(values=c("green", "red", "blue")) +
labs(title="Classification of data points", x="Time", y="Value") +
theme_minimal()
# Converta a coluna Classification em fatores
df$Classification <- as.factor(df$Classification)
# Crie o gráfico
ggplot(df, aes(x=Time, y=Value, color=Classification)) +
geom_point() +
scale_color_manual(values=c("normal" = "green", "fail" = "red", "corrupt" = "blue")) +
labs(title="Classification of data points", x="Time", y="Value") +
theme_minimal()()
# Crie o gráfico
ggplot(df, aes(x=Time, y=Value, color=Classification)) +
geom_point() +
scale_color_manual(values=c("normal" = "green", "fail" = "red", "corrupt" = "blue")) +
labs(title="Classification of data points", x="Time", y="Value") +
theme_minimal()
# Crie o gráfico
ggplot(df, aes(x=Time, y=Value, color=Classification)) +
geom_point(aes(color = Classification)) +
scale_color_manual(values = c("normal" = "green", "fail" = "red", "corrupt" = "blue")) +
labs(title="Classification of data points", x="Time", y="Value") +
theme_minimal()
# Crie o gráfico
# Crie o gráfico
ggplot(df, aes(x=Time, y=Value)) +
geom_point(aes(color = Classification)) +
scale_color_manual(values = c("normal" = "green", "fail" = "red", "corrupt" = "blue")) +
labs(title="Classification of data points", x="Time", y="Value") +
theme_minimal()
# Instale e carregue os pacotes necessários
install.packages(c("quantmod", "FuzzyMCDM"))
library(quantmod)
library(FuzzyMCDM)
# Obtenha os dados de preços diários para milho e soja nos últimos 252 dias
end <- Sys.Date()
start <- end - 252
getSymbols("C", src = "yahoo", from = start, to = end)
getSymbols("S", src = "yahoo", from = start, to = end)
# Calcule os retornos diários
returns_corn <- dailyReturn(Cl(C))
returns_soy <- dailyReturn(Cl(S))
# Calcule o risco como o desvio padrão dos retornos
risk_corn <- sd(returns_corn)
risk_soy <- sd(returns_soy)
# Calcule o retorno como a média dos retornos
return_corn <- mean(returns_corn)
return_soy <- mean(returns_soy)
# Crie uma matriz de decisão
decision_matrix <- matrix(c(risk_corn, risk_soy, return_corn, return_soy), nrow = 2)
# Defina os pesos para o risco e retorno. Aqui, assumimos que ambos são igualmente importantes
weights <- c(0.5, 0.5)
# Defina a direção da otimização. Aqui, assumimos que queremos minimizar o risco e maximizar o retorno
optimization_direction <- c("min", "max")
# Aplique o método Fuzzy TOPSIS
result <- FuzzyTOPSIS(decision_matrix, weights, optimization_direction)
library(FuzzyR)
# Crie uma matriz de decisão
decision_matrix <- matrix(c(risk_corn, risk_soy, return_corn, return_soy), nrow = 2)
# Defina os pesos para o risco e retorno. Aqui, assumimos que ambos são igualmente importantes
weights <- c(0.5, 0.5)
# Defina a direção da otimização. Aqui, assumimos que queremos minimizar o risco e maximizar o retorno
optimization_direction <- c("min", "max")
# Aplique o método TOPSIS
result <- fuzzy.topsis(decision_matrix, weights, optimization_direction)
library(quantmod)
library(FuzzyMCDM)
# Obtenha os dados de preços diários para milho e soja nos últimos 252 dias
end <- Sys.Date()
start <- end - 252
getSymbols("C", src = "yahoo", from = start, to = end)
getSymbols("S", src = "yahoo", from = start, to = end)
# Calcule os retornos diários
returns_corn <- dailyReturn(Cl(C))
returns_soy <- dailyReturn(Cl(S))
# Calcule o risco como o desvio padrão dos retornos
risk_corn <- sd(returns_corn)
risk_soy <- sd(returns_soy)
# Calcule o retorno como a média dos retornos
return_corn <- mean(returns_corn)
return_soy <- mean(returns_soy)
# Crie uma matriz de decisão
decision_matrix <- matrix(c(risk_corn, risk_soy, return_corn, return_soy), nrow = 2)
# Defina os pesos para o risco e retorno. Aqui, assumimos que ambos são igualmente importantes
weights <- c(0.5, 0.5)
# Defina a direção da otimização. Aqui, assumimos que queremos minimizar o risco e maximizar o retorno
optimization_direction <- c("min", "max")
# Aplique o método Fuzzy TOPSIS
result <- FuzzyTOPSISLinear(decision_matrix, weights, optimization_direction)
library(quantmod)
library(FuzzyMCDM)
# Obtenha os dados de preços diários para milho e soja nos últimos 252 dias
end <- Sys.Date()
start <- end - 252
getSymbols("C", src = "yahoo", from = start, to = end)
getSymbols("S", src = "yahoo", from = start, to = end)
# Calcule os retornos diários
returns_corn <- dailyReturn(Cl(C))
returns_soy <- dailyReturn(Cl(S))
# Calcule o risco como o desvio padrão dos retornos
risk_corn <- sd(returns_corn)
risk_soy <- sd(returns_soy)
# Calcule o retorno como a média dos retornos
return_corn <- mean(returns_corn)
return_soy <- mean(returns_soy)
# Crie uma matriz de decisão
decision_matrix <- matrix(c(risk_corn, risk_soy, return_corn, return_soy), nrow = 2, byrow = TRUE)
# Defina os pesos para o risco e retorno. Aqui, assumimos que ambos são igualmente importantes
weights <- c(0.5, 0.5)
# Defina a direção da otimização. Aqui, assumimos que queremos minimizar o risco e maximizar o retorno
optimization_direction <- c("min", "max")
# Aplique o método Fuzzy TOPSIS
result <- FuzzyTOPSISLinear(decision_matrix, weights, optimization_direction)
library(rugarch)
# Defina os pesos para o risco e retorno. Aqui, assumimos que ambos são igualmente importantes
weights <- c(0.5, 0.5
q
rmarkdown::render_site()
rmarkdown::render_site()
rmarkdown::render_site()
rmarkdown::render_site()
install.packages("rmgarch")
install.packages("installr")
library(installr)
updateR()
